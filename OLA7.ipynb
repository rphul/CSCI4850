{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# Visualization\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfshome/sandbox/gutenberg_example/PandP_Jane_Austen.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "text = []\n",
    "for i in range(len(lines)):\n",
    "    if lines[i] != '':\n",
    "        text = text + [lines[i]]\n",
    "min_length = max([len(i) for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/nfshome/sandbox/gutenberg_example/unique_chars.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "itos = ['','',' ']\n",
    "for i in lines:\n",
    "    itos = itos + [i]\n",
    "stoi = dict()\n",
    "stoi['STOP'] = 0\n",
    "stoi['START'] = 1\n",
    "for i in range(2,len(itos)):\n",
    "    stoi[itos[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(x,mapping,min_length=0):\n",
    "    y = [mapping['START']]\n",
    "    for i in list(x):\n",
    "        y = y + [mapping[i]]\n",
    "    y = y + [mapping['STOP']]\n",
    "    while len(y) < min_length:\n",
    "        y = y + [mapping['STOP']]\n",
    "    return keras.utils.to_categorical(y,len(mapping))\n",
    "\n",
    "def decode_seq(x,mapping):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        y = y + [mapping[np.argmax(i)]]\n",
    "    return ''.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = encode_seq(text[0],stoi)\n",
    "temp = decode_seq(temp,itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "for i in range(len(text)):\n",
    "    temp = encode_seq(text[i],stoi)\n",
    "    dataX[i,0:len(temp),:] = temp\n",
    "\n",
    "dataY = np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "for i in range(len(text)):\n",
    "    temp = encode_seq(text[i],stoi)\n",
    "    dataY[i,0:len(temp),:] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataX[0:dataX.shape[0]-1,:,:]\n",
    "Y = dataY[1:dataY.shape[0],:,:]\n",
    "preY = Y[:,0:Y.shape[1]-1,:]\n",
    "postY = Y[:,1:Y.shape[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 76, 71)\n",
      "(50, 76, 71)\n",
      "(50, 75, 71)\n",
      "(50, 75, 71)\n"
     ]
    }
   ],
   "source": [
    "nlines = 50\n",
    "X = X[0:nlines,:,:]\n",
    "Y = Y[0:nlines,:,:]\n",
    "preY = preY[0:nlines,:,:]\n",
    "postY = postY[0:nlines,:,:]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(preY.shape)\n",
    "print(postY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 228), (None, 273600      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 228),  273600      input_4[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 71)     16259       lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 563,459\n",
      "Trainable params: 563,459\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_size = X.shape[1]*3\n",
    "encoder_input = keras.layers.Input(shape=(None, X.shape[2]))\n",
    "encoder_hidden = keras.layers.LSTM(hidden_size, return_state=True)\n",
    "# Tie the hidden layer to the input layer (passed in)\n",
    "encoder_output, enc_state_h, enc_state_c = encoder_hidden(encoder_input)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [enc_state_h, enc_state_c]\n",
    "## Decoder Construction\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_input = keras.layers.Input(shape=(None, preY.shape[2]))\n",
    "decoder_hidden = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "# Connect hidden to input (also reads from the encoder...)\n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = decoder_hidden(decoder_input,\n",
    "initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(postY.shape[2], activation='softmax')\n",
    "# Connect output to hidden\n",
    "decoder_output = decoder_dense(decoder_hidden_output)\n",
    "# 2 input layers and an output layer...\n",
    "# 1. Targets are postY\n",
    "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "optimizer=keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 263.00 264.00\" width=\"263pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 259,-260 259,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140171834210904 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140171834210904</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 125,-255.5 125,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-233.8\">input_3: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140171834210848 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140171834210848</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-146.5 13.5,-182.5 111.5,-182.5 111.5,-146.5 13.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 140171834210904&#45;&gt;140171834210848 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140171834210904-&gt;140171834210848</title>\n",
       "<path d=\"M62.5,-219.313C62.5,-211.289 62.5,-201.547 62.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-192.529 62.5,-182.529 59.0001,-192.529 66.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140171834210960 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140171834210960</title>\n",
       "<polygon fill=\"none\" points=\"130,-146.5 130,-182.5 255,-182.5 255,-146.5 130,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-160.8\">input_4: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140171834211520 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140171834211520</title>\n",
       "<polygon fill=\"none\" points=\"78.5,-73.5 78.5,-109.5 176.5,-109.5 176.5,-73.5 78.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-87.8\">lstm_4: LSTM</text>\n",
       "</g>\n",
       "<!-- 140171834210960&#45;&gt;140171834211520 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140171834210960-&gt;140171834211520</title>\n",
       "<path d=\"M176.765,-146.313C168.701,-137.505 158.741,-126.625 149.892,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"152.424,-114.541 143.09,-109.529 147.261,-119.268 152.424,-114.541\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140171834210848&#45;&gt;140171834211520 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140171834210848-&gt;140171834211520</title>\n",
       "<path d=\"M78.2347,-146.313C86.2986,-137.505 96.2588,-126.625 105.108,-116.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107.739,-119.268 111.91,-109.529 102.576,-114.541 107.739,-119.268\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140171834659952 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140171834659952</title>\n",
       "<polygon fill=\"none\" points=\"76.5,-0.5 76.5,-36.5 178.5,-36.5 178.5,-0.5 76.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140171834211520&#45;&gt;140171834659952 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140171834211520-&gt;140171834659952</title>\n",
       "<path d=\"M127.5,-73.3129C127.5,-65.2895 127.5,-55.5475 127.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"131,-46.5288 127.5,-36.5288 124,-46.5289 131,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422c3828d1f643ca9f74812382a0e4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=1000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=50, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 31ms/step\n",
      "Accuracy: 74.4266676902771 %\n"
     ]
    }
   ],
   "source": [
    "batch_size = nlines # only one pattern...\n",
    "epochs = 1000\n",
    "history = model.fit([X,preY], postY,\n",
    "batch_size=batch_size,\n",
    "epochs=epochs,\n",
    "verbose=0,\n",
    "callbacks=[TQDMNotebookCallback()])\n",
    "print('Accuracy:',model.evaluate([X,preY],postY)[1]*100.0,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "# summarize history for accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# summarize history for loss\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - make the encoder\n",
    "# Make just a model out of the encoder\n",
    "# input = encoder_input (Input layer)\n",
    "# output = encoder_states (enc Hidden layer * 2)\n",
    "encoder_model = keras.Model(encoder_input, encoder_states)\n",
    "# Part 2 - make the decoder\n",
    "# Make just a model out of the decoder\n",
    "# input = encoder_states (enc Hidden layer * 2)\n",
    "# output = decoder_output\n",
    "decoder_state_input_h = keras.layers.Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = keras.layers.Input(shape=(hidden_size,))\n",
    "# Connect hidden to input(s)\n",
    "decoder_states_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = decoder_hidden(decoder_input,\n",
    "initial_state=decoder_states_input)\n",
    "decoder_states = [decoder_state_h, decoder_state_c]\n",
    "# Connect output to hidden(s)\n",
    "decoder_output = decoder_dense(decoder_hidden_output)\n",
    "decoder_model = keras.Model(\n",
    "[decoder_input] + decoder_states_input,\n",
    "[decoder_output] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the gestalt context for the input sequence(s)\n",
    "i = 0\n",
    "context = encoder_model.predict(X[i:i+1,:,:])\n",
    "# Prep a starting token...\n",
    "token = encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: It is a truth universally acknowledged, that a single man in possession\n",
      "Output: of a good fortune, must be in want of a wife.\n"
     ]
    }
   ],
   "source": [
    "# What should we see?\n",
    "print('Input:', text[i])\n",
    "print('Output:', text[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Txt: of a good fortune, must be in want of a wife.\n",
      "Net: of a good fortune, must be in want of a wife.\n",
      "Txt: However little known the feelings or views of such a man may be on his\n",
      "Net: However little known the feelings or views of such a man may be on his\n",
      "Txt: first entering a neighbourhood, this truth is so well fixed in the minds\n",
      "Net: first entering a neighbourhood, this truth is so well fixed in the minds\n",
      "Txt: of the surrounding families, that he is considered the rightful property\n",
      "Net: of the surrounding families, that he is considered the rightful property\n",
      "Txt: of some one or other of their daughters.\n",
      "Net: of some one or other of their daughters.\n",
      "Txt: \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that\n",
      "Net: \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that\n",
      "Txt: Netherfield Park is let at last?\"\n",
      "Net:  an eechad an  eresngl ougle my thi he\n",
      "Txt: Mr. Bennet replied that he had not.\n",
      "Net: Mr. Bennet replied that he had not.\n",
      "Txt: \"But it is,\" returned she; \"for Mrs. Long has just been here, and she\n",
      "Net: \"But it is,\" returned she; \"for Mrs. Long has just been here, and she\n",
      "Txt: told me all about it.\"\n",
      "Net: told me all about it.\"\n",
      "Txt: Mr. Bennet made no answer.\n",
      "Net: Mr. Bennet made no answer.\n",
      "Txt: \"Do you not want to know who has taken it?\" cried his wife impatiently.\n",
      "Net: \"o is orthnne haseand tht e Mir amyin on ee wime betth\n",
      "Txt: \"_You_ want to tell me, and I have no objection to hearing it.\"\n",
      "Net: \"_You_ want to tell me, and I have no objection to hearing it.\"\n",
      "Txt: This was invitation enough.\n",
      "Net: This was invitation enough.\n",
      "Txt: \"Why, my dear, you must know, Mrs. Long says that Netherfield is taken\n",
      "Net: \"Why, my dear, you must know, Mrs. Long says that Netherfield is taken\n",
      "Txt: by a young man of large fortune from the north of England; that he came\n",
      "Net: by a young man of large fortune from the north of England; that he came\n",
      "Txt: down on Monday in a chaise and four to see the place, and was so much\n",
      "Net: down on Monday in a chaise and four to see the place, and was so much\n",
      "Txt: delighted with it, that he agreed with Mr. Morris immediately; that he\n",
      "Net: delighted with it, that he agreed with Mr. Morris immediately; that he\n",
      "Txt: is to take possession before Michaelmas, and some of his servants are to\n",
      "Net: is to take possession before Michaelmas, and some of his servants are to\n",
      "Txt: be in the house by the end of next week.\"\n",
      "Net: be in the house by the end of next week.\"\n",
      "Txt: \"What is his name?\"\n",
      "Net: \"What is his name?\"\n",
      "Txt: \"Bingley.\"\n",
      "Net: \"Bingley.\"\n",
      "Txt: \"Is he married or single?\"\n",
      "Net: \"Is he married or single?\"\n",
      "Txt: \"Oh! Single, my dear, to be sure! A single man of large fortune; four or\n",
      "Net: \"Oh! Single, my dear, to be sure! A single man of large fortune; four or\n",
      "Txt: five thousand a year. What a fine thing for our girls!\"\n",
      "Net: five thousand a year. What a fine thing for our girls!\"\n",
      "Txt: \"How so? How can it affect them?\"\n",
      "Net: \"How so? How can it affect them?\"\n",
      "Txt: \"My dear Mr. Bennet,\" replied his wife, \"how can you be so tiresome! You\n",
      "Net: \"My dear Mr. Bennet,\" replied his wife, \"how can you be so tiresome! You\n",
      "Txt: must know that I am thinking of his marrying one of them.\"\n",
      "Net: t an o ah atin e thare ins bee io  sase t mmu\n",
      "Txt: \"Is that his design in settling here?\"\n",
      "Net: \"Is that his design in settling here?\"\n",
      "Txt: \"Design! Nonsense, how can you talk so! But it is very likely that he\n",
      "Net: \"Design! Nonsense, how can you talk so! But it is very likely that he\n",
      "Txt: _may_ fall in love with one of them, and therefore you must visit him as\n",
      "Net: _may_ fall in love with one of them, and therefore you must visit him as\n",
      "Txt: soon as he comes.\"\n",
      "Net: soon as he comes.\"\n",
      "Txt: \"I see no occasion for that. You and the girls may go, or you may send\n",
      "Net: \"I see no occasion for that. You and the girls may go, or you may send\n",
      "Txt: them by themselves, which perhaps will be still better, for as you are\n",
      "Net: them by themselves, which perhaps will be still better, for as you are\n",
      "Txt: as handsome as any of them, Mr. Bingley may like you the best of the\n",
      "Net: as handsome as any of them, Mr. Bingley may like you the best of the\n",
      "Txt: party.\"\n",
      "Net: party.\"\n",
      "Txt: \"My dear, you flatter me. I certainly _have_ had my share of beauty, but\n",
      "Net: \"My dear, you flatter me. I certainly _have_ had my share of beauty, but\n",
      "Txt: I do not pretend to be anything extraordinary now. When a woman has five\n",
      "Net: et an e achat a. Inertyou he sti  oe sandiserehe\n",
      "Txt: grown-up daughters, she ought to give over thinking of her own beauty.\"\n",
      "Net: grown-up daughters, she ought to give over thinking of her own beauty.\"\n",
      "Txt: \"In such cases, a woman has not often much beauty to think of.\"\n",
      "Net: \"In such cases, a woman has not often much beauty to think of.\"\n",
      "Txt: \"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "Net: \"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "Txt: the neighbourhood.\"\n",
      "Net: the neighbourhood.\"\n",
      "Txt: \"It is more than I engage for, I assure you.\"\n",
      "Net: \"It is more than I engage for, I assure you.\"\n",
      "Txt: \"But consider your daughters. Only think what an establishment it would\n",
      "Net: \"But consider your daughters. Only think what an establishment it would\n",
      "Txt: be for one of them. Sir William and Lady Lucas are determined to\n",
      "Net: be for one of them. Sir William and Lady Lucas are determined to\n",
      "Txt: go, merely on that account, for in general, you know, they visit no\n",
      "Net: go, merely on that account, for in general, you know, they visit no\n",
      "Txt: newcomers. Indeed you must go, for it will be impossible for _us_ to\n",
      "Net: newcomers. Indeed you must go, for it will be impossible for _us_ to\n",
      "Txt: visit him if you do not.\"\n",
      "Net: visit him if you do not.\"\n",
      "Txt: \"You are over-scrupulous, surely. I dare say Mr. Bingley will be very\n",
      "Net: \"You are over-scrupulous, surely. I dare say Mr. Bingley will be very\n",
      "Txt: glad to see you; and I will send a few lines by you to assure him of my\n",
      "Net: glad to see you; and I will send a few lines by you to assure him of my\n"
     ]
    }
   ],
   "source": [
    "# Iterate - teacher forcing through each line\n",
    "for i in range(0,nlines):\n",
    "    # Get the gestalt context for the input sequence(s)\n",
    "    context = encoder_model.predict(X[i:i+1,:,:])\n",
    "    # Prep a starting token...\n",
    "    token = encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    result = np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token = np.round(out)\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Txt: of a good fortune, must be in want of a wife.\n",
      "Net: of a good fortune, must be in want of a wife.\n",
      "Txt: However little known the feelings or views of such a man may be on his\n",
      "Net: Howerltt tken whee and sit hive ofre i  emut nnto\n",
      "Txt: first entering a neighbourhood, this truth is so well fixed in the minds\n",
      "Net: first entering a neighbourhood, this truth is so well fixed in the minds\n",
      "Txt: of the surrounding families, that he is considered the rightful property\n",
      "Net: of the surrounding families, that he is considered the rightful property\n",
      "Txt: of some one or other of their daughters.\n",
      "Net: of some one or other of their daughters.\n",
      "Txt: \"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that\n",
      "Net: go, mere on thet ickeonthttri hat le ine etile u\n",
      "Txt: Netherfield Park is let at last?\"\n",
      "Net: newcomers. Indeed you must go, for it will be impossible for _us_ to\n",
      "Txt: Mr. Bennet replied that he had not.\n",
      "Net: visit him if you do not.\"\n",
      "Txt: \"But it is,\" returned she; \"for Mrs. Long has just been here, and she\n",
      "Net: \"You are over-scrupoussurely. I dare yo  are ioy bute\n",
      "Txt: told me all about it.\"\n",
      "Net: glad to see you; and I will send a few lines by you to assure him of my\n",
      "Txt: Mr. Bennet made no answer.\n",
      "Net: ond a at es bowan tofonne t e.\"\n",
      "Txt: \"Do you not want to know who has taken it?\" cried his wife impatiently.\n",
      "Net: \"I sea  hoces on fo ha ntee  file bera, has ay uuhh \n",
      "Txt: \"_You_ want to tell me, and I have no objection to hearing it.\"\n",
      "Net: ma o e al o thing o intereitis beey of i surt iel r\n",
      "Txt: This was invitation enough.\n",
      "Net:  on oo  otote. forighaty i la sey bo hesove o\n",
      "Txt: \"Why, my dear, you must know, Mrs. Long says that Netherfield is taken\n",
      "Net: \"In such coes owhe an ot nke, of his bey ute, of re.\n",
      "Txt: by a young man of large fortune from the north of England; that he came\n",
      "Net: \"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "Txt: down on Monday in a chaise and four to see the place, and was so much\n",
      "Net: the neighbourhood.\"\n",
      "Txt: delighted with it, that he agreed with Mr. Morris immediately; that he\n",
      "Net: s make a os of ul  sa tingofrrou housryt in e ared o\n",
      "Txt: is to take possession before Michaelmas, and some of his servants are to\n",
      "Net:  thet ind teringhe argond ser o hea thae ar, oe\n",
      "Txt: be in the house by the end of next week.\"\n",
      "Net: r an eht ar i lingfrigerryou hio  out n\n",
      "Txt: \"What is his name?\"\n",
      "Net: r in te tiely to n hnge as a eersbout  oo fo o  aresof\n",
      "Txt: \"Bingley.\"\n",
      "Net: o thi huhoedin feid te he bt, fis e rittln\n",
      "Txt: \"Is he married or single?\"\n",
      "Net: s o a o  il an to e wefil i  f o aron \n",
      "Txt: \"Oh! Single, my dear, to be sure! A single man of large fortune; four or\n",
      "Net:  in te ount i biteind tareor urte. Mrin he wan e athine or\n",
      "Txt: five thousand a year. What a fine thing for our girls!\"\n",
      "Net: \"I that hs se ine betttll se reronge o sha  o asenf\n",
      "Txt: \"How so? How can it affect them?\"\n",
      "Net: go dat ie, s tking e Mrniy he are oon bet\n",
      "Txt: \"My dear Mr. Bennet,\" replied his wife, \"how can you be so tiresome! You\n",
      "Net:  in ous it on he forelng ereyoua syie a thak\n",
      "Txt: must know that I am thinking of his marrying one of them.\"\n",
      "Net: \"Is that hes seding n settlang there ust ri, \"have  oo sbe\n",
      "Txt: \"Is that his design in settling here?\"\n",
      "Net: ma go  ael o beuth. e siel ant a h\n",
      "Txt: \"Design! Nonsense, how can you talk so! But it is very likely that he\n",
      "Net: down on Monday in a chaise and four to see the place, and was so much\n",
      "Txt: _may_ fall in love with one of them, and therefore you must visit him as\n",
      "Net: delighted with it, that he agreed with Mr. Morris immediately; that he\n",
      "Txt: soon as he comes.\"\n",
      "Net: is to take possession before Michaelmas, and some of his servants are to\n",
      "Txt: \"I see no occasion for that. You and the girls may go, or you may send\n",
      "Net: be in the house by the end of next week.\"\n",
      "Txt: them by themselves, which perhaps will be still better, for as you are\n",
      "Net: \"t  he anee nbeth o his nnt ee oo  asur o erito\n",
      "Txt: as handsome as any of them, Mr. Bingley may like you the best of the\n",
      "Net:  ou has tee ime ha now fo  hemscind the iil  stin, of ur ir\n",
      "Txt: party.\"\n",
      "Net: gwnou daa yy us chatind an da noer teelamsbst\n",
      "Txt: \"My dear, you flatter me. I certainly _have_ had my share of beauty, but\n",
      "Net: \"In such cases, a woman has not often much beauty to think of.\"\n",
      "Txt: I do not pretend to be anything extraordinary now. When a woman has five\n",
      "Net: \"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "Txt: grown-up daughters, she ought to give over thinking of her own beauty.\"\n",
      "Net: the neighbourhood.\"\n",
      "Txt: \"In such cases, a woman has not often much beauty to think of.\"\n",
      "Net: s make a os of ul  sa tingofrrou housryt in e ared o\n",
      "Txt: \"But, my dear, you must indeed go and see Mr. Bingley when he comes into\n",
      "Net:  thet ind teringhe argond ser o hea thae ar, oe\n",
      "Txt: the neighbourhood.\"\n",
      "Net: r an eht ar i lingfrigerryou hio  out n\n",
      "Txt: \"It is more than I engage for, I assure you.\"\n",
      "Net: r in te tiely to n hnge as a eersbout  oo fo o  aresof\n",
      "Txt: \"But consider your daughters. Only think what an establishment it would\n",
      "Net: o thi huhoedin feid te he bt, fis e rittln\n",
      "Txt: be for one of them. Sir William and Lady Lucas are determined to\n",
      "Net: s o a o  il an to e wefil i  f o aron \n",
      "Txt: go, merely on that account, for in general, you know, they visit no\n",
      "Net:  in te ount i biteind tareor urte. Mrin he wan e athine or\n",
      "Txt: newcomers. Indeed you must go, for it will be impossible for _us_ to\n",
      "Net: \"I that hs se ine betttll se reronge o sha  o asenf\n",
      "Txt: visit him if you do not.\"\n",
      "Net: go dat ie, s tking e Mrniy he are oon bet\n",
      "Txt: \"You are over-scrupulous, surely. I dare say Mr. Bingley will be very\n",
      "Net:  in ous it on he forelng ereyoua syie a thak\n",
      "Txt: glad to see you; and I will send a few lines by you to assure him of my\n",
      "Net: \"Is that hes seding n settlang there ust ri, \"have  oo sbe\n"
     ]
    }
   ],
   "source": [
    "# Iterate - but no teaching forcing past first line...\n",
    "# Get the gestalt context for the input sequence\n",
    "i = 0\n",
    "context = encoder_model.predict(X[i:i+1,:,:])\n",
    "for i in range(0,nlines):\n",
    "    # Prep a starting token...\n",
    "    token = encode_seq('',stoi)[0].reshape(1,1,len(stoi))\n",
    "    result = np.zeros([1,postY.shape[1],postY.shape[2]])\n",
    "    for x in range(postY.shape[1]):\n",
    "        out,h,c = decoder_model.predict([token]+context)\n",
    "        token = np.round(out)\n",
    "        context = [h,c]\n",
    "        result[:,x,:] = token\n",
    "    print('Txt:',text[i+1])\n",
    "    print('Net:',decode_seq(result[0,:,:],itos))\n",
    "    # CRUCIAL -> keep predicted result instead of teacher forcing!\n",
    "    context = encoder_model.predict(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem 2 </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# Visualization\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing - grab lines from the file\n",
    "with open('/nfshome/sandbox/gutenberg_example/PandP_Jane_Austen.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "words = []\n",
    "for i in range(len(lines)):\n",
    "    if lines[i] != '':\n",
    "        words = lines[i].split()\n",
    "        text = text + words\n",
    "# Paragraphs are separated by blank\n",
    "# lines -> just drop those lines...\n",
    "#text = []\n",
    "#for i in range(len(lines)):\n",
    " #   if lines[i] != '':\n",
    "  #      text = text + [lines[i]]\n",
    "min_length = max([len(i) for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364317"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(i) for i in text)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique characters - precalculated\n",
    "with open('/nfshome/sandbox/gutenberg_example/unique_chars.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split()\n",
    "# Integer code to symbol\n",
    "itos = ['','',' ']\n",
    "for i in lines:\n",
    "    itos = itos + [i]\n",
    "# Symbol to integer code\n",
    "stoi = dict()\n",
    "stoi['STOP'] = 0\n",
    "stoi['START'] = 1\n",
    "for i in range(2,len(itos)):\n",
    "    stoi[itos[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(x,mapping,min_length=0):\n",
    "    # String to one-hot\n",
    "    y = [mapping['START']]\n",
    "    for i in list(x):\n",
    "        y = y + [mapping[i]]\n",
    "    y = y + [mapping['STOP']]\n",
    "    # Stop-padding - handled elsewhere...\n",
    "    while len(y) < min_length:\n",
    "        y = y + [mapping['STOP']]\n",
    "    return keras.utils.to_categorical(y,len(mapping))\n",
    "def decode_seq(x,mapping):\n",
    "    # One-hot to string\n",
    "    y = []\n",
    "    for i in x:\n",
    "        y = y + [mapping[np.argmax(i)]]\n",
    "    return ''.join(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An ecoding-decoding cycle on the first line...\n",
    "temp = encode_seq(text[0],stoi)\n",
    "temp = decode_seq(temp,itos)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode that data\n",
    "dataX = np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "for i in range(len(text)):\n",
    "    temp = encode_seq(text[i],stoi)\n",
    "    dataX[i,0:len(temp),:] = temp\n",
    "# Not strictly necessary, but I was trying some alternative strategies\n",
    "# earlier and this is worth keeping around...\n",
    "# This will be the same as dataX using this implementation...\n",
    "dataY = np.ones([len(text),max([len(i) for i in text])+2,len(itos)])*(1.0/len(itos))\n",
    "for i in range(len(text)):\n",
    "    temp = encode_seq(text[i],stoi)\n",
    "    dataY[i,0:len(temp),:] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataX[0:dataX.shape[0]-1,:,:]\n",
    "Y = dataY[1:dataY.shape[0],:,:]\n",
    "preY = Y[:,0:Y.shape[1]-1,:]\n",
    "postY = Y[:,1:Y.shape[1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30, 71)\n",
      "(500, 30, 71)\n",
      "(500, 29, 71)\n",
      "(500, 29, 71)\n"
     ]
    }
   ],
   "source": [
    "nlines = 500\n",
    "X = X[0:nlines,:,:]\n",
    "Y = Y[0:nlines,:,:]\n",
    "preY = preY[0:nlines,:,:]\n",
    "postY = postY[0:nlines,:,:]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(preY.shape)\n",
    "print(postY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Initializer for variable lstm_27/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7b84968aaa28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tie the hidden layer to the input layer (passed in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state_c\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# We discard `encoder_outputs` and only keep the states.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menc_state_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_state_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# set or validate state_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                                       \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m   1869\u001b[0m         self.recurrent_kernel = self.add_weight(\n\u001b[1;32m   1870\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                      aggregation=VariableAggregation.NONE):\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2439\u001b[0m         \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2441\u001b[0;31m         expected_shape=expected_shape, import_scope=import_scope)\n\u001b[0m\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[1;32m   1102\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                 \"initializer.\" % name)\n\u001b[0m\u001b[1;32m   1232\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m           shape = (self._initial_value.get_shape()\n",
      "\u001b[0;31mValueError\u001b[0m: Initializer for variable lstm_27/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
     ]
    }
   ],
   "source": [
    "hidden_size = X.shape[1]*3\n",
    "encoder_input = keras.layers.Input(shape=(None, X.shape[2]))\n",
    "encoder_hidden = keras.layers.LSTM(hidden_size, return_state=True)\n",
    "# Tie the hidden layer to the input layer (passed in)\n",
    "encoder_output, enc_state_h, enc_state_c =  encoder_hidden(encoder_input)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [enc_state_h, enc_state_c]\n",
    "## Decoder Construction\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_input = keras.layers.Input(shape=(None, preY.shape[2]))\n",
    "decoder_hidden = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "# Connect hidden to input (also reads from the encoder...)\n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = decoder_hidden(decoder_input,\n",
    "initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(postY.shape[2], activation='softmax')\n",
    "# Connect output to hidden\n",
    "decoder_output = decoder_dense(decoder_hidden_output)\n",
    "# 2 input layers and an output layer...\n",
    "# 1. Targets are postY\n",
    "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "optimizer=keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# it had an error that I couldn't save encoder_output since it was in a loop or conditional.\n",
    "# Initializer for variable lstm_27/kernel/ is from inside a control-flow construct, such as a loop or conditional.\n",
    "# When creating a variable inside a loop or conditional, use a lambda as the initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
