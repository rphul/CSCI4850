{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Richa Phulwani - OLA 3 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem 1 </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pandas.read_table(\"https://www.cs.mtsu.edu/~jphillips/courses/CSCI4850-5850/public/iris-data.txt\",delim_whitespace=True,header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:,0:4]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "Y = keras.utils.to_categorical(labels,len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "output_size = Y.shape[1]\n",
    "model.add(keras.layers.Dense(output_size,activation='sigmoid',input_shape=[input_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mse,optimizer=keras.optimizers.SGD(lr=0.05),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13795485, 0.85699797, 0.98908967],\n",
       "       [0.16526714, 0.9370867 , 0.99618995],\n",
       "       [0.15023924, 0.9365326 , 0.9980842 ],\n",
       "       [0.13749689, 0.90146786, 0.9904456 ],\n",
       "       [0.0753902 , 0.7893428 , 0.9577341 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8323812,  1.7905769,  4.5070753],\n",
       "       [-1.6195486,  2.7010183,  5.5663147],\n",
       "       [-1.7327259,  2.691658 ,  6.255683 ],\n",
       "       [-1.8362374,  2.2136414,  4.641162 ],\n",
       "       [-2.5066946,  1.3209687,  3.1205895]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer_neti = np.dot(np.float32(X[0:5,:]),model.get_weights()[0])+model.get_weights()[1]\n",
    "output_layer_neti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13795485, 0.85699797, 0.98908967],\n",
       "       [0.16526714, 0.9370867 , 0.99618995],\n",
       "       [0.15023924, 0.9365326 , 0.9980842 ],\n",
       "       [0.13749689, 0.90146786, 0.9904456 ],\n",
       "       [0.0753902 , 0.7893428 , 0.9577341 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / (1.0 + np.exp(-1.0 * output_layer_neti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40939122 -0.46344644  0.45063925]\n",
      " [-0.21908915  0.7463629   0.02760482]\n",
      " [ 0.06977051  0.5093701   0.56956613]\n",
      " [ 0.7179365   0.39736927 -0.33539432]]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()[0]\n",
    "bias_weights = model.get_weights()[1]\n",
    "print(weights)\n",
    "print(bias_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8323812,  1.7905769,  4.5070753]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_neti = np.dot(np.float32(X[0:1]),weights)+bias_weights\n",
    "output_neti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13795485, 0.85699797, 0.98908967]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_acts = 1.0 / (1.0 + np.exp(-output_neti))\n",
    "output_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13795485, 0.85699797, 0.98908967]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13795485, -0.14300203,  0.98908967]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = output_acts - np.float32(Y[0:1])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23784661, 0.24510483, 0.02158258]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv = 2.0 * np.exp(-output_neti) / np.power(1.0+np.exp(-output_neti),2.0)\n",
    "deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01093736, -0.0116835 ,  0.0071157 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas = error*deriv*(1.0/len(bias_weights))\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06343672, -0.06776428,  0.04127108],\n",
       "       [ 0.02953088, -0.03154544,  0.0192124 ],\n",
       "       [ 0.04265573, -0.04556564,  0.02775124],\n",
       "       [ 0.01312484, -0.0140202 ,  0.00853884]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_updates = np.outer(np.float32(X[0:1]),deltas)\n",
    "w_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06343672, -0.06776428,  0.04127108],\n",
       "       [ 0.02953088, -0.03154544,  0.0192124 ],\n",
       "       [ 0.04265573, -0.04556564,  0.02775124],\n",
       "       [ 0.01312484, -0.0140202 ,  0.00853884]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_updates = np.outer(np.float32(X[0:1]),deltas)\n",
    "w_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40939122, -0.46344644,  0.45063925],\n",
       "       [-0.21908915,  0.7463629 ,  0.02760482],\n",
       "       [ 0.06977051,  0.5093701 ,  0.56956613],\n",
       "       [ 0.7179365 ,  0.39736927, -0.33539432]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = np.float32(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40945467, -0.46337867,  0.45059797],\n",
       "       [-0.21911868,  0.74639446,  0.02758561],\n",
       "       [ 0.06972786,  0.5094156 ,  0.56953835],\n",
       "       [ 0.7179234 ,  0.39738327, -0.33540288]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights - eta*w_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0937365e-05,  1.1683497e-05, -7.1157028e-06]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_weights - eta*deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.41256306, -0.4600582 ,  0.4485757 ],\n",
       "        [-0.22056569,  0.7479402 ,  0.0266442 ],\n",
       "        [ 0.06763773,  0.51164836,  0.5681786 ],\n",
       "        [ 0.71728027,  0.39807028, -0.33582127]], dtype=float32),\n",
       " array([-0.00054687,  0.00058418, -0.00035579], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X[0:1],Y[0:1],batch_size=1,epochs=1,verbose=0)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4745 - acc: 0.3333 - val_loss: 0.4437 - val_acc: 0.3333\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 738us/step - loss: 0.4485 - acc: 0.3333 - val_loss: 0.4155 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 382us/step - loss: 0.4194 - acc: 0.3333 - val_loss: 0.3922 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 615us/step - loss: 0.3964 - acc: 0.3333 - val_loss: 0.3795 - val_acc: 0.3333\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 605us/step - loss: 0.3825 - acc: 0.3333 - val_loss: 0.3723 - val_acc: 0.3333\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 409us/step - loss: 0.3729 - acc: 0.3333 - val_loss: 0.3651 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 453us/step - loss: 0.3633 - acc: 0.3333 - val_loss: 0.3546 - val_acc: 0.3333\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 427us/step - loss: 0.3488 - acc: 0.3333 - val_loss: 0.3382 - val_acc: 0.3333\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 277us/step - loss: 0.3273 - acc: 0.3333 - val_loss: 0.3114 - val_acc: 0.3333\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 378us/step - loss: 0.2949 - acc: 0.3333 - val_loss: 0.2758 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 355us/step - loss: 0.2609 - acc: 0.3333 - val_loss: 0.2504 - val_acc: 0.3333\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 821us/step - loss: 0.2435 - acc: 0.3333 - val_loss: 0.2395 - val_acc: 0.3333\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 527us/step - loss: 0.2373 - acc: 0.2933 - val_loss: 0.2367 - val_acc: 0.3333\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 318us/step - loss: 0.2353 - acc: 0.3333 - val_loss: 0.2326 - val_acc: 0.3067\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 448us/step - loss: 0.2322 - acc: 0.2933 - val_loss: 0.2312 - val_acc: 0.3200\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 340us/step - loss: 0.2301 - acc: 0.2800 - val_loss: 0.2299 - val_acc: 0.3200\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 330us/step - loss: 0.2282 - acc: 0.2933 - val_loss: 0.2289 - val_acc: 0.3333\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 314us/step - loss: 0.2259 - acc: 0.2933 - val_loss: 0.2270 - val_acc: 0.3333\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 378us/step - loss: 0.2244 - acc: 0.2667 - val_loss: 0.2260 - val_acc: 0.3333\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 348us/step - loss: 0.2226 - acc: 0.2933 - val_loss: 0.2244 - val_acc: 0.3333\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 327us/step - loss: 0.2240 - acc: 0.2800 - val_loss: 0.2237 - val_acc: 0.3333\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 321us/step - loss: 0.2192 - acc: 0.3333 - val_loss: 0.2208 - val_acc: 0.3333\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 328us/step - loss: 0.2172 - acc: 0.3067 - val_loss: 0.2181 - val_acc: 0.3333\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 327us/step - loss: 0.2144 - acc: 0.3067 - val_loss: 0.2159 - val_acc: 0.3200\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 361us/step - loss: 0.2123 - acc: 0.2933 - val_loss: 0.2138 - val_acc: 0.3600\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 358us/step - loss: 0.2101 - acc: 0.3467 - val_loss: 0.2120 - val_acc: 0.4267\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 308us/step - loss: 0.2100 - acc: 0.4000 - val_loss: 0.2101 - val_acc: 0.5067\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 308us/step - loss: 0.2066 - acc: 0.4133 - val_loss: 0.2079 - val_acc: 0.5867\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 320us/step - loss: 0.2042 - acc: 0.6133 - val_loss: 0.2056 - val_acc: 0.6267\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 616us/step - loss: 0.2004 - acc: 0.6400 - val_loss: 0.2034 - val_acc: 0.6267\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 500us/step - loss: 0.1979 - acc: 0.6667 - val_loss: 0.2012 - val_acc: 0.6267\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 396us/step - loss: 0.1952 - acc: 0.6400 - val_loss: 0.1994 - val_acc: 0.6533\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 352us/step - loss: 0.1935 - acc: 0.6667 - val_loss: 0.1971 - val_acc: 0.6533\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 516us/step - loss: 0.1900 - acc: 0.6533 - val_loss: 0.1949 - val_acc: 0.6533\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 494us/step - loss: 0.1877 - acc: 0.6800 - val_loss: 0.1924 - val_acc: 0.6533\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 653us/step - loss: 0.1854 - acc: 0.6800 - val_loss: 0.1899 - val_acc: 0.6667\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 320us/step - loss: 0.1830 - acc: 0.6400 - val_loss: 0.1879 - val_acc: 0.6533\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 431us/step - loss: 0.1804 - acc: 0.6533 - val_loss: 0.1859 - val_acc: 0.6533\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 396us/step - loss: 0.1800 - acc: 0.6533 - val_loss: 0.1841 - val_acc: 0.6533\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 297us/step - loss: 0.1761 - acc: 0.6667 - val_loss: 0.1829 - val_acc: 0.6533\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 481us/step - loss: 0.1742 - acc: 0.6800 - val_loss: 0.1806 - val_acc: 0.6533\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 292us/step - loss: 0.1716 - acc: 0.6800 - val_loss: 0.1788 - val_acc: 0.6533\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 278us/step - loss: 0.1691 - acc: 0.6800 - val_loss: 0.1769 - val_acc: 0.6533\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 263us/step - loss: 0.1673 - acc: 0.6533 - val_loss: 0.1757 - val_acc: 0.6533\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 341us/step - loss: 0.1657 - acc: 0.6667 - val_loss: 0.1743 - val_acc: 0.6533\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 555us/step - loss: 0.1641 - acc: 0.6800 - val_loss: 0.1728 - val_acc: 0.6533\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 926us/step - loss: 0.1630 - acc: 0.6800 - val_loss: 0.1709 - val_acc: 0.6533\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 503us/step - loss: 0.1599 - acc: 0.6800 - val_loss: 0.1693 - val_acc: 0.6533\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 721us/step - loss: 0.1597 - acc: 0.6800 - val_loss: 0.1672 - val_acc: 0.6533\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 364us/step - loss: 0.1570 - acc: 0.6800 - val_loss: 0.1659 - val_acc: 0.6533\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 454us/step - loss: 0.1555 - acc: 0.6800 - val_loss: 0.1645 - val_acc: 0.6533\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 705us/step - loss: 0.1544 - acc: 0.6800 - val_loss: 0.1628 - val_acc: 0.6533\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 553us/step - loss: 0.1534 - acc: 0.6800 - val_loss: 0.1617 - val_acc: 0.6533\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 322us/step - loss: 0.1512 - acc: 0.6800 - val_loss: 0.1611 - val_acc: 0.6533\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.1498 - acc: 0.6800 - val_loss: 0.1594 - val_acc: 0.6533\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.1489 - acc: 0.6800 - val_loss: 0.1589 - val_acc: 0.6533\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.1479 - acc: 0.6800 - val_loss: 0.1577 - val_acc: 0.6533\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 260us/step - loss: 0.1467 - acc: 0.6800 - val_loss: 0.1563 - val_acc: 0.6533\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 250us/step - loss: 0.1458 - acc: 0.6800 - val_loss: 0.1559 - val_acc: 0.6533\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 354us/step - loss: 0.1443 - acc: 0.6800 - val_loss: 0.1548 - val_acc: 0.6533\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 322us/step - loss: 0.1432 - acc: 0.6800 - val_loss: 0.1540 - val_acc: 0.6533\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 314us/step - loss: 0.1425 - acc: 0.6800 - val_loss: 0.1527 - val_acc: 0.6533\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.1415 - acc: 0.6800 - val_loss: 0.1517 - val_acc: 0.6533\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 271us/step - loss: 0.1414 - acc: 0.6667 - val_loss: 0.1511 - val_acc: 0.6533\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 243us/step - loss: 0.1395 - acc: 0.6800 - val_loss: 0.1505 - val_acc: 0.6533\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 351us/step - loss: 0.1390 - acc: 0.6800 - val_loss: 0.1495 - val_acc: 0.6533\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 325us/step - loss: 0.1386 - acc: 0.6800 - val_loss: 0.1485 - val_acc: 0.6533\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 382us/step - loss: 0.1378 - acc: 0.6800 - val_loss: 0.1478 - val_acc: 0.6533\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 224us/step - loss: 0.1366 - acc: 0.6933 - val_loss: 0.1477 - val_acc: 0.6533\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 237us/step - loss: 0.1360 - acc: 0.6933 - val_loss: 0.1472 - val_acc: 0.6533\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 237us/step - loss: 0.1353 - acc: 0.6933 - val_loss: 0.1472 - val_acc: 0.6533\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 240us/step - loss: 0.1348 - acc: 0.6800 - val_loss: 0.1459 - val_acc: 0.6533\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.1343 - acc: 0.6800 - val_loss: 0.1455 - val_acc: 0.6533\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.1331 - acc: 0.6800 - val_loss: 0.1447 - val_acc: 0.6533\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 220us/step - loss: 0.1329 - acc: 0.6800 - val_loss: 0.1437 - val_acc: 0.6533\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.1328 - acc: 0.6800 - val_loss: 0.1438 - val_acc: 0.6533\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 219us/step - loss: 0.1325 - acc: 0.6800 - val_loss: 0.1428 - val_acc: 0.6533\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 237us/step - loss: 0.1311 - acc: 0.6800 - val_loss: 0.1422 - val_acc: 0.6533\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 281us/step - loss: 0.1312 - acc: 0.6933 - val_loss: 0.1421 - val_acc: 0.6533\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.1301 - acc: 0.6800 - val_loss: 0.1421 - val_acc: 0.6533\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 206us/step - loss: 0.1297 - acc: 0.6800 - val_loss: 0.1414 - val_acc: 0.6533\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.1293 - acc: 0.6800 - val_loss: 0.1410 - val_acc: 0.6533\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.1283 - acc: 0.6800 - val_loss: 0.1407 - val_acc: 0.6533\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.1283 - acc: 0.6800 - val_loss: 0.1400 - val_acc: 0.6533\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.1280 - acc: 0.6800 - val_loss: 0.1395 - val_acc: 0.6533\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.1278 - acc: 0.6800 - val_loss: 0.1393 - val_acc: 0.6533\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 248us/step - loss: 0.1282 - acc: 0.6933 - val_loss: 0.1396 - val_acc: 0.6533\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 225us/step - loss: 0.1267 - acc: 0.6800 - val_loss: 0.1390 - val_acc: 0.6533\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 337us/step - loss: 0.1258 - acc: 0.6800 - val_loss: 0.1387 - val_acc: 0.6533\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 237us/step - loss: 0.1255 - acc: 0.6800 - val_loss: 0.1384 - val_acc: 0.6533\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 241us/step - loss: 0.1252 - acc: 0.6800 - val_loss: 0.1379 - val_acc: 0.6533\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.1252 - acc: 0.6800 - val_loss: 0.1369 - val_acc: 0.6533\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 362us/step - loss: 0.1250 - acc: 0.6800 - val_loss: 0.1363 - val_acc: 0.6533\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.1245 - acc: 0.6933 - val_loss: 0.1361 - val_acc: 0.6533\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.1241 - acc: 0.6800 - val_loss: 0.1361 - val_acc: 0.6533\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 209us/step - loss: 0.1232 - acc: 0.6800 - val_loss: 0.1359 - val_acc: 0.6533\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.1231 - acc: 0.6800 - val_loss: 0.1364 - val_acc: 0.6533\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 227us/step - loss: 0.1248 - acc: 0.6933 - val_loss: 0.1358 - val_acc: 0.6533\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 298us/step - loss: 0.1225 - acc: 0.6800 - val_loss: 0.1356 - val_acc: 0.6533\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 888us/step - loss: 0.1218 - acc: 0.6800 - val_loss: 0.1350 - val_acc: 0.6533\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 453us/step - loss: 0.1167 - acc: 0.7143 - val_loss: 0.1585 - val_acc: 0.5556\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 348us/step - loss: 0.1163 - acc: 0.7143 - val_loss: 0.1572 - val_acc: 0.5556\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 206us/step - loss: 0.1161 - acc: 0.7143 - val_loss: 0.1559 - val_acc: 0.5556\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 244us/step - loss: 0.1155 - acc: 0.7143 - val_loss: 0.1544 - val_acc: 0.5556\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 452us/step - loss: 0.1154 - acc: 0.7238 - val_loss: 0.1566 - val_acc: 0.5556\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 231us/step - loss: 0.1153 - acc: 0.7143 - val_loss: 0.1551 - val_acc: 0.5556\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 248us/step - loss: 0.1145 - acc: 0.7143 - val_loss: 0.1550 - val_acc: 0.5556\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 367us/step - loss: 0.1146 - acc: 0.7143 - val_loss: 0.1531 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.1141 - acc: 0.7143 - val_loss: 0.1561 - val_acc: 0.5556\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 468us/step - loss: 0.1134 - acc: 0.7143 - val_loss: 0.1545 - val_acc: 0.5556\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 189us/step - loss: 0.1138 - acc: 0.7143 - val_loss: 0.1541 - val_acc: 0.5556\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 167us/step - loss: 0.1125 - acc: 0.7143 - val_loss: 0.1558 - val_acc: 0.5556\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.1121 - acc: 0.7143 - val_loss: 0.1539 - val_acc: 0.5556\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.1121 - acc: 0.7143 - val_loss: 0.1510 - val_acc: 0.5556\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 206us/step - loss: 0.1115 - acc: 0.7143 - val_loss: 0.1529 - val_acc: 0.5556\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 214us/step - loss: 0.1115 - acc: 0.7143 - val_loss: 0.1534 - val_acc: 0.5556\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 164us/step - loss: 0.1117 - acc: 0.7143 - val_loss: 0.1518 - val_acc: 0.5556\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 178us/step - loss: 0.1108 - acc: 0.7143 - val_loss: 0.1528 - val_acc: 0.5556\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.1110 - acc: 0.7143 - val_loss: 0.1509 - val_acc: 0.5556\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.1103 - acc: 0.7143 - val_loss: 0.1520 - val_acc: 0.5556\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 156us/step - loss: 0.1101 - acc: 0.7143 - val_loss: 0.1519 - val_acc: 0.5556\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 166us/step - loss: 0.1098 - acc: 0.7143 - val_loss: 0.1516 - val_acc: 0.5556\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 159us/step - loss: 0.1097 - acc: 0.7143 - val_loss: 0.1490 - val_acc: 0.5556\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 178us/step - loss: 0.1091 - acc: 0.7143 - val_loss: 0.1509 - val_acc: 0.5556\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 192us/step - loss: 0.1091 - acc: 0.7143 - val_loss: 0.1495 - val_acc: 0.5556\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1089 - acc: 0.7143 - val_loss: 0.1486 - val_acc: 0.5556\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.1096 - acc: 0.7143 - val_loss: 0.1498 - val_acc: 0.5556\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 156us/step - loss: 0.1090 - acc: 0.7238 - val_loss: 0.1510 - val_acc: 0.5556\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1080 - acc: 0.7143 - val_loss: 0.1501 - val_acc: 0.5556\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 168us/step - loss: 0.1078 - acc: 0.7143 - val_loss: 0.1492 - val_acc: 0.5556\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 198us/step - loss: 0.1083 - acc: 0.7143 - val_loss: 0.1476 - val_acc: 0.5556\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 195us/step - loss: 0.1083 - acc: 0.7143 - val_loss: 0.1473 - val_acc: 0.5556\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 153us/step - loss: 0.1073 - acc: 0.7143 - val_loss: 0.1476 - val_acc: 0.5556\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 167us/step - loss: 0.1082 - acc: 0.7238 - val_loss: 0.1491 - val_acc: 0.5556\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 176us/step - loss: 0.1068 - acc: 0.7143 - val_loss: 0.1509 - val_acc: 0.5556\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 156us/step - loss: 0.1068 - acc: 0.7143 - val_loss: 0.1485 - val_acc: 0.5556\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 155us/step - loss: 0.1067 - acc: 0.7143 - val_loss: 0.1497 - val_acc: 0.5556\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.1064 - acc: 0.7143 - val_loss: 0.1515 - val_acc: 0.5556\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1061 - acc: 0.7143 - val_loss: 0.1483 - val_acc: 0.5556\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1060 - acc: 0.7143 - val_loss: 0.1499 - val_acc: 0.5556\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1057 - acc: 0.7143 - val_loss: 0.1484 - val_acc: 0.5556\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 183us/step - loss: 0.1058 - acc: 0.7143 - val_loss: 0.1490 - val_acc: 0.5556\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 176us/step - loss: 0.1058 - acc: 0.7143 - val_loss: 0.1484 - val_acc: 0.5556\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 151us/step - loss: 0.1053 - acc: 0.7143 - val_loss: 0.1455 - val_acc: 0.5556\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1054 - acc: 0.7238 - val_loss: 0.1468 - val_acc: 0.5556\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 167us/step - loss: 0.1051 - acc: 0.7238 - val_loss: 0.1453 - val_acc: 0.5556\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.1045 - acc: 0.7143 - val_loss: 0.1466 - val_acc: 0.5556\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 158us/step - loss: 0.1043 - acc: 0.7143 - val_loss: 0.1468 - val_acc: 0.5556\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.1042 - acc: 0.7143 - val_loss: 0.1469 - val_acc: 0.5556\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 317us/step - loss: 0.1040 - acc: 0.7143 - val_loss: 0.1461 - val_acc: 0.5556\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 201us/step - loss: 0.1046 - acc: 0.7143 - val_loss: 0.1438 - val_acc: 0.5556\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.1035 - acc: 0.7238 - val_loss: 0.1434 - val_acc: 0.5556\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 184us/step - loss: 0.1036 - acc: 0.7143 - val_loss: 0.1454 - val_acc: 0.5556\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.1037 - acc: 0.7143 - val_loss: 0.1450 - val_acc: 0.5556\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 192us/step - loss: 0.1044 - acc: 0.7143 - val_loss: 0.1445 - val_acc: 0.5556\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 168us/step - loss: 0.1033 - acc: 0.7143 - val_loss: 0.1445 - val_acc: 0.5556\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 186us/step - loss: 0.1038 - acc: 0.7143 - val_loss: 0.1423 - val_acc: 0.5556\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 177us/step - loss: 0.1029 - acc: 0.7143 - val_loss: 0.1426 - val_acc: 0.5556\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 188us/step - loss: 0.1027 - acc: 0.7238 - val_loss: 0.1427 - val_acc: 0.5556\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.1028 - acc: 0.7238 - val_loss: 0.1438 - val_acc: 0.5556\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1023 - acc: 0.7143 - val_loss: 0.1441 - val_acc: 0.5556\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 187us/step - loss: 0.1023 - acc: 0.7238 - val_loss: 0.1432 - val_acc: 0.5556\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 144us/step - loss: 0.1019 - acc: 0.7238 - val_loss: 0.1438 - val_acc: 0.5556\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 157us/step - loss: 0.1022 - acc: 0.7143 - val_loss: 0.1407 - val_acc: 0.5556\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 174us/step - loss: 0.1020 - acc: 0.7238 - val_loss: 0.1413 - val_acc: 0.5556\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 173us/step - loss: 0.1022 - acc: 0.7238 - val_loss: 0.1434 - val_acc: 0.5556\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.1017 - acc: 0.7238 - val_loss: 0.1447 - val_acc: 0.5556\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 163us/step - loss: 0.1014 - acc: 0.7143 - val_loss: 0.1443 - val_acc: 0.5556\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 175us/step - loss: 0.1016 - acc: 0.7143 - val_loss: 0.1428 - val_acc: 0.5556\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.1012 - acc: 0.7143 - val_loss: 0.1425 - val_acc: 0.5556\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 178us/step - loss: 0.1010 - acc: 0.7238 - val_loss: 0.1433 - val_acc: 0.5556\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 167us/step - loss: 0.1009 - acc: 0.7143 - val_loss: 0.1425 - val_acc: 0.5556\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 164us/step - loss: 0.1006 - acc: 0.7238 - val_loss: 0.1405 - val_acc: 0.5556\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 170us/step - loss: 0.1012 - acc: 0.7238 - val_loss: 0.1420 - val_acc: 0.5556\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 207us/step - loss: 0.1003 - acc: 0.7238 - val_loss: 0.1418 - val_acc: 0.5556\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 185us/step - loss: 0.1008 - acc: 0.7143 - val_loss: 0.1403 - val_acc: 0.5556\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 211us/step - loss: 0.1004 - acc: 0.7143 - val_loss: 0.1386 - val_acc: 0.5556\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1004 - acc: 0.7429 - val_loss: 0.1416 - val_acc: 0.5556\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 538us/step - loss: 0.1007 - acc: 0.7143 - val_loss: 0.1396 - val_acc: 0.5556\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 179us/step - loss: 0.1002 - acc: 0.7238 - val_loss: 0.1416 - val_acc: 0.5556\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 146us/step - loss: 0.0997 - acc: 0.7238 - val_loss: 0.1413 - val_acc: 0.5556\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 205us/step - loss: 0.1002 - acc: 0.7238 - val_loss: 0.1423 - val_acc: 0.5556\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.1004 - acc: 0.7238 - val_loss: 0.1395 - val_acc: 0.5556\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 192us/step - loss: 0.0995 - acc: 0.7238 - val_loss: 0.1415 - val_acc: 0.5556\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 409us/step - loss: 0.0992 - acc: 0.7238 - val_loss: 0.1406 - val_acc: 0.5556\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.0990 - acc: 0.7238 - val_loss: 0.1394 - val_acc: 0.5556\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 170us/step - loss: 0.0997 - acc: 0.7238 - val_loss: 0.1397 - val_acc: 0.5556\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 262us/step - loss: 0.0987 - acc: 0.7238 - val_loss: 0.1406 - val_acc: 0.5556\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 160us/step - loss: 0.0990 - acc: 0.7238 - val_loss: 0.1390 - val_acc: 0.5556\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 149us/step - loss: 0.0988 - acc: 0.7238 - val_loss: 0.1398 - val_acc: 0.5556\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 165us/step - loss: 0.0986 - acc: 0.7333 - val_loss: 0.1408 - val_acc: 0.5556\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.0986 - acc: 0.7238 - val_loss: 0.1397 - val_acc: 0.5556\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.0984 - acc: 0.7238 - val_loss: 0.1391 - val_acc: 0.5556\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 189us/step - loss: 0.0987 - acc: 0.7238 - val_loss: 0.1386 - val_acc: 0.5556\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.0980 - acc: 0.7238 - val_loss: 0.1388 - val_acc: 0.5556\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 145us/step - loss: 0.0981 - acc: 0.7238 - val_loss: 0.1394 - val_acc: 0.5556\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 147us/step - loss: 0.0982 - acc: 0.7238 - val_loss: 0.1380 - val_acc: 0.5556\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0980 - acc: 0.7238 - val_loss: 0.1382 - val_acc: 0.5556\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 182us/step - loss: 0.0979 - acc: 0.7143 - val_loss: 0.1372 - val_acc: 0.5556\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 172us/step - loss: 0.0979 - acc: 0.7238 - val_loss: 0.1355 - val_acc: 0.5778\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "validation_split = 0.3\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 709us/step - loss: 0.1029 - acc: 0.6933 - val_loss: 0.1159 - val_acc: 0.6667\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.1019 - acc: 0.7333 - val_loss: 0.1159 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.1014 - acc: 0.7333 - val_loss: 0.1156 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 499us/step - loss: 0.1018 - acc: 0.7067 - val_loss: 0.1151 - val_acc: 0.6800\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 590us/step - loss: 0.1017 - acc: 0.7867 - val_loss: 0.1152 - val_acc: 0.6667\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 273us/step - loss: 0.1016 - acc: 0.7467 - val_loss: 0.1152 - val_acc: 0.6800\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 271us/step - loss: 0.1017 - acc: 0.7600 - val_loss: 0.1150 - val_acc: 0.6800\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 272us/step - loss: 0.1012 - acc: 0.7467 - val_loss: 0.1151 - val_acc: 0.6800\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 281us/step - loss: 0.1012 - acc: 0.7600 - val_loss: 0.1152 - val_acc: 0.6800\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 422us/step - loss: 0.1016 - acc: 0.7200 - val_loss: 0.1149 - val_acc: 0.6800\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 707us/step - loss: 0.1011 - acc: 0.7867 - val_loss: 0.1152 - val_acc: 0.6800\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 294us/step - loss: 0.1010 - acc: 0.7200 - val_loss: 0.1146 - val_acc: 0.6800\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 269us/step - loss: 0.1005 - acc: 0.8000 - val_loss: 0.1149 - val_acc: 0.6800\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 292us/step - loss: 0.1007 - acc: 0.7333 - val_loss: 0.1145 - val_acc: 0.6800\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 425us/step - loss: 0.1004 - acc: 0.7733 - val_loss: 0.1146 - val_acc: 0.6800\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 386us/step - loss: 0.1010 - acc: 0.7867 - val_loss: 0.1151 - val_acc: 0.6800\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 318us/step - loss: 0.1006 - acc: 0.7333 - val_loss: 0.1148 - val_acc: 0.6800\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 257us/step - loss: 0.1002 - acc: 0.7600 - val_loss: 0.1147 - val_acc: 0.6800\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.1005 - acc: 0.7600 - val_loss: 0.1152 - val_acc: 0.6533\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 438us/step - loss: 0.1017 - acc: 0.7467 - val_loss: 0.1151 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 287us/step - loss: 0.1003 - acc: 0.7200 - val_loss: 0.1147 - val_acc: 0.6800\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 287us/step - loss: 0.1005 - acc: 0.7867 - val_loss: 0.1147 - val_acc: 0.6800\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 350us/step - loss: 0.1000 - acc: 0.7600 - val_loss: 0.1148 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 292us/step - loss: 0.0998 - acc: 0.7467 - val_loss: 0.1148 - val_acc: 0.6667\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0999 - acc: 0.7200 - val_loss: 0.1144 - val_acc: 0.6800\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 382us/step - loss: 0.1002 - acc: 0.7200 - val_loss: 0.1136 - val_acc: 0.6800\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 299us/step - loss: 0.1004 - acc: 0.8533 - val_loss: 0.1141 - val_acc: 0.6800\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 282us/step - loss: 0.1000 - acc: 0.7733 - val_loss: 0.1140 - val_acc: 0.6800\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 285us/step - loss: 0.1002 - acc: 0.7200 - val_loss: 0.1135 - val_acc: 0.6800\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 267us/step - loss: 0.1011 - acc: 0.8267 - val_loss: 0.1139 - val_acc: 0.6800\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 425us/step - loss: 0.0999 - acc: 0.7600 - val_loss: 0.1135 - val_acc: 0.6800\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 238us/step - loss: 0.0991 - acc: 0.8400 - val_loss: 0.1138 - val_acc: 0.6800\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 314us/step - loss: 0.0993 - acc: 0.8267 - val_loss: 0.1139 - val_acc: 0.6800\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 433us/step - loss: 0.0991 - acc: 0.7867 - val_loss: 0.1141 - val_acc: 0.6800\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 356us/step - loss: 0.0991 - acc: 0.7333 - val_loss: 0.1139 - val_acc: 0.6800\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 495us/step - loss: 0.0999 - acc: 0.7200 - val_loss: 0.1131 - val_acc: 0.6800\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.0998 - acc: 0.8800 - val_loss: 0.1137 - val_acc: 0.6800\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 344us/step - loss: 0.0988 - acc: 0.7333 - val_loss: 0.1135 - val_acc: 0.6800\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 410us/step - loss: 0.0986 - acc: 0.7333 - val_loss: 0.1130 - val_acc: 0.6800\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 315us/step - loss: 0.0991 - acc: 0.8533 - val_loss: 0.1133 - val_acc: 0.6800\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 412us/step - loss: 0.0986 - acc: 0.7600 - val_loss: 0.1135 - val_acc: 0.6800\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 364us/step - loss: 0.0985 - acc: 0.7467 - val_loss: 0.1130 - val_acc: 0.6800\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 316us/step - loss: 0.0982 - acc: 0.7600 - val_loss: 0.1128 - val_acc: 0.6800\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 370us/step - loss: 0.0987 - acc: 0.8267 - val_loss: 0.1127 - val_acc: 0.6800\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 297us/step - loss: 0.0990 - acc: 0.8133 - val_loss: 0.1125 - val_acc: 0.6800\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 291us/step - loss: 0.0984 - acc: 0.8400 - val_loss: 0.1127 - val_acc: 0.6800\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 357us/step - loss: 0.0984 - acc: 0.7600 - val_loss: 0.1122 - val_acc: 0.7200\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 318us/step - loss: 0.0984 - acc: 0.8133 - val_loss: 0.1124 - val_acc: 0.6800\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 470us/step - loss: 0.0979 - acc: 0.8533 - val_loss: 0.1125 - val_acc: 0.6800\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 321us/step - loss: 0.0979 - acc: 0.8000 - val_loss: 0.1122 - val_acc: 0.6800\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.0977 - acc: 0.8267 - val_loss: 0.1122 - val_acc: 0.6800\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 491us/step - loss: 0.0981 - acc: 0.8667 - val_loss: 0.1124 - val_acc: 0.6800\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 362us/step - loss: 0.0980 - acc: 0.8533 - val_loss: 0.1129 - val_acc: 0.6800\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 389us/step - loss: 0.0978 - acc: 0.7467 - val_loss: 0.1125 - val_acc: 0.6800\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 278us/step - loss: 0.0978 - acc: 0.7867 - val_loss: 0.1122 - val_acc: 0.6800\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 261us/step - loss: 0.0978 - acc: 0.8267 - val_loss: 0.1123 - val_acc: 0.6800\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 246us/step - loss: 0.0973 - acc: 0.8133 - val_loss: 0.1123 - val_acc: 0.6800\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 281us/step - loss: 0.0977 - acc: 0.8133 - val_loss: 0.1126 - val_acc: 0.6800\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 251us/step - loss: 0.0983 - acc: 0.7733 - val_loss: 0.1119 - val_acc: 0.6800\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 281us/step - loss: 0.0979 - acc: 0.8400 - val_loss: 0.1125 - val_acc: 0.6800\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.0977 - acc: 0.7467 - val_loss: 0.1124 - val_acc: 0.6800\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 274us/step - loss: 0.0980 - acc: 0.8400 - val_loss: 0.1123 - val_acc: 0.6800\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 310us/step - loss: 0.0970 - acc: 0.7733 - val_loss: 0.1121 - val_acc: 0.6800\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 358us/step - loss: 0.0971 - acc: 0.7867 - val_loss: 0.1117 - val_acc: 0.6800\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 349us/step - loss: 0.0979 - acc: 0.8400 - val_loss: 0.1122 - val_acc: 0.6800\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 389us/step - loss: 0.0983 - acc: 0.8267 - val_loss: 0.1124 - val_acc: 0.6800\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 285us/step - loss: 0.0968 - acc: 0.7467 - val_loss: 0.1118 - val_acc: 0.6800\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 297us/step - loss: 0.0966 - acc: 0.7733 - val_loss: 0.1116 - val_acc: 0.6800\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 327us/step - loss: 0.0967 - acc: 0.8267 - val_loss: 0.1114 - val_acc: 0.6800\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 235us/step - loss: 0.0965 - acc: 0.7867 - val_loss: 0.1112 - val_acc: 0.6800\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 244us/step - loss: 0.0971 - acc: 0.8400 - val_loss: 0.1112 - val_acc: 0.6800\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 243us/step - loss: 0.0973 - acc: 0.8133 - val_loss: 0.1113 - val_acc: 0.6800\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 291us/step - loss: 0.0964 - acc: 0.8533 - val_loss: 0.1113 - val_acc: 0.6800\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 311us/step - loss: 0.0962 - acc: 0.8400 - val_loss: 0.1114 - val_acc: 0.6800\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0966 - acc: 0.7333 - val_loss: 0.1106 - val_acc: 0.7200\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0962 - acc: 0.9067 - val_loss: 0.1110 - val_acc: 0.6800\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0962 - acc: 0.8000 - val_loss: 0.1109 - val_acc: 0.6800\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 374us/step - loss: 0.0961 - acc: 0.8800 - val_loss: 0.1112 - val_acc: 0.6800\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 359us/step - loss: 0.0960 - acc: 0.8000 - val_loss: 0.1109 - val_acc: 0.6800\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 246us/step - loss: 0.0966 - acc: 0.7733 - val_loss: 0.1106 - val_acc: 0.7200\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 463us/step - loss: 0.0963 - acc: 0.8933 - val_loss: 0.1110 - val_acc: 0.6800\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 474us/step - loss: 0.0961 - acc: 0.8267 - val_loss: 0.1110 - val_acc: 0.6800\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0965 - acc: 0.7733 - val_loss: 0.1105 - val_acc: 0.7067\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 310us/step - loss: 0.0960 - acc: 0.8800 - val_loss: 0.1110 - val_acc: 0.6800\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 321us/step - loss: 0.0955 - acc: 0.8000 - val_loss: 0.1106 - val_acc: 0.6800\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0957 - acc: 0.8800 - val_loss: 0.1108 - val_acc: 0.6800\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.0957 - acc: 0.8400 - val_loss: 0.1108 - val_acc: 0.6800\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0954 - acc: 0.7600 - val_loss: 0.1101 - val_acc: 0.7200\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0954 - acc: 0.8400 - val_loss: 0.1100 - val_acc: 0.7200\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.0953 - acc: 0.8267 - val_loss: 0.1096 - val_acc: 0.7467\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.0957 - acc: 0.9333 - val_loss: 0.1098 - val_acc: 0.7200\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0953 - acc: 0.8933 - val_loss: 0.1097 - val_acc: 0.7200\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.0953 - acc: 0.9200 - val_loss: 0.1100 - val_acc: 0.7067\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 218us/step - loss: 0.0960 - acc: 0.8000 - val_loss: 0.1099 - val_acc: 0.7200\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0960 - acc: 0.8133 - val_loss: 0.1093 - val_acc: 0.7467\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 223us/step - loss: 0.0954 - acc: 0.9200 - val_loss: 0.1097 - val_acc: 0.7200\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0952 - acc: 0.8800 - val_loss: 0.1095 - val_acc: 0.7200\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.0946 - acc: 0.9067 - val_loss: 0.1096 - val_acc: 0.7200\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 206us/step - loss: 0.0952 - acc: 0.8533 - val_loss: 0.1092 - val_acc: 0.7467\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0949 - acc: 0.9067 - val_loss: 0.1091 - val_acc: 0.7467\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/50\n",
      "75/75 [==============================] - 0s 372us/step - loss: 0.0946 - acc: 0.9067 - val_loss: 0.1091 - val_acc: 0.7467\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.0945 - acc: 0.9200 - val_loss: 0.1094 - val_acc: 0.7200\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 0s 333us/step - loss: 0.0949 - acc: 0.8533 - val_loss: 0.1090 - val_acc: 0.7467\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 0s 373us/step - loss: 0.0953 - acc: 0.9067 - val_loss: 0.1088 - val_acc: 0.7467\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 0s 253us/step - loss: 0.0944 - acc: 0.9333 - val_loss: 0.1091 - val_acc: 0.7200\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 0s 588us/step - loss: 0.0942 - acc: 0.8667 - val_loss: 0.1091 - val_acc: 0.7200\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 0s 577us/step - loss: 0.0944 - acc: 0.9067 - val_loss: 0.1089 - val_acc: 0.7333\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 0s 426us/step - loss: 0.0945 - acc: 0.9067 - val_loss: 0.1089 - val_acc: 0.7333\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 0s 284us/step - loss: 0.0950 - acc: 0.8267 - val_loss: 0.1086 - val_acc: 0.7467\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 0s 335us/step - loss: 0.0945 - acc: 0.9333 - val_loss: 0.1092 - val_acc: 0.7200\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 0s 465us/step - loss: 0.0940 - acc: 0.9067 - val_loss: 0.1092 - val_acc: 0.7200\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 0s 331us/step - loss: 0.0944 - acc: 0.8133 - val_loss: 0.1086 - val_acc: 0.7333\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 0s 490us/step - loss: 0.0940 - acc: 0.9333 - val_loss: 0.1090 - val_acc: 0.7200\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 0s 351us/step - loss: 0.0943 - acc: 0.8933 - val_loss: 0.1088 - val_acc: 0.7200\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 0s 277us/step - loss: 0.0939 - acc: 0.9067 - val_loss: 0.1091 - val_acc: 0.7200\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 0s 338us/step - loss: 0.0937 - acc: 0.8533 - val_loss: 0.1089 - val_acc: 0.7200\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 0s 287us/step - loss: 0.0943 - acc: 0.8400 - val_loss: 0.1084 - val_acc: 0.7333\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 0s 268us/step - loss: 0.0936 - acc: 0.9067 - val_loss: 0.1085 - val_acc: 0.7200\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 0s 221us/step - loss: 0.0947 - acc: 0.8133 - val_loss: 0.1079 - val_acc: 0.7600\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 0s 285us/step - loss: 0.0936 - acc: 0.9333 - val_loss: 0.1081 - val_acc: 0.7467\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 0s 260us/step - loss: 0.0935 - acc: 0.9333 - val_loss: 0.1083 - val_acc: 0.7333\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0949 - acc: 0.8933 - val_loss: 0.1088 - val_acc: 0.7200\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 0s 355us/step - loss: 0.0937 - acc: 0.8667 - val_loss: 0.1089 - val_acc: 0.6800\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 0s 332us/step - loss: 0.0934 - acc: 0.8133 - val_loss: 0.1086 - val_acc: 0.7200\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 0s 295us/step - loss: 0.0945 - acc: 0.8533 - val_loss: 0.1079 - val_acc: 0.7467\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.0939 - acc: 0.8400 - val_loss: 0.1076 - val_acc: 0.7600\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 0s 417us/step - loss: 0.0932 - acc: 0.9200 - val_loss: 0.1076 - val_acc: 0.7467\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 0s 340us/step - loss: 0.0939 - acc: 0.9200 - val_loss: 0.1076 - val_acc: 0.7467\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 0s 321us/step - loss: 0.0935 - acc: 0.9333 - val_loss: 0.1079 - val_acc: 0.7333\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 0s 441us/step - loss: 0.0930 - acc: 0.9067 - val_loss: 0.1077 - val_acc: 0.7333\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 0s 379us/step - loss: 0.0929 - acc: 0.9333 - val_loss: 0.1079 - val_acc: 0.7333\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 0s 464us/step - loss: 0.0929 - acc: 0.9200 - val_loss: 0.1082 - val_acc: 0.7200\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 0s 313us/step - loss: 0.0932 - acc: 0.8800 - val_loss: 0.1077 - val_acc: 0.7333\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 0s 326us/step - loss: 0.0935 - acc: 0.8933 - val_loss: 0.1077 - val_acc: 0.7333\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 0s 286us/step - loss: 0.0936 - acc: 0.8400 - val_loss: 0.1071 - val_acc: 0.7733\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 0s 349us/step - loss: 0.0936 - acc: 0.9333 - val_loss: 0.1071 - val_acc: 0.7733\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 0s 271us/step - loss: 0.0931 - acc: 0.9333 - val_loss: 0.1071 - val_acc: 0.7600\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 0s 295us/step - loss: 0.0927 - acc: 0.9333 - val_loss: 0.1074 - val_acc: 0.7333\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 0s 399us/step - loss: 0.0925 - acc: 0.9067 - val_loss: 0.1073 - val_acc: 0.7333\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 0s 307us/step - loss: 0.0925 - acc: 0.9200 - val_loss: 0.1076 - val_acc: 0.7333\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 0s 289us/step - loss: 0.0929 - acc: 0.9067 - val_loss: 0.1077 - val_acc: 0.7200\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 0s 351us/step - loss: 0.0923 - acc: 0.8800 - val_loss: 0.1072 - val_acc: 0.7333\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 0s 233us/step - loss: 0.0926 - acc: 0.8800 - val_loss: 0.1070 - val_acc: 0.7467\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 0s 348us/step - loss: 0.0922 - acc: 0.9200 - val_loss: 0.1069 - val_acc: 0.7467\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 0s 275us/step - loss: 0.0941 - acc: 0.8800 - val_loss: 0.1070 - val_acc: 0.7333\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 0s 434us/step - loss: 0.0920 - acc: 0.9333 - val_loss: 0.1069 - val_acc: 0.7467\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 0s 326us/step - loss: 0.0923 - acc: 0.9067 - val_loss: 0.1069 - val_acc: 0.7467\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 0s 288us/step - loss: 0.0925 - acc: 0.9067 - val_loss: 0.1067 - val_acc: 0.7600\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 0s 258us/step - loss: 0.0923 - acc: 0.9333 - val_loss: 0.1068 - val_acc: 0.7467\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 0s 245us/step - loss: 0.0925 - acc: 0.9333 - val_loss: 0.1071 - val_acc: 0.7333\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 50\n",
    "validation_split = 0.5\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/25\n",
      "75/75 [==============================] - 0s 257us/step - loss: 0.0925 - acc: 0.9200 - val_loss: 0.1069 - val_acc: 0.7333\n",
      "Epoch 2/25\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.0929 - acc: 0.9200 - val_loss: 0.1065 - val_acc: 0.7600\n",
      "Epoch 3/25\n",
      "75/75 [==============================] - 0s 298us/step - loss: 0.0917 - acc: 0.9200 - val_loss: 0.1065 - val_acc: 0.7467\n",
      "Epoch 4/25\n",
      "75/75 [==============================] - 0s 248us/step - loss: 0.0920 - acc: 0.9333 - val_loss: 0.1068 - val_acc: 0.7333\n",
      "Epoch 5/25\n",
      "75/75 [==============================] - 0s 470us/step - loss: 0.0916 - acc: 0.9200 - val_loss: 0.1065 - val_acc: 0.7333\n",
      "Epoch 6/25\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0921 - acc: 0.8667 - val_loss: 0.1061 - val_acc: 0.7733\n",
      "Epoch 7/25\n",
      "75/75 [==============================] - 0s 254us/step - loss: 0.0926 - acc: 0.9333 - val_loss: 0.1064 - val_acc: 0.7333\n",
      "Epoch 8/25\n",
      "75/75 [==============================] - 0s 894us/step - loss: 0.0917 - acc: 0.9333 - val_loss: 0.1065 - val_acc: 0.7333\n",
      "Epoch 9/25\n",
      "75/75 [==============================] - 0s 338us/step - loss: 0.0914 - acc: 0.9200 - val_loss: 0.1066 - val_acc: 0.7333\n",
      "Epoch 10/25\n",
      "75/75 [==============================] - 0s 283us/step - loss: 0.0914 - acc: 0.9200 - val_loss: 0.1066 - val_acc: 0.7333\n",
      "Epoch 11/25\n",
      "75/75 [==============================] - 0s 476us/step - loss: 0.0914 - acc: 0.9067 - val_loss: 0.1063 - val_acc: 0.7333\n",
      "Epoch 12/25\n",
      "75/75 [==============================] - 0s 209us/step - loss: 0.0916 - acc: 0.9200 - val_loss: 0.1062 - val_acc: 0.7333\n",
      "Epoch 13/25\n",
      "75/75 [==============================] - 0s 274us/step - loss: 0.0912 - acc: 0.9333 - val_loss: 0.1063 - val_acc: 0.7333\n",
      "Epoch 14/25\n",
      "75/75 [==============================] - 0s 573us/step - loss: 0.0914 - acc: 0.9333 - val_loss: 0.1066 - val_acc: 0.7333\n",
      "Epoch 15/25\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0916 - acc: 0.9200 - val_loss: 0.1065 - val_acc: 0.7333\n",
      "Epoch 16/25\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0919 - acc: 0.9067 - val_loss: 0.1064 - val_acc: 0.7333\n",
      "Epoch 17/25\n",
      "75/75 [==============================] - 0s 273us/step - loss: 0.0913 - acc: 0.9200 - val_loss: 0.1063 - val_acc: 0.7333\n",
      "Epoch 18/25\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0912 - acc: 0.9200 - val_loss: 0.1057 - val_acc: 0.7733\n",
      "Epoch 19/25\n",
      "75/75 [==============================] - 0s 241us/step - loss: 0.0914 - acc: 0.9333 - val_loss: 0.1056 - val_acc: 0.7733\n",
      "Epoch 20/25\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0913 - acc: 0.9200 - val_loss: 0.1056 - val_acc: 0.7733\n",
      "Epoch 21/25\n",
      "75/75 [==============================] - 0s 232us/step - loss: 0.0915 - acc: 0.9333 - val_loss: 0.1056 - val_acc: 0.7733\n",
      "Epoch 22/25\n",
      "75/75 [==============================] - 0s 206us/step - loss: 0.0908 - acc: 0.9333 - val_loss: 0.1057 - val_acc: 0.7733\n",
      "Epoch 23/25\n",
      "75/75 [==============================] - 0s 923us/step - loss: 0.0909 - acc: 0.9333 - val_loss: 0.1057 - val_acc: 0.7600\n",
      "Epoch 24/25\n",
      "75/75 [==============================] - 0s 232us/step - loss: 0.0908 - acc: 0.9200 - val_loss: 0.1055 - val_acc: 0.7733\n",
      "Epoch 25/25\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0908 - acc: 0.9200 - val_loss: 0.1053 - val_acc: 0.7867\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 25\n",
    "validation_split = 0.5\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 0s 340us/step - loss: 0.0899 - acc: 0.9333 - val_loss: 0.1112 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 256us/step - loss: 0.0898 - acc: 0.9111 - val_loss: 0.1127 - val_acc: 0.6833\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 305us/step - loss: 0.0896 - acc: 0.8222 - val_loss: 0.1121 - val_acc: 0.6833\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.0896 - acc: 0.8667 - val_loss: 0.1122 - val_acc: 0.6833\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 0s 312us/step - loss: 0.0902 - acc: 0.8556 - val_loss: 0.1123 - val_acc: 0.6833\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 0s 642us/step - loss: 0.0893 - acc: 0.8444 - val_loss: 0.1123 - val_acc: 0.6833\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 0s 376us/step - loss: 0.0899 - acc: 0.7778 - val_loss: 0.1113 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 0s 361us/step - loss: 0.0896 - acc: 0.9000 - val_loss: 0.1113 - val_acc: 0.7000\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 0s 698us/step - loss: 0.0905 - acc: 0.8778 - val_loss: 0.1117 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 0s 381us/step - loss: 0.0898 - acc: 0.8778 - val_loss: 0.1119 - val_acc: 0.7000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "validation_split = 0.4\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 75 samples\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 427us/step - loss: 0.0903 - acc: 0.8933 - val_loss: 0.1057 - val_acc: 0.7333\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 385us/step - loss: 0.0903 - acc: 0.9200 - val_loss: 0.1054 - val_acc: 0.7333\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 337us/step - loss: 0.0912 - acc: 0.8800 - val_loss: 0.1049 - val_acc: 0.7867\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 433us/step - loss: 0.0901 - acc: 0.9333 - val_loss: 0.1048 - val_acc: 0.7867\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 553us/step - loss: 0.0905 - acc: 0.9333 - val_loss: 0.1052 - val_acc: 0.7333\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 350us/step - loss: 0.0902 - acc: 0.9333 - val_loss: 0.1055 - val_acc: 0.7333\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 391us/step - loss: 0.0901 - acc: 0.9333 - val_loss: 0.1054 - val_acc: 0.7333\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 683us/step - loss: 0.0905 - acc: 0.9200 - val_loss: 0.1053 - val_acc: 0.7333\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 663us/step - loss: 0.0902 - acc: 0.9067 - val_loss: 0.1050 - val_acc: 0.7467\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 298us/step - loss: 0.0905 - acc: 0.9333 - val_loss: 0.1053 - val_acc: 0.7333\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.0900 - acc: 0.9200 - val_loss: 0.1052 - val_acc: 0.7333\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 705us/step - loss: 0.0907 - acc: 0.9200 - val_loss: 0.1050 - val_acc: 0.7333\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 271us/step - loss: 0.0895 - acc: 0.9200 - val_loss: 0.1047 - val_acc: 0.7600\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 295us/step - loss: 0.0898 - acc: 0.9333 - val_loss: 0.1048 - val_acc: 0.7467\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 313us/step - loss: 0.0896 - acc: 0.9200 - val_loss: 0.1048 - val_acc: 0.7333\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 206us/step - loss: 0.0899 - acc: 0.9333 - val_loss: 0.1048 - val_acc: 0.7467\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 309us/step - loss: 0.0899 - acc: 0.9200 - val_loss: 0.1045 - val_acc: 0.7867\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 320us/step - loss: 0.0903 - acc: 0.9333 - val_loss: 0.1046 - val_acc: 0.7600\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 272us/step - loss: 0.0896 - acc: 0.9200 - val_loss: 0.1045 - val_acc: 0.7600\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 346us/step - loss: 0.0894 - acc: 0.9200 - val_loss: 0.1041 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0897 - acc: 0.9333 - val_loss: 0.1043 - val_acc: 0.7867\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 277us/step - loss: 0.0897 - acc: 0.9333 - val_loss: 0.1041 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 315us/step - loss: 0.0891 - acc: 0.9333 - val_loss: 0.1042 - val_acc: 0.7867\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 341us/step - loss: 0.0900 - acc: 0.9333 - val_loss: 0.1048 - val_acc: 0.7333\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 304us/step - loss: 0.0891 - acc: 0.9200 - val_loss: 0.1045 - val_acc: 0.7467\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 277us/step - loss: 0.0892 - acc: 0.9200 - val_loss: 0.1041 - val_acc: 0.7867\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 394us/step - loss: 0.0893 - acc: 0.9333 - val_loss: 0.1037 - val_acc: 0.8267\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 286us/step - loss: 0.0891 - acc: 0.9333 - val_loss: 0.1040 - val_acc: 0.7867\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 559us/step - loss: 0.0889 - acc: 0.9333 - val_loss: 0.1038 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 314us/step - loss: 0.0894 - acc: 0.9333 - val_loss: 0.1037 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 344us/step - loss: 0.0890 - acc: 0.9333 - val_loss: 0.1035 - val_acc: 0.8400\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 350us/step - loss: 0.0892 - acc: 0.9333 - val_loss: 0.1033 - val_acc: 0.8533\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 222us/step - loss: 0.0897 - acc: 0.9200 - val_loss: 0.1033 - val_acc: 0.8533\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 217us/step - loss: 0.0889 - acc: 0.9333 - val_loss: 0.1035 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0894 - acc: 0.9467 - val_loss: 0.1040 - val_acc: 0.7600\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 248us/step - loss: 0.0891 - acc: 0.9200 - val_loss: 0.1042 - val_acc: 0.7333\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 274us/step - loss: 0.0892 - acc: 0.9067 - val_loss: 0.1036 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 309us/step - loss: 0.0890 - acc: 0.9200 - val_loss: 0.1033 - val_acc: 0.8267\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 339us/step - loss: 0.0889 - acc: 0.9333 - val_loss: 0.1031 - val_acc: 0.8533\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 262us/step - loss: 0.0888 - acc: 0.9333 - val_loss: 0.1035 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 293us/step - loss: 0.0886 - acc: 0.9333 - val_loss: 0.1036 - val_acc: 0.7867\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 316us/step - loss: 0.0884 - acc: 0.9200 - val_loss: 0.1035 - val_acc: 0.8000\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 297us/step - loss: 0.0886 - acc: 0.9333 - val_loss: 0.1033 - val_acc: 0.8000\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 302us/step - loss: 0.0885 - acc: 0.9200 - val_loss: 0.1032 - val_acc: 0.8000\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 262us/step - loss: 0.0887 - acc: 0.9200 - val_loss: 0.1032 - val_acc: 0.8000\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 270us/step - loss: 0.0886 - acc: 0.9333 - val_loss: 0.1036 - val_acc: 0.7733\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 246us/step - loss: 0.0884 - acc: 0.9200 - val_loss: 0.1035 - val_acc: 0.7867\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 284us/step - loss: 0.0887 - acc: 0.9333 - val_loss: 0.1036 - val_acc: 0.7733\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 250us/step - loss: 0.0885 - acc: 0.9200 - val_loss: 0.1034 - val_acc: 0.7867\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 267us/step - loss: 0.0882 - acc: 0.9333 - val_loss: 0.1034 - val_acc: 0.7733\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0890 - acc: 0.9200 - val_loss: 0.1032 - val_acc: 0.7867\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.0885 - acc: 0.9200 - val_loss: 0.1030 - val_acc: 0.8000\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 239us/step - loss: 0.0882 - acc: 0.9200 - val_loss: 0.1027 - val_acc: 0.8267\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 356us/step - loss: 0.0885 - acc: 0.9200 - val_loss: 0.1024 - val_acc: 0.8533\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 262us/step - loss: 0.0894 - acc: 0.9333 - val_loss: 0.1026 - val_acc: 0.8267\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 247us/step - loss: 0.0884 - acc: 0.9333 - val_loss: 0.1029 - val_acc: 0.8000\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0884 - acc: 0.9333 - val_loss: 0.1030 - val_acc: 0.7867\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 224us/step - loss: 0.0881 - acc: 0.9200 - val_loss: 0.1024 - val_acc: 0.8533\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 266us/step - loss: 0.0879 - acc: 0.9333 - val_loss: 0.1024 - val_acc: 0.8533\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.0880 - acc: 0.9333 - val_loss: 0.1025 - val_acc: 0.8267\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.0881 - acc: 0.9333 - val_loss: 0.1030 - val_acc: 0.7867\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 228us/step - loss: 0.0877 - acc: 0.9200 - val_loss: 0.1032 - val_acc: 0.7733\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 225us/step - loss: 0.0880 - acc: 0.9200 - val_loss: 0.1029 - val_acc: 0.7867\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 297us/step - loss: 0.0883 - acc: 0.8933 - val_loss: 0.1024 - val_acc: 0.8000\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 280us/step - loss: 0.0878 - acc: 0.9333 - val_loss: 0.1024 - val_acc: 0.8133\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 392us/step - loss: 0.0878 - acc: 0.9333 - val_loss: 0.1024 - val_acc: 0.8000\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 247us/step - loss: 0.0880 - acc: 0.9200 - val_loss: 0.1022 - val_acc: 0.8400\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 306us/step - loss: 0.0880 - acc: 0.9333 - val_loss: 0.1026 - val_acc: 0.7867\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 234us/step - loss: 0.0880 - acc: 0.9200 - val_loss: 0.1024 - val_acc: 0.8000\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 410us/step - loss: 0.0875 - acc: 0.9333 - val_loss: 0.1022 - val_acc: 0.8267\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.0874 - acc: 0.9333 - val_loss: 0.1024 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 271us/step - loss: 0.0879 - acc: 0.9333 - val_loss: 0.1022 - val_acc: 0.8133\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 413us/step - loss: 0.0877 - acc: 0.9333 - val_loss: 0.1027 - val_acc: 0.7867\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 319us/step - loss: 0.0874 - acc: 0.9200 - val_loss: 0.1024 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 214us/step - loss: 0.0871 - acc: 0.9333 - val_loss: 0.1025 - val_acc: 0.7867\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 233us/step - loss: 0.0872 - acc: 0.9333 - val_loss: 0.1022 - val_acc: 0.8000\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 234us/step - loss: 0.0870 - acc: 0.9200 - val_loss: 0.1021 - val_acc: 0.8000\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.0871 - acc: 0.9333 - val_loss: 0.1020 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0871 - acc: 0.9333 - val_loss: 0.1019 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 249us/step - loss: 0.0871 - acc: 0.9333 - val_loss: 0.1024 - val_acc: 0.7867\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 283us/step - loss: 0.0870 - acc: 0.9200 - val_loss: 0.1020 - val_acc: 0.8000\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0870 - acc: 0.9333 - val_loss: 0.1020 - val_acc: 0.8000\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 231us/step - loss: 0.0875 - acc: 0.9333 - val_loss: 0.1019 - val_acc: 0.8000\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 254us/step - loss: 0.0877 - acc: 0.9333 - val_loss: 0.1023 - val_acc: 0.7867\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 247us/step - loss: 0.0869 - acc: 0.9200 - val_loss: 0.1018 - val_acc: 0.8000\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 203us/step - loss: 0.0868 - acc: 0.9333 - val_loss: 0.1016 - val_acc: 0.8400\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 259us/step - loss: 0.0878 - acc: 0.9200 - val_loss: 0.1013 - val_acc: 0.8533\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 262us/step - loss: 0.0872 - acc: 0.9200 - val_loss: 0.1011 - val_acc: 0.8800\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0875 - acc: 0.9333 - val_loss: 0.1010 - val_acc: 0.8800\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0870 - acc: 0.9333 - val_loss: 0.1009 - val_acc: 0.8800\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 268us/step - loss: 0.0869 - acc: 0.9333 - val_loss: 0.1010 - val_acc: 0.8800\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 397us/step - loss: 0.0865 - acc: 0.9333 - val_loss: 0.1013 - val_acc: 0.8533\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 288us/step - loss: 0.0869 - acc: 0.9600 - val_loss: 0.1015 - val_acc: 0.8000\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 221us/step - loss: 0.0866 - acc: 0.9200 - val_loss: 0.1011 - val_acc: 0.8533\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 231us/step - loss: 0.0864 - acc: 0.9333 - val_loss: 0.1010 - val_acc: 0.8533\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 251us/step - loss: 0.0865 - acc: 0.9333 - val_loss: 0.1011 - val_acc: 0.8533\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 263us/step - loss: 0.0869 - acc: 0.9333 - val_loss: 0.1013 - val_acc: 0.8267\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 378us/step - loss: 0.0868 - acc: 0.9333 - val_loss: 0.1015 - val_acc: 0.8000\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 480us/step - loss: 0.0868 - acc: 0.9333 - val_loss: 0.1011 - val_acc: 0.8533\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 378us/step - loss: 0.0867 - acc: 0.9333 - val_loss: 0.1015 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 105 samples\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 0s 470us/step - loss: 0.0923 - acc: 0.8889 - val_loss: 0.0944 - val_acc: 0.8952\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 607us/step - loss: 0.0915 - acc: 0.8889 - val_loss: 0.0944 - val_acc: 0.9143\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 547us/step - loss: 0.0912 - acc: 0.9333 - val_loss: 0.0945 - val_acc: 0.9143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 802us/step - loss: 0.0912 - acc: 0.9111 - val_loss: 0.0946 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 537us/step - loss: 0.0908 - acc: 0.9556 - val_loss: 0.0946 - val_acc: 0.9524\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 776us/step - loss: 0.0908 - acc: 0.9556 - val_loss: 0.0946 - val_acc: 0.9524\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 458us/step - loss: 0.0907 - acc: 0.9556 - val_loss: 0.0947 - val_acc: 0.9619\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 814us/step - loss: 0.0907 - acc: 0.9556 - val_loss: 0.0947 - val_acc: 0.9619\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 644us/step - loss: 0.0912 - acc: 0.9556 - val_loss: 0.0947 - val_acc: 0.9619\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 412us/step - loss: 0.0912 - acc: 0.9556 - val_loss: 0.0946 - val_acc: 0.9619\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "validation_split = 0.7\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 132us/step\n",
      "Test loss: 0.09339550316333771\n",
      "Test accuracy: 0.9599999976158142\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X, Y, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem 2 </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pandas.read_table(\"https://www.cs.mtsu.edu/~jphillips/courses/CSCI4850-5850/public/WDBC.txt\",delim_whitespace=True,header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[:,0:30]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = keras.utils.to_categorical(labels,len(np.unique(labels)))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "output_size = Y.shape[1]\n",
    "model.add(keras.layers.Dense(output_size,activation='sigmoid',input_shape=[input_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mse,optimizer=keras.optimizers.SGD(lr=0.05),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.21963508,  0.08235863],\n",
       "        [-0.24390268, -0.28651336],\n",
       "        [-0.32273233,  0.04278916],\n",
       "        [ 0.23763302,  0.18622503],\n",
       "        [ 0.10275772,  0.4031786 ],\n",
       "        [ 0.17379048,  0.32699648],\n",
       "        [ 0.12472776, -0.38638616],\n",
       "        [ 0.09127244, -0.11566672],\n",
       "        [-0.10711735,  0.1066635 ],\n",
       "        [-0.40730256, -0.3511564 ],\n",
       "        [ 0.3435841 , -0.34328306],\n",
       "        [ 0.29436967,  0.19802317],\n",
       "        [ 0.217365  ,  0.1350343 ],\n",
       "        [-0.18595277,  0.33420643],\n",
       "        [-0.00332808, -0.00146732],\n",
       "        [-0.23134603, -0.25946328],\n",
       "        [ 0.09288195,  0.36829016],\n",
       "        [ 0.34103337,  0.13652983],\n",
       "        [-0.05165362, -0.2957006 ],\n",
       "        [ 0.01573527, -0.42108816],\n",
       "        [-0.14394471,  0.36315474],\n",
       "        [-0.01892534,  0.04953724],\n",
       "        [ 0.112443  ,  0.12716582],\n",
       "        [ 0.26906338,  0.24222323],\n",
       "        [-0.07433084,  0.21387222],\n",
       "        [ 0.4193202 ,  0.15005395],\n",
       "        [ 0.3231363 , -0.2890553 ],\n",
       "        [ 0.09068581,  0.08261248],\n",
       "        [ 0.3709316 , -0.30458254],\n",
       "        [ 0.04432049, -0.21082339]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56029445, 0.5476688 ],\n",
       "       [0.59629494, 0.54004794],\n",
       "       [0.5067248 , 0.5289208 ],\n",
       "       [0.4906607 , 0.53065133],\n",
       "       [0.49457318, 0.5226373 ],\n",
       "       [0.48402303, 0.52604455],\n",
       "       [0.49983537, 0.553619  ],\n",
       "       [0.60296357, 0.62862325],\n",
       "       [0.43196186, 0.4951144 ],\n",
       "       [0.45191038, 0.5472938 ],\n",
       "       [0.48641577, 0.48978716],\n",
       "       [0.5289009 , 0.54487103],\n",
       "       [0.48711345, 0.5679239 ],\n",
       "       [0.4651212 , 0.54221773],\n",
       "       [0.5187801 , 0.5701978 ],\n",
       "       [0.56459385, 0.57064426],\n",
       "       [0.47626922, 0.5640357 ],\n",
       "       [0.48191524, 0.50926363],\n",
       "       [0.43974477, 0.5285816 ],\n",
       "       [0.5575765 , 0.5250758 ],\n",
       "       [0.5027628 , 0.5455001 ],\n",
       "       [0.5318497 , 0.5925504 ],\n",
       "       [0.6628148 , 0.44505554],\n",
       "       [0.43423027, 0.50659007],\n",
       "       [0.42621395, 0.4967944 ],\n",
       "       [0.47777843, 0.54932   ],\n",
       "       [0.4714012 , 0.53008527],\n",
       "       [0.5707782 , 0.51106536],\n",
       "       [0.5514232 , 0.5792724 ],\n",
       "       [0.49021637, 0.521839  ],\n",
       "       [0.47839722, 0.5462049 ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:31,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.42357060e-01,  1.91256061e-01],\n",
       "       [ 3.90050858e-01,  1.60535663e-01],\n",
       "       [ 2.69006193e-02,  1.15812555e-01],\n",
       "       [-3.73615026e-02,  1.22759208e-01],\n",
       "       [-2.17079818e-02,  9.06111747e-02],\n",
       "       [-6.39296621e-02,  1.04272589e-01],\n",
       "       [-6.58564270e-04,  2.15303898e-01],\n",
       "       [ 4.17828709e-01,  5.26315153e-01],\n",
       "       [-2.73851186e-01, -1.95431113e-02],\n",
       "       [-1.92954838e-01,  1.89742327e-01],\n",
       "       [-5.43501154e-02, -4.08571213e-02],\n",
       "       [ 1.15732834e-01,  1.79968297e-01],\n",
       "       [-5.15574664e-02,  2.73385644e-01],\n",
       "       [-1.39742225e-01,  1.69273838e-01],\n",
       "       [ 7.51559213e-02,  2.82658517e-01],\n",
       "       [ 2.59827375e-01,  2.84480423e-01],\n",
       "       [-9.49945226e-02,  2.57557154e-01],\n",
       "       [-7.23705590e-02,  3.70586962e-02],\n",
       "       [-2.42197961e-01,  1.14451274e-01],\n",
       "       [ 2.31332183e-01,  1.00387588e-01],\n",
       "       [ 1.10512972e-02,  1.82505384e-01],\n",
       "       [ 1.27571508e-01,  3.74518812e-01],\n",
       "       [ 6.75863385e-01, -2.20669001e-01],\n",
       "       [-2.64612228e-01,  2.63618231e-02],\n",
       "       [-2.97315180e-01, -1.28225386e-02],\n",
       "       [-8.89448747e-02,  1.97923422e-01],\n",
       "       [-1.14520147e-01,  1.20486662e-01],\n",
       "       [ 2.85026699e-01,  4.42686528e-02],\n",
       "       [ 2.06422701e-01,  3.19787145e-01],\n",
       "       [-3.91394719e-02,  8.74115229e-02],\n",
       "       [-8.64648968e-02,  1.85348600e-01]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer_neti = np.dot(np.float32(X[0:31,:]),model.get_weights()[0])+model.get_weights()[1]\n",
    "output_layer_neti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5602944 , 0.5476688 ],\n",
       "       [0.59629494, 0.54004794],\n",
       "       [0.5067247 , 0.5289208 ],\n",
       "       [0.4906607 , 0.53065133],\n",
       "       [0.49457318, 0.5226373 ],\n",
       "       [0.48402303, 0.52604455],\n",
       "       [0.49983537, 0.553619  ],\n",
       "       [0.60296357, 0.62862325],\n",
       "       [0.43196186, 0.4951144 ],\n",
       "       [0.45191038, 0.5472938 ],\n",
       "       [0.48641577, 0.48978716],\n",
       "       [0.5289009 , 0.54487103],\n",
       "       [0.48711345, 0.56792384],\n",
       "       [0.4651212 , 0.54221773],\n",
       "       [0.5187802 , 0.5701979 ],\n",
       "       [0.56459385, 0.57064426],\n",
       "       [0.47626922, 0.56403565],\n",
       "       [0.48191524, 0.50926363],\n",
       "       [0.43974477, 0.5285816 ],\n",
       "       [0.5575765 , 0.52507585],\n",
       "       [0.5027628 , 0.5455001 ],\n",
       "       [0.5318497 , 0.5925504 ],\n",
       "       [0.6628148 , 0.44505554],\n",
       "       [0.43423027, 0.50659007],\n",
       "       [0.42621395, 0.4967944 ],\n",
       "       [0.47777843, 0.54932   ],\n",
       "       [0.4714012 , 0.53008527],\n",
       "       [0.5707782 , 0.51106536],\n",
       "       [0.5514232 , 0.5792724 ],\n",
       "       [0.49021637, 0.52183896],\n",
       "       [0.47839725, 0.5462049 ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / (1.0 + np.exp(-1.0 * output_layer_neti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21963508  0.08235863]\n",
      " [-0.24390268 -0.28651336]\n",
      " [-0.32273233  0.04278916]\n",
      " [ 0.23763302  0.18622503]\n",
      " [ 0.10275772  0.4031786 ]\n",
      " [ 0.17379048  0.32699648]\n",
      " [ 0.12472776 -0.38638616]\n",
      " [ 0.09127244 -0.11566672]\n",
      " [-0.10711735  0.1066635 ]\n",
      " [-0.40730256 -0.3511564 ]\n",
      " [ 0.3435841  -0.34328306]\n",
      " [ 0.29436967  0.19802317]\n",
      " [ 0.217365    0.1350343 ]\n",
      " [-0.18595277  0.33420643]\n",
      " [-0.00332808 -0.00146732]\n",
      " [-0.23134603 -0.25946328]\n",
      " [ 0.09288195  0.36829016]\n",
      " [ 0.34103337  0.13652983]\n",
      " [-0.05165362 -0.2957006 ]\n",
      " [ 0.01573527 -0.42108816]\n",
      " [-0.14394471  0.36315474]\n",
      " [-0.01892534  0.04953724]\n",
      " [ 0.112443    0.12716582]\n",
      " [ 0.26906338  0.24222323]\n",
      " [-0.07433084  0.21387222]\n",
      " [ 0.4193202   0.15005395]\n",
      " [ 0.3231363  -0.2890553 ]\n",
      " [ 0.09068581  0.08261248]\n",
      " [ 0.3709316  -0.30458254]\n",
      " [ 0.04432049 -0.21082339]]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()[0]\n",
    "bias_weights = model.get_weights()[1]\n",
    "print(weights)\n",
    "print(bias_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24235712, 0.19125602]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_neti = np.dot(np.float32(X[0:1]),weights)+bias_weights\n",
    "output_neti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56029445, 0.5476688 ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_acts = 1.0 / (1.0 + np.exp(-output_neti))\n",
    "output_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56029445, 0.5476688 ]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56029445, -0.4523312 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = output_acts - np.float32(Y[0:1])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49272916, 0.4954554 ]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv = 2.0 * np.exp(-output_neti) / np.power(1.0+np.exp(-output_neti),2.0)\n",
    "deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13803671, -0.11205497]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas = error*deriv*(1.0/len(bias_weights))\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09339944, -0.07581947],\n",
       "       [ 0.08641351, -0.07014846],\n",
       "       [ 0.08933941, -0.07252365],\n",
       "       [ 0.05938724, -0.04820917],\n",
       "       [ 0.076275  , -0.06191826],\n",
       "       [ 0.04819695, -0.03912516],\n",
       "       [ 0.04747842, -0.03854187],\n",
       "       [ 0.05674461, -0.04606395],\n",
       "       [ 0.0886795 , -0.07198794],\n",
       "       [ 0.07974227, -0.0647329 ],\n",
       "       [ 0.02640138, -0.02143203],\n",
       "       [ 0.01875151, -0.01522204],\n",
       "       [ 0.01918572, -0.01557452],\n",
       "       [ 0.01467691, -0.01191437],\n",
       "       [ 0.01716923, -0.01393758],\n",
       "       [ 0.01877871, -0.01524412],\n",
       "       [ 0.01293223, -0.01049808],\n",
       "       [ 0.03137793, -0.02547186],\n",
       "       [ 0.03433871, -0.02787535],\n",
       "       [ 0.01543662, -0.01253108],\n",
       "       [ 0.09406719, -0.07636154],\n",
       "       [ 0.08473347, -0.06878465],\n",
       "       [ 0.08401995, -0.06820542],\n",
       "       [ 0.05266422, -0.04275158],\n",
       "       [ 0.07745185, -0.0628736 ],\n",
       "       [ 0.04182852, -0.03395541],\n",
       "       [ 0.06345057, -0.05150769],\n",
       "       [ 0.09278344, -0.07531942],\n",
       "       [ 0.08226471, -0.06678057],\n",
       "       [ 0.06178723, -0.05015743]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_updates = np.outer(np.float32(X[0:1]),deltas)\n",
    "w_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = np.float32(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21963508,  0.08235863],\n",
       "       [-0.24390268, -0.28651336],\n",
       "       [-0.32273233,  0.04278916],\n",
       "       [ 0.23763302,  0.18622503],\n",
       "       [ 0.10275772,  0.4031786 ],\n",
       "       [ 0.17379048,  0.32699648],\n",
       "       [ 0.12472776, -0.38638616],\n",
       "       [ 0.09127244, -0.11566672],\n",
       "       [-0.10711735,  0.1066635 ],\n",
       "       [-0.40730256, -0.3511564 ],\n",
       "       [ 0.3435841 , -0.34328306],\n",
       "       [ 0.29436967,  0.19802317],\n",
       "       [ 0.217365  ,  0.1350343 ],\n",
       "       [-0.18595277,  0.33420643],\n",
       "       [-0.00332808, -0.00146732],\n",
       "       [-0.23134603, -0.25946328],\n",
       "       [ 0.09288195,  0.36829016],\n",
       "       [ 0.34103337,  0.13652983],\n",
       "       [-0.05165362, -0.2957006 ],\n",
       "       [ 0.01573527, -0.42108816],\n",
       "       [-0.14394471,  0.36315474],\n",
       "       [-0.01892534,  0.04953724],\n",
       "       [ 0.112443  ,  0.12716582],\n",
       "       [ 0.26906338,  0.24222323],\n",
       "       [-0.07433084,  0.21387222],\n",
       "       [ 0.4193202 ,  0.15005395],\n",
       "       [ 0.3231363 , -0.2890553 ],\n",
       "       [ 0.09068581,  0.08261248],\n",
       "       [ 0.3709316 , -0.30458254],\n",
       "       [ 0.04432049, -0.21082339]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22430506,  0.0861496 ],\n",
       "       [-0.24822336, -0.28300592],\n",
       "       [-0.3271993 ,  0.04641534],\n",
       "       [ 0.23466365,  0.18863548],\n",
       "       [ 0.09894397,  0.40627453],\n",
       "       [ 0.17138064,  0.32895273],\n",
       "       [ 0.12235384, -0.38445905],\n",
       "       [ 0.08843521, -0.11336352],\n",
       "       [-0.11155133,  0.11026289],\n",
       "       [-0.41128966, -0.34791976],\n",
       "       [ 0.34226403, -0.34221146],\n",
       "       [ 0.2934321 ,  0.19878428],\n",
       "       [ 0.2164057 ,  0.13581301],\n",
       "       [-0.18668662,  0.33480215],\n",
       "       [-0.00418655, -0.00077044],\n",
       "       [-0.23228496, -0.2587011 ],\n",
       "       [ 0.09223533,  0.36881506],\n",
       "       [ 0.3394645 ,  0.13780342],\n",
       "       [-0.05337056, -0.29430684],\n",
       "       [ 0.01496344, -0.4204616 ],\n",
       "       [-0.14864807,  0.3669728 ],\n",
       "       [-0.02316201,  0.05297647],\n",
       "       [ 0.10824201,  0.13057609],\n",
       "       [ 0.26643017,  0.2443608 ],\n",
       "       [-0.07820343,  0.2170159 ],\n",
       "       [ 0.41722876,  0.15175171],\n",
       "       [ 0.31996378, -0.2864799 ],\n",
       "       [ 0.08604664,  0.08637846],\n",
       "       [ 0.36681837, -0.3012435 ],\n",
       "       [ 0.04123113, -0.20831552]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights - eta*w_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00690184,  0.00560275]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_weights - eta*deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.22430505,  0.0861496 ],\n",
       "        [-0.24822336, -0.28300592],\n",
       "        [-0.3271993 ,  0.04641534],\n",
       "        [ 0.23466365,  0.18863548],\n",
       "        [ 0.09894397,  0.40627453],\n",
       "        [ 0.17138064,  0.32895273],\n",
       "        [ 0.12235384, -0.38445905],\n",
       "        [ 0.08843521, -0.11336352],\n",
       "        [-0.11155133,  0.11026289],\n",
       "        [-0.41128966, -0.34791976],\n",
       "        [ 0.34226403, -0.34221146],\n",
       "        [ 0.2934321 ,  0.19878428],\n",
       "        [ 0.2164057 ,  0.13581301],\n",
       "        [-0.18668662,  0.33480215],\n",
       "        [-0.00418655, -0.00077044],\n",
       "        [-0.23228496, -0.2587011 ],\n",
       "        [ 0.09223533,  0.36881506],\n",
       "        [ 0.3394645 ,  0.13780342],\n",
       "        [-0.05337056, -0.29430684],\n",
       "        [ 0.01496344, -0.4204616 ],\n",
       "        [-0.14864807,  0.3669728 ],\n",
       "        [-0.02316201,  0.05297647],\n",
       "        [ 0.10824201,  0.13057609],\n",
       "        [ 0.26643017,  0.2443608 ],\n",
       "        [-0.07820343,  0.2170159 ],\n",
       "        [ 0.41722876,  0.15175171],\n",
       "        [ 0.31996378, -0.2864799 ],\n",
       "        [ 0.08604664,  0.08637846],\n",
       "        [ 0.36681837, -0.3012435 ],\n",
       "        [ 0.04123113, -0.20831552]], dtype=float32),\n",
       " array([-0.00690184,  0.00560275], dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X[0:1],Y[0:1],batch_size=1,epochs=1,verbose=0)\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      "284/284 [==============================] - 0s 288us/step - loss: 0.2671 - acc: 0.2923 - val_loss: 0.2693 - val_acc: 0.2535\n",
      "Epoch 2/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.2628 - acc: 0.3063 - val_loss: 0.2680 - val_acc: 0.2641\n",
      "Epoch 3/100\n",
      "284/284 [==============================] - 0s 57us/step - loss: 0.2592 - acc: 0.3063 - val_loss: 0.2669 - val_acc: 0.2923\n",
      "Epoch 4/100\n",
      "284/284 [==============================] - 0s 56us/step - loss: 0.2557 - acc: 0.4049 - val_loss: 0.2661 - val_acc: 0.3556\n",
      "Epoch 5/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.2528 - acc: 0.5352 - val_loss: 0.2654 - val_acc: 0.4613\n",
      "Epoch 6/100\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.2502 - acc: 0.6092 - val_loss: 0.2649 - val_acc: 0.5176\n",
      "Epoch 7/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.2479 - acc: 0.6585 - val_loss: 0.2645 - val_acc: 0.5528\n",
      "Epoch 8/100\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.2460 - acc: 0.6690 - val_loss: 0.2641 - val_acc: 0.5739\n",
      "Epoch 9/100\n",
      "284/284 [==============================] - 0s 60us/step - loss: 0.2441 - acc: 0.6725 - val_loss: 0.2639 - val_acc: 0.5775\n",
      "Epoch 10/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.2425 - acc: 0.6796 - val_loss: 0.2635 - val_acc: 0.5775\n",
      "Epoch 11/100\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.2411 - acc: 0.6796 - val_loss: 0.2633 - val_acc: 0.5775\n",
      "Epoch 12/100\n",
      "284/284 [==============================] - 0s 147us/step - loss: 0.2397 - acc: 0.6796 - val_loss: 0.2630 - val_acc: 0.5775\n",
      "Epoch 13/100\n",
      "284/284 [==============================] - 0s 130us/step - loss: 0.2385 - acc: 0.6796 - val_loss: 0.2628 - val_acc: 0.5775\n",
      "Epoch 14/100\n",
      "284/284 [==============================] - 0s 63us/step - loss: 0.2373 - acc: 0.6796 - val_loss: 0.2625 - val_acc: 0.5775\n",
      "Epoch 15/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.2363 - acc: 0.6796 - val_loss: 0.2622 - val_acc: 0.5775\n",
      "Epoch 16/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.2354 - acc: 0.6796 - val_loss: 0.2620 - val_acc: 0.5775\n",
      "Epoch 17/100\n",
      "284/284 [==============================] - 0s 56us/step - loss: 0.2344 - acc: 0.6796 - val_loss: 0.2617 - val_acc: 0.5775\n",
      "Epoch 18/100\n",
      "284/284 [==============================] - 0s 56us/step - loss: 0.2335 - acc: 0.6796 - val_loss: 0.2614 - val_acc: 0.5775\n",
      "Epoch 19/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2327 - acc: 0.6796 - val_loss: 0.2611 - val_acc: 0.5775\n",
      "Epoch 20/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2319 - acc: 0.6796 - val_loss: 0.2608 - val_acc: 0.5775\n",
      "Epoch 21/100\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.2312 - acc: 0.6796 - val_loss: 0.2605 - val_acc: 0.5775\n",
      "Epoch 22/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.2304 - acc: 0.6796 - val_loss: 0.2602 - val_acc: 0.5775\n",
      "Epoch 23/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.2296 - acc: 0.6796 - val_loss: 0.2599 - val_acc: 0.5775\n",
      "Epoch 24/100\n",
      "284/284 [==============================] - 0s 60us/step - loss: 0.2291 - acc: 0.6796 - val_loss: 0.2595 - val_acc: 0.5775\n",
      "Epoch 25/100\n",
      "284/284 [==============================] - 0s 46us/step - loss: 0.2283 - acc: 0.6796 - val_loss: 0.2591 - val_acc: 0.5775\n",
      "Epoch 26/100\n",
      "284/284 [==============================] - 0s 48us/step - loss: 0.2277 - acc: 0.6796 - val_loss: 0.2589 - val_acc: 0.5775\n",
      "Epoch 27/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.2270 - acc: 0.6796 - val_loss: 0.2585 - val_acc: 0.5775\n",
      "Epoch 28/100\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.2264 - acc: 0.6796 - val_loss: 0.2581 - val_acc: 0.5775\n",
      "Epoch 29/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.2258 - acc: 0.6796 - val_loss: 0.2576 - val_acc: 0.5775\n",
      "Epoch 30/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2252 - acc: 0.6796 - val_loss: 0.2570 - val_acc: 0.5775\n",
      "Epoch 31/100\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.2246 - acc: 0.6796 - val_loss: 0.2566 - val_acc: 0.5775\n",
      "Epoch 32/100\n",
      "284/284 [==============================] - 0s 48us/step - loss: 0.2240 - acc: 0.6796 - val_loss: 0.2561 - val_acc: 0.5775\n",
      "Epoch 33/100\n",
      "284/284 [==============================] - 0s 48us/step - loss: 0.2235 - acc: 0.6796 - val_loss: 0.2558 - val_acc: 0.5775\n",
      "Epoch 34/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2230 - acc: 0.6796 - val_loss: 0.2555 - val_acc: 0.5775\n",
      "Epoch 35/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.2224 - acc: 0.6796 - val_loss: 0.2549 - val_acc: 0.5775\n",
      "Epoch 36/100\n",
      "284/284 [==============================] - 0s 55us/step - loss: 0.2218 - acc: 0.6796 - val_loss: 0.2545 - val_acc: 0.5775\n",
      "Epoch 37/100\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.2213 - acc: 0.6796 - val_loss: 0.2539 - val_acc: 0.5775\n",
      "Epoch 38/100\n",
      "284/284 [==============================] - 0s 46us/step - loss: 0.2208 - acc: 0.6796 - val_loss: 0.2534 - val_acc: 0.5775\n",
      "Epoch 39/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2202 - acc: 0.6796 - val_loss: 0.2529 - val_acc: 0.5775\n",
      "Epoch 40/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.2197 - acc: 0.6796 - val_loss: 0.2525 - val_acc: 0.5775\n",
      "Epoch 41/100\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.2192 - acc: 0.6796 - val_loss: 0.2519 - val_acc: 0.5775\n",
      "Epoch 42/100\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.2187 - acc: 0.6796 - val_loss: 0.2512 - val_acc: 0.5775\n",
      "Epoch 43/100\n",
      "284/284 [==============================] - 0s 48us/step - loss: 0.2182 - acc: 0.6796 - val_loss: 0.2507 - val_acc: 0.5775\n",
      "Epoch 44/100\n",
      "284/284 [==============================] - 0s 45us/step - loss: 0.2177 - acc: 0.6796 - val_loss: 0.2500 - val_acc: 0.5775\n",
      "Epoch 45/100\n",
      "284/284 [==============================] - 0s 46us/step - loss: 0.2172 - acc: 0.6796 - val_loss: 0.2494 - val_acc: 0.5775\n",
      "Epoch 46/100\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.2167 - acc: 0.6796 - val_loss: 0.2491 - val_acc: 0.5775\n",
      "Epoch 47/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.2162 - acc: 0.6796 - val_loss: 0.2485 - val_acc: 0.5775\n",
      "Epoch 48/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2157 - acc: 0.6796 - val_loss: 0.2481 - val_acc: 0.5775\n",
      "Epoch 49/100\n",
      "284/284 [==============================] - 0s 42us/step - loss: 0.2152 - acc: 0.6796 - val_loss: 0.2473 - val_acc: 0.5775\n",
      "Epoch 50/100\n",
      "284/284 [==============================] - 0s 52us/step - loss: 0.2147 - acc: 0.6796 - val_loss: 0.2466 - val_acc: 0.5775\n",
      "Epoch 51/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2142 - acc: 0.6796 - val_loss: 0.2460 - val_acc: 0.5775\n",
      "Epoch 52/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2138 - acc: 0.6796 - val_loss: 0.2453 - val_acc: 0.5775\n",
      "Epoch 53/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2132 - acc: 0.6796 - val_loss: 0.2447 - val_acc: 0.5775\n",
      "Epoch 54/100\n",
      "284/284 [==============================] - 0s 46us/step - loss: 0.2128 - acc: 0.6796 - val_loss: 0.2438 - val_acc: 0.5775\n",
      "Epoch 55/100\n",
      "284/284 [==============================] - 0s 40us/step - loss: 0.2122 - acc: 0.6796 - val_loss: 0.2433 - val_acc: 0.5775\n",
      "Epoch 56/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2118 - acc: 0.6796 - val_loss: 0.2429 - val_acc: 0.5775\n",
      "Epoch 57/100\n",
      "284/284 [==============================] - 0s 44us/step - loss: 0.2113 - acc: 0.6796 - val_loss: 0.2422 - val_acc: 0.5775\n",
      "Epoch 58/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2108 - acc: 0.6796 - val_loss: 0.2417 - val_acc: 0.5775\n",
      "Epoch 59/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.2104 - acc: 0.6796 - val_loss: 0.2412 - val_acc: 0.5775\n",
      "Epoch 60/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2099 - acc: 0.6796 - val_loss: 0.2407 - val_acc: 0.5775\n",
      "Epoch 61/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.2094 - acc: 0.6796 - val_loss: 0.2398 - val_acc: 0.5775\n",
      "Epoch 62/100\n",
      "284/284 [==============================] - 0s 59us/step - loss: 0.2089 - acc: 0.6796 - val_loss: 0.2391 - val_acc: 0.5775\n",
      "Epoch 63/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.2084 - acc: 0.6796 - val_loss: 0.2383 - val_acc: 0.5775\n",
      "Epoch 64/100\n",
      "284/284 [==============================] - 0s 57us/step - loss: 0.2080 - acc: 0.6796 - val_loss: 0.2379 - val_acc: 0.5775\n",
      "Epoch 65/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2075 - acc: 0.6796 - val_loss: 0.2372 - val_acc: 0.5810\n",
      "Epoch 66/100\n",
      "284/284 [==============================] - 0s 48us/step - loss: 0.2070 - acc: 0.6796 - val_loss: 0.2364 - val_acc: 0.5810\n",
      "Epoch 67/100\n",
      "284/284 [==============================] - 0s 55us/step - loss: 0.2066 - acc: 0.6796 - val_loss: 0.2358 - val_acc: 0.5845\n",
      "Epoch 68/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.2061 - acc: 0.6796 - val_loss: 0.2351 - val_acc: 0.5845\n",
      "Epoch 69/100\n",
      "284/284 [==============================] - 0s 55us/step - loss: 0.2057 - acc: 0.6796 - val_loss: 0.2348 - val_acc: 0.5845\n",
      "Epoch 70/100\n",
      "284/284 [==============================] - 0s 45us/step - loss: 0.2052 - acc: 0.6796 - val_loss: 0.2340 - val_acc: 0.5845\n",
      "Epoch 71/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.2048 - acc: 0.6796 - val_loss: 0.2334 - val_acc: 0.5845\n",
      "Epoch 72/100\n",
      "284/284 [==============================] - 0s 44us/step - loss: 0.2043 - acc: 0.6796 - val_loss: 0.2327 - val_acc: 0.5845\n",
      "Epoch 73/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2038 - acc: 0.6796 - val_loss: 0.2323 - val_acc: 0.5845\n",
      "Epoch 74/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2034 - acc: 0.6796 - val_loss: 0.2318 - val_acc: 0.5845\n",
      "Epoch 75/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.2029 - acc: 0.6796 - val_loss: 0.2310 - val_acc: 0.5845\n",
      "Epoch 76/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2025 - acc: 0.6796 - val_loss: 0.2303 - val_acc: 0.5880\n",
      "Epoch 77/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.2020 - acc: 0.6866 - val_loss: 0.2298 - val_acc: 0.5880\n",
      "Epoch 78/100\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.2016 - acc: 0.6866 - val_loss: 0.2293 - val_acc: 0.5880\n",
      "Epoch 79/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.2011 - acc: 0.6866 - val_loss: 0.2289 - val_acc: 0.5880\n",
      "Epoch 80/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.2007 - acc: 0.6866 - val_loss: 0.2281 - val_acc: 0.5880\n",
      "Epoch 81/100\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.2002 - acc: 0.6866 - val_loss: 0.2275 - val_acc: 0.5951\n",
      "Epoch 82/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1997 - acc: 0.6866 - val_loss: 0.2267 - val_acc: 0.5951\n",
      "Epoch 83/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1993 - acc: 0.6866 - val_loss: 0.2261 - val_acc: 0.5951\n",
      "Epoch 84/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.1989 - acc: 0.6866 - val_loss: 0.2255 - val_acc: 0.5951\n",
      "Epoch 85/100\n",
      "284/284 [==============================] - 0s 59us/step - loss: 0.1984 - acc: 0.6866 - val_loss: 0.2248 - val_acc: 0.5986\n",
      "Epoch 86/100\n",
      "284/284 [==============================] - 0s 54us/step - loss: 0.1980 - acc: 0.6901 - val_loss: 0.2243 - val_acc: 0.5986\n",
      "Epoch 87/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1976 - acc: 0.6901 - val_loss: 0.2235 - val_acc: 0.6021\n",
      "Epoch 88/100\n",
      "284/284 [==============================] - 0s 53us/step - loss: 0.1971 - acc: 0.6937 - val_loss: 0.2228 - val_acc: 0.6021\n",
      "Epoch 89/100\n",
      "284/284 [==============================] - 0s 60us/step - loss: 0.1966 - acc: 0.6937 - val_loss: 0.2224 - val_acc: 0.6021\n",
      "Epoch 90/100\n",
      "284/284 [==============================] - 0s 56us/step - loss: 0.1962 - acc: 0.6937 - val_loss: 0.2217 - val_acc: 0.6021\n",
      "Epoch 91/100\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.1959 - acc: 0.6937 - val_loss: 0.2213 - val_acc: 0.6021\n",
      "Epoch 92/100\n",
      "284/284 [==============================] - 0s 46us/step - loss: 0.1954 - acc: 0.6937 - val_loss: 0.2208 - val_acc: 0.6021\n",
      "Epoch 93/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1950 - acc: 0.6937 - val_loss: 0.2199 - val_acc: 0.6021\n",
      "Epoch 94/100\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.1945 - acc: 0.6937 - val_loss: 0.2195 - val_acc: 0.6092\n",
      "Epoch 95/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.1941 - acc: 0.6972 - val_loss: 0.2191 - val_acc: 0.6092\n",
      "Epoch 96/100\n",
      "284/284 [==============================] - 0s 47us/step - loss: 0.1937 - acc: 0.6937 - val_loss: 0.2184 - val_acc: 0.6092\n",
      "Epoch 97/100\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1933 - acc: 0.6972 - val_loss: 0.2178 - val_acc: 0.6092\n",
      "Epoch 98/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.1929 - acc: 0.6972 - val_loss: 0.2172 - val_acc: 0.6092\n",
      "Epoch 99/100\n",
      "284/284 [==============================] - 0s 51us/step - loss: 0.1925 - acc: 0.6972 - val_loss: 0.2166 - val_acc: 0.6162\n",
      "Epoch 100/100\n",
      "284/284 [==============================] - 0s 50us/step - loss: 0.1921 - acc: 0.7007 - val_loss: 0.2160 - val_acc: 0.6162\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      "284/284 [==============================] - 0s 111us/step - loss: 0.1916 - acc: 0.7007 - val_loss: 0.2154 - val_acc: 0.6197\n",
      "Epoch 2/100\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1912 - acc: 0.7007 - val_loss: 0.2148 - val_acc: 0.6197\n",
      "Epoch 3/100\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1909 - acc: 0.7007 - val_loss: 0.2142 - val_acc: 0.6232\n",
      "Epoch 4/100\n",
      "284/284 [==============================] - 0s 102us/step - loss: 0.1904 - acc: 0.7007 - val_loss: 0.2136 - val_acc: 0.6268\n",
      "Epoch 5/100\n",
      "284/284 [==============================] - 0s 134us/step - loss: 0.1900 - acc: 0.7042 - val_loss: 0.2131 - val_acc: 0.6268\n",
      "Epoch 6/100\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1896 - acc: 0.7042 - val_loss: 0.2126 - val_acc: 0.6268\n",
      "Epoch 7/100\n",
      "284/284 [==============================] - 0s 181us/step - loss: 0.1892 - acc: 0.7042 - val_loss: 0.2120 - val_acc: 0.6268\n",
      "Epoch 8/100\n",
      "284/284 [==============================] - 0s 138us/step - loss: 0.1888 - acc: 0.7042 - val_loss: 0.2114 - val_acc: 0.6268\n",
      "Epoch 9/100\n",
      "284/284 [==============================] - 0s 88us/step - loss: 0.1884 - acc: 0.7042 - val_loss: 0.2109 - val_acc: 0.6303\n",
      "Epoch 10/100\n",
      "284/284 [==============================] - 0s 120us/step - loss: 0.1879 - acc: 0.7042 - val_loss: 0.2102 - val_acc: 0.6338\n",
      "Epoch 11/100\n",
      "284/284 [==============================] - 0s 84us/step - loss: 0.1876 - acc: 0.7042 - val_loss: 0.2096 - val_acc: 0.6373\n",
      "Epoch 12/100\n",
      "284/284 [==============================] - 0s 88us/step - loss: 0.1871 - acc: 0.7077 - val_loss: 0.2093 - val_acc: 0.6373\n",
      "Epoch 13/100\n",
      "284/284 [==============================] - 0s 188us/step - loss: 0.1867 - acc: 0.7113 - val_loss: 0.2087 - val_acc: 0.6373\n",
      "Epoch 14/100\n",
      "284/284 [==============================] - 0s 133us/step - loss: 0.1864 - acc: 0.7148 - val_loss: 0.2081 - val_acc: 0.6444\n",
      "Epoch 15/100\n",
      "284/284 [==============================] - 0s 101us/step - loss: 0.1860 - acc: 0.7148 - val_loss: 0.2076 - val_acc: 0.6444\n",
      "Epoch 16/100\n",
      "284/284 [==============================] - 0s 112us/step - loss: 0.1856 - acc: 0.7183 - val_loss: 0.2073 - val_acc: 0.6444\n",
      "Epoch 17/100\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1852 - acc: 0.7183 - val_loss: 0.2069 - val_acc: 0.6444\n",
      "Epoch 18/100\n",
      "284/284 [==============================] - 0s 76us/step - loss: 0.1849 - acc: 0.7183 - val_loss: 0.2066 - val_acc: 0.6444\n",
      "Epoch 19/100\n",
      "284/284 [==============================] - 0s 91us/step - loss: 0.1846 - acc: 0.7183 - val_loss: 0.2062 - val_acc: 0.6444\n",
      "Epoch 20/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1841 - acc: 0.7183 - val_loss: 0.2058 - val_acc: 0.6444\n",
      "Epoch 21/100\n",
      "284/284 [==============================] - 0s 87us/step - loss: 0.1837 - acc: 0.7183 - val_loss: 0.2053 - val_acc: 0.6514\n",
      "Epoch 22/100\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1834 - acc: 0.7183 - val_loss: 0.2050 - val_acc: 0.6514\n",
      "Epoch 23/100\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1830 - acc: 0.7183 - val_loss: 0.2040 - val_acc: 0.6514\n",
      "Epoch 24/100\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.1825 - acc: 0.7183 - val_loss: 0.2035 - val_acc: 0.6514\n",
      "Epoch 25/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1823 - acc: 0.7183 - val_loss: 0.2032 - val_acc: 0.6514\n",
      "Epoch 26/100\n",
      "284/284 [==============================] - 0s 90us/step - loss: 0.1818 - acc: 0.7183 - val_loss: 0.2028 - val_acc: 0.6514\n",
      "Epoch 27/100\n",
      "284/284 [==============================] - 0s 100us/step - loss: 0.1815 - acc: 0.7183 - val_loss: 0.2022 - val_acc: 0.6514\n",
      "Epoch 28/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1812 - acc: 0.7254 - val_loss: 0.2017 - val_acc: 0.6514\n",
      "Epoch 29/100\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1808 - acc: 0.7183 - val_loss: 0.2011 - val_acc: 0.6585\n",
      "Epoch 30/100\n",
      "284/284 [==============================] - 0s 92us/step - loss: 0.1804 - acc: 0.7359 - val_loss: 0.2006 - val_acc: 0.6620\n",
      "Epoch 31/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1800 - acc: 0.7359 - val_loss: 0.2001 - val_acc: 0.6655\n",
      "Epoch 32/100\n",
      "284/284 [==============================] - 0s 105us/step - loss: 0.1796 - acc: 0.7359 - val_loss: 0.1994 - val_acc: 0.6725\n",
      "Epoch 33/100\n",
      "284/284 [==============================] - 0s 84us/step - loss: 0.1792 - acc: 0.7430 - val_loss: 0.1990 - val_acc: 0.6761\n",
      "Epoch 34/100\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.1789 - acc: 0.7465 - val_loss: 0.1987 - val_acc: 0.6761\n",
      "Epoch 35/100\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1785 - acc: 0.7430 - val_loss: 0.1981 - val_acc: 0.6796\n",
      "Epoch 36/100\n",
      "284/284 [==============================] - 0s 88us/step - loss: 0.1782 - acc: 0.7465 - val_loss: 0.1976 - val_acc: 0.6831\n",
      "Epoch 37/100\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1778 - acc: 0.7465 - val_loss: 0.1970 - val_acc: 0.6831\n",
      "Epoch 38/100\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1775 - acc: 0.7500 - val_loss: 0.1966 - val_acc: 0.6866\n",
      "Epoch 39/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1771 - acc: 0.7535 - val_loss: 0.1960 - val_acc: 0.6866\n",
      "Epoch 40/100\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1768 - acc: 0.7570 - val_loss: 0.1956 - val_acc: 0.6866\n",
      "Epoch 41/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1764 - acc: 0.7570 - val_loss: 0.1952 - val_acc: 0.6866\n",
      "Epoch 42/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1761 - acc: 0.7570 - val_loss: 0.1948 - val_acc: 0.6866\n",
      "Epoch 43/100\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1758 - acc: 0.7570 - val_loss: 0.1943 - val_acc: 0.6937\n",
      "Epoch 44/100\n",
      "284/284 [==============================] - 0s 76us/step - loss: 0.1754 - acc: 0.7570 - val_loss: 0.1939 - val_acc: 0.6937\n",
      "Epoch 45/100\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1751 - acc: 0.7570 - val_loss: 0.1933 - val_acc: 0.6972\n",
      "Epoch 46/100\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.1747 - acc: 0.7570 - val_loss: 0.1929 - val_acc: 0.7007\n",
      "Epoch 47/100\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.1744 - acc: 0.7570 - val_loss: 0.1925 - val_acc: 0.7007\n",
      "Epoch 48/100\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.1740 - acc: 0.7570 - val_loss: 0.1919 - val_acc: 0.7042\n",
      "Epoch 49/100\n",
      "284/284 [==============================] - 0s 109us/step - loss: 0.1737 - acc: 0.7606 - val_loss: 0.1914 - val_acc: 0.7077\n",
      "Epoch 50/100\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1734 - acc: 0.7676 - val_loss: 0.1910 - val_acc: 0.7077\n",
      "Epoch 51/100\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1731 - acc: 0.7606 - val_loss: 0.1907 - val_acc: 0.7077\n",
      "Epoch 52/100\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.1727 - acc: 0.7606 - val_loss: 0.1901 - val_acc: 0.7113\n",
      "Epoch 53/100\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1724 - acc: 0.7641 - val_loss: 0.1896 - val_acc: 0.7148\n",
      "Epoch 54/100\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1720 - acc: 0.7711 - val_loss: 0.1892 - val_acc: 0.7183\n",
      "Epoch 55/100\n",
      "284/284 [==============================] - 0s 78us/step - loss: 0.1717 - acc: 0.7782 - val_loss: 0.1889 - val_acc: 0.7148\n",
      "Epoch 56/100\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1714 - acc: 0.7746 - val_loss: 0.1885 - val_acc: 0.7183\n",
      "Epoch 57/100\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1710 - acc: 0.7782 - val_loss: 0.1881 - val_acc: 0.7183\n",
      "Epoch 58/100\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1708 - acc: 0.7817 - val_loss: 0.1877 - val_acc: 0.7183\n",
      "Epoch 59/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1704 - acc: 0.7817 - val_loss: 0.1874 - val_acc: 0.7218\n",
      "Epoch 60/100\n",
      "284/284 [==============================] - 0s 84us/step - loss: 0.1701 - acc: 0.7817 - val_loss: 0.1869 - val_acc: 0.7218\n",
      "Epoch 61/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1698 - acc: 0.7817 - val_loss: 0.1865 - val_acc: 0.7218\n",
      "Epoch 62/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1695 - acc: 0.7817 - val_loss: 0.1863 - val_acc: 0.7218\n",
      "Epoch 63/100\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1692 - acc: 0.7817 - val_loss: 0.1859 - val_acc: 0.7218\n",
      "Epoch 64/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1689 - acc: 0.7817 - val_loss: 0.1856 - val_acc: 0.7218\n",
      "Epoch 65/100\n",
      "284/284 [==============================] - 0s 100us/step - loss: 0.1686 - acc: 0.7817 - val_loss: 0.1851 - val_acc: 0.7289\n",
      "Epoch 66/100\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1682 - acc: 0.7817 - val_loss: 0.1847 - val_acc: 0.7289\n",
      "Epoch 67/100\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1679 - acc: 0.7817 - val_loss: 0.1842 - val_acc: 0.7289\n",
      "Epoch 68/100\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.1676 - acc: 0.7852 - val_loss: 0.1838 - val_acc: 0.7324\n",
      "Epoch 69/100\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.1673 - acc: 0.7852 - val_loss: 0.1835 - val_acc: 0.7324\n",
      "Epoch 70/100\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1671 - acc: 0.7852 - val_loss: 0.1832 - val_acc: 0.7324\n",
      "Epoch 71/100\n",
      "284/284 [==============================] - 0s 59us/step - loss: 0.1667 - acc: 0.7852 - val_loss: 0.1828 - val_acc: 0.7324\n",
      "Epoch 72/100\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.1664 - acc: 0.7852 - val_loss: 0.1824 - val_acc: 0.7324\n",
      "Epoch 73/100\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1662 - acc: 0.7852 - val_loss: 0.1820 - val_acc: 0.7359\n",
      "Epoch 74/100\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.1658 - acc: 0.7887 - val_loss: 0.1816 - val_acc: 0.7394\n",
      "Epoch 75/100\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1655 - acc: 0.7887 - val_loss: 0.1811 - val_acc: 0.7430\n",
      "Epoch 76/100\n",
      "284/284 [==============================] - 0s 78us/step - loss: 0.1652 - acc: 0.7887 - val_loss: 0.1807 - val_acc: 0.7430\n",
      "Epoch 77/100\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1649 - acc: 0.7958 - val_loss: 0.1804 - val_acc: 0.7430\n",
      "Epoch 78/100\n",
      "284/284 [==============================] - 0s 92us/step - loss: 0.1646 - acc: 0.7958 - val_loss: 0.1801 - val_acc: 0.7430\n",
      "Epoch 79/100\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.1643 - acc: 0.7958 - val_loss: 0.1797 - val_acc: 0.7465\n",
      "Epoch 80/100\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1641 - acc: 0.7958 - val_loss: 0.1793 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "284/284 [==============================] - 0s 105us/step - loss: 0.1638 - acc: 0.7993 - val_loss: 0.1786 - val_acc: 0.7535\n",
      "Epoch 82/100\n",
      "284/284 [==============================] - 0s 100us/step - loss: 0.1634 - acc: 0.8028 - val_loss: 0.1783 - val_acc: 0.7570\n",
      "Epoch 83/100\n",
      "284/284 [==============================] - 0s 84us/step - loss: 0.1632 - acc: 0.7993 - val_loss: 0.1779 - val_acc: 0.7606\n",
      "Epoch 84/100\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1629 - acc: 0.8028 - val_loss: 0.1775 - val_acc: 0.7641\n",
      "Epoch 85/100\n",
      "284/284 [==============================] - 0s 80us/step - loss: 0.1626 - acc: 0.8028 - val_loss: 0.1771 - val_acc: 0.7676\n",
      "Epoch 86/100\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1623 - acc: 0.8028 - val_loss: 0.1765 - val_acc: 0.7711\n",
      "Epoch 87/100\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1620 - acc: 0.8063 - val_loss: 0.1762 - val_acc: 0.7711\n",
      "Epoch 88/100\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1617 - acc: 0.8063 - val_loss: 0.1759 - val_acc: 0.7711\n",
      "Epoch 89/100\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1614 - acc: 0.8063 - val_loss: 0.1756 - val_acc: 0.7711\n",
      "Epoch 90/100\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.1612 - acc: 0.8063 - val_loss: 0.1753 - val_acc: 0.7711\n",
      "Epoch 91/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1610 - acc: 0.8134 - val_loss: 0.1750 - val_acc: 0.7746\n",
      "Epoch 92/100\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1606 - acc: 0.8099 - val_loss: 0.1746 - val_acc: 0.7782\n",
      "Epoch 93/100\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1604 - acc: 0.8134 - val_loss: 0.1742 - val_acc: 0.7782\n",
      "Epoch 94/100\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1601 - acc: 0.8134 - val_loss: 0.1738 - val_acc: 0.7817\n",
      "Epoch 95/100\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1599 - acc: 0.8169 - val_loss: 0.1735 - val_acc: 0.7817\n",
      "Epoch 96/100\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1595 - acc: 0.8134 - val_loss: 0.1732 - val_acc: 0.7852\n",
      "Epoch 97/100\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1593 - acc: 0.8134 - val_loss: 0.1729 - val_acc: 0.7852\n",
      "Epoch 98/100\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1591 - acc: 0.8134 - val_loss: 0.1727 - val_acc: 0.7852\n",
      "Epoch 99/100\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1588 - acc: 0.8169 - val_loss: 0.1725 - val_acc: 0.7852\n",
      "Epoch 100/100\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1585 - acc: 0.8134 - val_loss: 0.1719 - val_acc: 0.7923\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "# Train the model and record the training\n",
    "# history for later examination\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/50\n",
      "284/284 [==============================] - 0s 126us/step - loss: 0.1582 - acc: 0.8169 - val_loss: 0.1716 - val_acc: 0.7923\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1580 - acc: 0.8204 - val_loss: 0.1714 - val_acc: 0.7923\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 0s 88us/step - loss: 0.1577 - acc: 0.8204 - val_loss: 0.1711 - val_acc: 0.7923\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 0s 121us/step - loss: 0.1575 - acc: 0.8204 - val_loss: 0.1707 - val_acc: 0.7923\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 0s 150us/step - loss: 0.1572 - acc: 0.8204 - val_loss: 0.1704 - val_acc: 0.7958\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 0s 156us/step - loss: 0.1570 - acc: 0.8204 - val_loss: 0.1699 - val_acc: 0.7958\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 0s 124us/step - loss: 0.1566 - acc: 0.8204 - val_loss: 0.1695 - val_acc: 0.7993\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 0s 134us/step - loss: 0.1564 - acc: 0.8239 - val_loss: 0.1691 - val_acc: 0.7993\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 0s 199us/step - loss: 0.1561 - acc: 0.8239 - val_loss: 0.1688 - val_acc: 0.7993\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 0s 220us/step - loss: 0.1559 - acc: 0.8239 - val_loss: 0.1684 - val_acc: 0.7993\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 0s 97us/step - loss: 0.1557 - acc: 0.8239 - val_loss: 0.1682 - val_acc: 0.7993\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1554 - acc: 0.8239 - val_loss: 0.1678 - val_acc: 0.8028\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 0s 84us/step - loss: 0.1551 - acc: 0.8275 - val_loss: 0.1677 - val_acc: 0.8028\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 0s 80us/step - loss: 0.1549 - acc: 0.8239 - val_loss: 0.1672 - val_acc: 0.8028\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1546 - acc: 0.8310 - val_loss: 0.1669 - val_acc: 0.8063\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1544 - acc: 0.8345 - val_loss: 0.1667 - val_acc: 0.8063\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1541 - acc: 0.8310 - val_loss: 0.1662 - val_acc: 0.8063\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1539 - acc: 0.8380 - val_loss: 0.1657 - val_acc: 0.8099\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1536 - acc: 0.8380 - val_loss: 0.1655 - val_acc: 0.8099\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.1534 - acc: 0.8380 - val_loss: 0.1652 - val_acc: 0.8099\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1532 - acc: 0.8380 - val_loss: 0.1648 - val_acc: 0.8134\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1529 - acc: 0.8380 - val_loss: 0.1645 - val_acc: 0.8134\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1527 - acc: 0.8380 - val_loss: 0.1642 - val_acc: 0.8134\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1524 - acc: 0.8380 - val_loss: 0.1639 - val_acc: 0.8134\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 0s 90us/step - loss: 0.1522 - acc: 0.8415 - val_loss: 0.1634 - val_acc: 0.8239\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1520 - acc: 0.8415 - val_loss: 0.1632 - val_acc: 0.8239\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 0s 77us/step - loss: 0.1518 - acc: 0.8415 - val_loss: 0.1628 - val_acc: 0.8310\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1515 - acc: 0.8451 - val_loss: 0.1623 - val_acc: 0.8310\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1513 - acc: 0.8451 - val_loss: 0.1622 - val_acc: 0.8310\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1510 - acc: 0.8451 - val_loss: 0.1619 - val_acc: 0.8310\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 0s 68us/step - loss: 0.1508 - acc: 0.8451 - val_loss: 0.1615 - val_acc: 0.8310\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 0s 80us/step - loss: 0.1506 - acc: 0.8451 - val_loss: 0.1611 - val_acc: 0.8310\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 0s 76us/step - loss: 0.1503 - acc: 0.8451 - val_loss: 0.1609 - val_acc: 0.8310\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1501 - acc: 0.8451 - val_loss: 0.1606 - val_acc: 0.8310\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 0s 99us/step - loss: 0.1499 - acc: 0.8451 - val_loss: 0.1602 - val_acc: 0.8310\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1497 - acc: 0.8451 - val_loss: 0.1599 - val_acc: 0.8380\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1494 - acc: 0.8451 - val_loss: 0.1595 - val_acc: 0.8380\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1492 - acc: 0.8486 - val_loss: 0.1593 - val_acc: 0.8380\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1490 - acc: 0.8486 - val_loss: 0.1591 - val_acc: 0.8380\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.1487 - acc: 0.8486 - val_loss: 0.1588 - val_acc: 0.8380\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 0s 62us/step - loss: 0.1486 - acc: 0.8486 - val_loss: 0.1585 - val_acc: 0.8415\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 0s 65us/step - loss: 0.1483 - acc: 0.8486 - val_loss: 0.1583 - val_acc: 0.8415\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1481 - acc: 0.8486 - val_loss: 0.1579 - val_acc: 0.8415\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1479 - acc: 0.8486 - val_loss: 0.1578 - val_acc: 0.8415\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1476 - acc: 0.8486 - val_loss: 0.1575 - val_acc: 0.8415\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1475 - acc: 0.8486 - val_loss: 0.1574 - val_acc: 0.8415\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1472 - acc: 0.8486 - val_loss: 0.1572 - val_acc: 0.8415\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1470 - acc: 0.8486 - val_loss: 0.1570 - val_acc: 0.8415\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 0s 193us/step - loss: 0.1468 - acc: 0.8486 - val_loss: 0.1567 - val_acc: 0.8415\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1466 - acc: 0.8486 - val_loss: 0.1566 - val_acc: 0.8415\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/50\n",
      "284/284 [==============================] - 0s 113us/step - loss: 0.1464 - acc: 0.8486 - val_loss: 0.1563 - val_acc: 0.8415\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1462 - acc: 0.8486 - val_loss: 0.1560 - val_acc: 0.8415\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 0s 59us/step - loss: 0.1460 - acc: 0.8486 - val_loss: 0.1557 - val_acc: 0.8415\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1458 - acc: 0.8486 - val_loss: 0.1554 - val_acc: 0.8415\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 0s 79us/step - loss: 0.1455 - acc: 0.8486 - val_loss: 0.1552 - val_acc: 0.8415\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 0s 128us/step - loss: 0.1453 - acc: 0.8486 - val_loss: 0.1549 - val_acc: 0.8415\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 0s 126us/step - loss: 0.1451 - acc: 0.8486 - val_loss: 0.1547 - val_acc: 0.8415\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 0s 79us/step - loss: 0.1449 - acc: 0.8486 - val_loss: 0.1544 - val_acc: 0.8451\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1447 - acc: 0.8486 - val_loss: 0.1541 - val_acc: 0.8486\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1445 - acc: 0.8486 - val_loss: 0.1538 - val_acc: 0.8486\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1443 - acc: 0.8486 - val_loss: 0.1536 - val_acc: 0.8486\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 0s 156us/step - loss: 0.1441 - acc: 0.8486 - val_loss: 0.1534 - val_acc: 0.8486\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1439 - acc: 0.8486 - val_loss: 0.1531 - val_acc: 0.8486\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 0s 123us/step - loss: 0.1437 - acc: 0.8486 - val_loss: 0.1528 - val_acc: 0.8486\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 0s 163us/step - loss: 0.1435 - acc: 0.8486 - val_loss: 0.1524 - val_acc: 0.8521\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1433 - acc: 0.8486 - val_loss: 0.1522 - val_acc: 0.8521\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1431 - acc: 0.8486 - val_loss: 0.1519 - val_acc: 0.8521\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 0s 90us/step - loss: 0.1429 - acc: 0.8486 - val_loss: 0.1516 - val_acc: 0.8521\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1427 - acc: 0.8521 - val_loss: 0.1514 - val_acc: 0.8521\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1425 - acc: 0.8521 - val_loss: 0.1510 - val_acc: 0.8521\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 0s 73us/step - loss: 0.1423 - acc: 0.8556 - val_loss: 0.1508 - val_acc: 0.8556\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1421 - acc: 0.8556 - val_loss: 0.1505 - val_acc: 0.8556\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1419 - acc: 0.8592 - val_loss: 0.1504 - val_acc: 0.8556\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1418 - acc: 0.8592 - val_loss: 0.1501 - val_acc: 0.8556\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 0s 78us/step - loss: 0.1416 - acc: 0.8592 - val_loss: 0.1500 - val_acc: 0.8556\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1414 - acc: 0.8592 - val_loss: 0.1499 - val_acc: 0.8556\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 0s 125us/step - loss: 0.1412 - acc: 0.8521 - val_loss: 0.1497 - val_acc: 0.8556\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 0s 100us/step - loss: 0.1410 - acc: 0.8556 - val_loss: 0.1495 - val_acc: 0.8556\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1408 - acc: 0.8521 - val_loss: 0.1493 - val_acc: 0.8556\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1406 - acc: 0.8521 - val_loss: 0.1490 - val_acc: 0.8556\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 0s 62us/step - loss: 0.1404 - acc: 0.8592 - val_loss: 0.1488 - val_acc: 0.8556\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 0s 79us/step - loss: 0.1402 - acc: 0.8556 - val_loss: 0.1486 - val_acc: 0.8556\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1400 - acc: 0.8556 - val_loss: 0.1483 - val_acc: 0.8556\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 0s 63us/step - loss: 0.1399 - acc: 0.8592 - val_loss: 0.1481 - val_acc: 0.8556\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1397 - acc: 0.8592 - val_loss: 0.1479 - val_acc: 0.8556\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 0s 49us/step - loss: 0.1395 - acc: 0.8592 - val_loss: 0.1475 - val_acc: 0.8556\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1393 - acc: 0.8627 - val_loss: 0.1473 - val_acc: 0.8556\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 0s 56us/step - loss: 0.1391 - acc: 0.8662 - val_loss: 0.1472 - val_acc: 0.8556\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1389 - acc: 0.8627 - val_loss: 0.1470 - val_acc: 0.8556\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1388 - acc: 0.8627 - val_loss: 0.1467 - val_acc: 0.8556\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 0s 67us/step - loss: 0.1386 - acc: 0.8662 - val_loss: 0.1466 - val_acc: 0.8556\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 0s 58us/step - loss: 0.1384 - acc: 0.8627 - val_loss: 0.1464 - val_acc: 0.8556\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 0s 60us/step - loss: 0.1382 - acc: 0.8627 - val_loss: 0.1460 - val_acc: 0.8592\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 0s 72us/step - loss: 0.1380 - acc: 0.8662 - val_loss: 0.1458 - val_acc: 0.8592\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 0s 61us/step - loss: 0.1379 - acc: 0.8662 - val_loss: 0.1455 - val_acc: 0.8627\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 0s 55us/step - loss: 0.1377 - acc: 0.8662 - val_loss: 0.1454 - val_acc: 0.8627\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1375 - acc: 0.8662 - val_loss: 0.1451 - val_acc: 0.8627\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1374 - acc: 0.8697 - val_loss: 0.1449 - val_acc: 0.8627\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 0s 66us/step - loss: 0.1372 - acc: 0.8732 - val_loss: 0.1446 - val_acc: 0.8662\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1370 - acc: 0.8697 - val_loss: 0.1443 - val_acc: 0.8662\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      "284/284 [==============================] - 0s 120us/step - loss: 0.1369 - acc: 0.8803 - val_loss: 0.1441 - val_acc: 0.8662\n",
      "Epoch 2/100\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1367 - acc: 0.8803 - val_loss: 0.1439 - val_acc: 0.8662\n",
      "Epoch 3/100\n",
      "284/284 [==============================] - 0s 125us/step - loss: 0.1365 - acc: 0.8803 - val_loss: 0.1438 - val_acc: 0.8662\n",
      "Epoch 4/100\n",
      "284/284 [==============================] - 0s 107us/step - loss: 0.1363 - acc: 0.8803 - val_loss: 0.1436 - val_acc: 0.8662\n",
      "Epoch 5/100\n",
      "284/284 [==============================] - 0s 179us/step - loss: 0.1362 - acc: 0.8803 - val_loss: 0.1435 - val_acc: 0.8662\n",
      "Epoch 6/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1360 - acc: 0.8803 - val_loss: 0.1433 - val_acc: 0.8662\n",
      "Epoch 7/100\n",
      "284/284 [==============================] - 0s 123us/step - loss: 0.1358 - acc: 0.8803 - val_loss: 0.1431 - val_acc: 0.8662\n",
      "Epoch 8/100\n",
      "284/284 [==============================] - 0s 132us/step - loss: 0.1357 - acc: 0.8803 - val_loss: 0.1430 - val_acc: 0.8662\n",
      "Epoch 9/100\n",
      "284/284 [==============================] - 0s 94us/step - loss: 0.1355 - acc: 0.8803 - val_loss: 0.1427 - val_acc: 0.8662\n",
      "Epoch 10/100\n",
      "284/284 [==============================] - 0s 115us/step - loss: 0.1353 - acc: 0.8803 - val_loss: 0.1424 - val_acc: 0.8662\n",
      "Epoch 11/100\n",
      "284/284 [==============================] - 0s 206us/step - loss: 0.1352 - acc: 0.8803 - val_loss: 0.1422 - val_acc: 0.8662\n",
      "Epoch 12/100\n",
      "284/284 [==============================] - 0s 97us/step - loss: 0.1350 - acc: 0.8803 - val_loss: 0.1420 - val_acc: 0.8662\n",
      "Epoch 13/100\n",
      "284/284 [==============================] - 0s 104us/step - loss: 0.1348 - acc: 0.8803 - val_loss: 0.1418 - val_acc: 0.8697\n",
      "Epoch 14/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1347 - acc: 0.8803 - val_loss: 0.1416 - val_acc: 0.8697\n",
      "Epoch 15/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1345 - acc: 0.8803 - val_loss: 0.1414 - val_acc: 0.8697\n",
      "Epoch 16/100\n",
      "284/284 [==============================] - 0s 168us/step - loss: 0.1343 - acc: 0.8803 - val_loss: 0.1412 - val_acc: 0.8697\n",
      "Epoch 17/100\n",
      "284/284 [==============================] - 0s 135us/step - loss: 0.1342 - acc: 0.8803 - val_loss: 0.1409 - val_acc: 0.8697\n",
      "Epoch 18/100\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1340 - acc: 0.8803 - val_loss: 0.1407 - val_acc: 0.8697\n",
      "Epoch 19/100\n",
      "284/284 [==============================] - 0s 102us/step - loss: 0.1339 - acc: 0.8803 - val_loss: 0.1405 - val_acc: 0.8697\n",
      "Epoch 20/100\n",
      "284/284 [==============================] - 0s 108us/step - loss: 0.1337 - acc: 0.8803 - val_loss: 0.1404 - val_acc: 0.8697\n",
      "Epoch 21/100\n",
      "284/284 [==============================] - 0s 87us/step - loss: 0.1336 - acc: 0.8803 - val_loss: 0.1402 - val_acc: 0.8697\n",
      "Epoch 22/100\n",
      "284/284 [==============================] - 0s 229us/step - loss: 0.1334 - acc: 0.8803 - val_loss: 0.1399 - val_acc: 0.8697\n",
      "Epoch 23/100\n",
      "284/284 [==============================] - 0s 131us/step - loss: 0.1332 - acc: 0.8803 - val_loss: 0.1398 - val_acc: 0.8697\n",
      "Epoch 24/100\n",
      "284/284 [==============================] - 0s 127us/step - loss: 0.1331 - acc: 0.8803 - val_loss: 0.1396 - val_acc: 0.8697\n",
      "Epoch 25/100\n",
      "284/284 [==============================] - 0s 91us/step - loss: 0.1329 - acc: 0.8803 - val_loss: 0.1394 - val_acc: 0.8697\n",
      "Epoch 26/100\n",
      "284/284 [==============================] - 0s 131us/step - loss: 0.1328 - acc: 0.8803 - val_loss: 0.1392 - val_acc: 0.8697\n",
      "Epoch 27/100\n",
      "284/284 [==============================] - 0s 112us/step - loss: 0.1326 - acc: 0.8803 - val_loss: 0.1389 - val_acc: 0.8697\n",
      "Epoch 28/100\n",
      "284/284 [==============================] - 0s 124us/step - loss: 0.1324 - acc: 0.8803 - val_loss: 0.1387 - val_acc: 0.8697\n",
      "Epoch 29/100\n",
      "284/284 [==============================] - 0s 119us/step - loss: 0.1323 - acc: 0.8803 - val_loss: 0.1385 - val_acc: 0.8697\n",
      "Epoch 30/100\n",
      "284/284 [==============================] - 0s 227us/step - loss: 0.1322 - acc: 0.8803 - val_loss: 0.1384 - val_acc: 0.8697\n",
      "Epoch 31/100\n",
      "284/284 [==============================] - 0s 129us/step - loss: 0.1320 - acc: 0.8803 - val_loss: 0.1383 - val_acc: 0.8697\n",
      "Epoch 32/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1319 - acc: 0.8803 - val_loss: 0.1381 - val_acc: 0.8697\n",
      "Epoch 33/100\n",
      "284/284 [==============================] - 0s 85us/step - loss: 0.1317 - acc: 0.8803 - val_loss: 0.1379 - val_acc: 0.8697\n",
      "Epoch 34/100\n",
      "284/284 [==============================] - 0s 81us/step - loss: 0.1315 - acc: 0.8803 - val_loss: 0.1376 - val_acc: 0.8697\n",
      "Epoch 35/100\n",
      "284/284 [==============================] - 0s 90us/step - loss: 0.1314 - acc: 0.8803 - val_loss: 0.1373 - val_acc: 0.8697\n",
      "Epoch 36/100\n",
      "284/284 [==============================] - 0s 138us/step - loss: 0.1313 - acc: 0.8768 - val_loss: 0.1371 - val_acc: 0.8697\n",
      "Epoch 37/100\n",
      "284/284 [==============================] - 0s 106us/step - loss: 0.1311 - acc: 0.8768 - val_loss: 0.1370 - val_acc: 0.8697\n",
      "Epoch 38/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1309 - acc: 0.8838 - val_loss: 0.1369 - val_acc: 0.8697\n",
      "Epoch 39/100\n",
      "284/284 [==============================] - 0s 165us/step - loss: 0.1308 - acc: 0.8803 - val_loss: 0.1367 - val_acc: 0.8697\n",
      "Epoch 40/100\n",
      "284/284 [==============================] - 0s 132us/step - loss: 0.1307 - acc: 0.8803 - val_loss: 0.1366 - val_acc: 0.8697\n",
      "Epoch 41/100\n",
      "284/284 [==============================] - 0s 122us/step - loss: 0.1305 - acc: 0.8803 - val_loss: 0.1364 - val_acc: 0.8697\n",
      "Epoch 42/100\n",
      "284/284 [==============================] - 0s 134us/step - loss: 0.1304 - acc: 0.8803 - val_loss: 0.1361 - val_acc: 0.8697\n",
      "Epoch 43/100\n",
      "284/284 [==============================] - 0s 87us/step - loss: 0.1302 - acc: 0.8803 - val_loss: 0.1359 - val_acc: 0.8697\n",
      "Epoch 44/100\n",
      "284/284 [==============================] - 0s 160us/step - loss: 0.1301 - acc: 0.8803 - val_loss: 0.1358 - val_acc: 0.8697\n",
      "Epoch 45/100\n",
      "284/284 [==============================] - 0s 124us/step - loss: 0.1299 - acc: 0.8803 - val_loss: 0.1356 - val_acc: 0.8697\n",
      "Epoch 46/100\n",
      "284/284 [==============================] - 0s 119us/step - loss: 0.1298 - acc: 0.8803 - val_loss: 0.1354 - val_acc: 0.8697\n",
      "Epoch 47/100\n",
      "284/284 [==============================] - 0s 109us/step - loss: 0.1296 - acc: 0.8803 - val_loss: 0.1352 - val_acc: 0.8732\n",
      "Epoch 48/100\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1295 - acc: 0.8803 - val_loss: 0.1350 - val_acc: 0.8697\n",
      "Epoch 49/100\n",
      "284/284 [==============================] - 0s 83us/step - loss: 0.1293 - acc: 0.8803 - val_loss: 0.1349 - val_acc: 0.8697\n",
      "Epoch 50/100\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1292 - acc: 0.8803 - val_loss: 0.1348 - val_acc: 0.8697\n",
      "Epoch 51/100\n",
      "284/284 [==============================] - 0s 95us/step - loss: 0.1290 - acc: 0.8803 - val_loss: 0.1346 - val_acc: 0.8697\n",
      "Epoch 52/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1289 - acc: 0.8803 - val_loss: 0.1344 - val_acc: 0.8732\n",
      "Epoch 53/100\n",
      "284/284 [==============================] - 0s 89us/step - loss: 0.1288 - acc: 0.8803 - val_loss: 0.1342 - val_acc: 0.8732\n",
      "Epoch 54/100\n",
      "284/284 [==============================] - 0s 94us/step - loss: 0.1286 - acc: 0.8838 - val_loss: 0.1340 - val_acc: 0.8732\n",
      "Epoch 55/100\n",
      "284/284 [==============================] - 0s 97us/step - loss: 0.1285 - acc: 0.8803 - val_loss: 0.1338 - val_acc: 0.8732\n",
      "Epoch 56/100\n",
      "284/284 [==============================] - 0s 101us/step - loss: 0.1284 - acc: 0.8873 - val_loss: 0.1337 - val_acc: 0.8732\n",
      "Epoch 57/100\n",
      "284/284 [==============================] - 0s 74us/step - loss: 0.1282 - acc: 0.8803 - val_loss: 0.1334 - val_acc: 0.8732\n",
      "Epoch 58/100\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1281 - acc: 0.8873 - val_loss: 0.1332 - val_acc: 0.8732\n",
      "Epoch 59/100\n",
      "284/284 [==============================] - 0s 71us/step - loss: 0.1279 - acc: 0.8873 - val_loss: 0.1331 - val_acc: 0.8732\n",
      "Epoch 60/100\n",
      "284/284 [==============================] - 0s 99us/step - loss: 0.1278 - acc: 0.8838 - val_loss: 0.1329 - val_acc: 0.8732\n",
      "Epoch 61/100\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1277 - acc: 0.8873 - val_loss: 0.1327 - val_acc: 0.8732\n",
      "Epoch 62/100\n",
      "284/284 [==============================] - 0s 82us/step - loss: 0.1275 - acc: 0.8873 - val_loss: 0.1326 - val_acc: 0.8732\n",
      "Epoch 63/100\n",
      "284/284 [==============================] - 0s 87us/step - loss: 0.1274 - acc: 0.8873 - val_loss: 0.1325 - val_acc: 0.8732\n",
      "Epoch 64/100\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1273 - acc: 0.8838 - val_loss: 0.1323 - val_acc: 0.8732\n",
      "Epoch 65/100\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1271 - acc: 0.8873 - val_loss: 0.1321 - val_acc: 0.8732\n",
      "Epoch 66/100\n",
      "284/284 [==============================] - 0s 134us/step - loss: 0.1270 - acc: 0.8873 - val_loss: 0.1320 - val_acc: 0.8732\n",
      "Epoch 67/100\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1268 - acc: 0.8873 - val_loss: 0.1318 - val_acc: 0.8732\n",
      "Epoch 68/100\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1267 - acc: 0.8873 - val_loss: 0.1317 - val_acc: 0.8732\n",
      "Epoch 69/100\n",
      "284/284 [==============================] - 0s 86us/step - loss: 0.1266 - acc: 0.8873 - val_loss: 0.1315 - val_acc: 0.8732\n",
      "Epoch 70/100\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1265 - acc: 0.8873 - val_loss: 0.1314 - val_acc: 0.8732\n",
      "Epoch 71/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1263 - acc: 0.8873 - val_loss: 0.1311 - val_acc: 0.8732\n",
      "Epoch 72/100\n",
      "284/284 [==============================] - 0s 91us/step - loss: 0.1262 - acc: 0.8873 - val_loss: 0.1309 - val_acc: 0.8732\n",
      "Epoch 73/100\n",
      "284/284 [==============================] - 0s 107us/step - loss: 0.1260 - acc: 0.8838 - val_loss: 0.1307 - val_acc: 0.8732\n",
      "Epoch 74/100\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1259 - acc: 0.8838 - val_loss: 0.1305 - val_acc: 0.8732\n",
      "Epoch 75/100\n",
      "284/284 [==============================] - 0s 109us/step - loss: 0.1258 - acc: 0.8838 - val_loss: 0.1303 - val_acc: 0.8732\n",
      "Epoch 76/100\n",
      "284/284 [==============================] - 0s 113us/step - loss: 0.1257 - acc: 0.8838 - val_loss: 0.1302 - val_acc: 0.8732\n",
      "Epoch 77/100\n",
      "284/284 [==============================] - 0s 64us/step - loss: 0.1255 - acc: 0.8838 - val_loss: 0.1300 - val_acc: 0.8732\n",
      "Epoch 78/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1254 - acc: 0.8838 - val_loss: 0.1299 - val_acc: 0.8732\n",
      "Epoch 79/100\n",
      "284/284 [==============================] - 0s 142us/step - loss: 0.1253 - acc: 0.8838 - val_loss: 0.1298 - val_acc: 0.8732\n",
      "Epoch 80/100\n",
      "284/284 [==============================] - 0s 101us/step - loss: 0.1251 - acc: 0.8838 - val_loss: 0.1296 - val_acc: 0.8732\n",
      "Epoch 81/100\n",
      "284/284 [==============================] - 0s 125us/step - loss: 0.1250 - acc: 0.8838 - val_loss: 0.1294 - val_acc: 0.8732\n",
      "Epoch 82/100\n",
      "284/284 [==============================] - 0s 105us/step - loss: 0.1249 - acc: 0.8838 - val_loss: 0.1292 - val_acc: 0.8732\n",
      "Epoch 83/100\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1248 - acc: 0.8838 - val_loss: 0.1290 - val_acc: 0.8732\n",
      "Epoch 84/100\n",
      "284/284 [==============================] - 0s 91us/step - loss: 0.1246 - acc: 0.8838 - val_loss: 0.1290 - val_acc: 0.8732\n",
      "Epoch 85/100\n",
      "284/284 [==============================] - 0s 133us/step - loss: 0.1245 - acc: 0.8838 - val_loss: 0.1289 - val_acc: 0.8732\n",
      "Epoch 86/100\n",
      "284/284 [==============================] - 0s 78us/step - loss: 0.1244 - acc: 0.8838 - val_loss: 0.1286 - val_acc: 0.8732\n",
      "Epoch 87/100\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1243 - acc: 0.8838 - val_loss: 0.1285 - val_acc: 0.8732\n",
      "Epoch 88/100\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1241 - acc: 0.8838 - val_loss: 0.1284 - val_acc: 0.8732\n",
      "Epoch 89/100\n",
      "284/284 [==============================] - 0s 195us/step - loss: 0.1241 - acc: 0.8838 - val_loss: 0.1283 - val_acc: 0.8732\n",
      "Epoch 90/100\n",
      "284/284 [==============================] - 0s 124us/step - loss: 0.1239 - acc: 0.8838 - val_loss: 0.1281 - val_acc: 0.8732\n",
      "Epoch 91/100\n",
      "284/284 [==============================] - 0s 106us/step - loss: 0.1237 - acc: 0.8838 - val_loss: 0.1279 - val_acc: 0.8732\n",
      "Epoch 92/100\n",
      "284/284 [==============================] - 0s 119us/step - loss: 0.1236 - acc: 0.8838 - val_loss: 0.1279 - val_acc: 0.8732\n",
      "Epoch 93/100\n",
      "284/284 [==============================] - 0s 109us/step - loss: 0.1235 - acc: 0.8838 - val_loss: 0.1277 - val_acc: 0.8732\n",
      "Epoch 94/100\n",
      "284/284 [==============================] - 0s 165us/step - loss: 0.1234 - acc: 0.8838 - val_loss: 0.1275 - val_acc: 0.8768\n",
      "Epoch 95/100\n",
      "284/284 [==============================] - 0s 128us/step - loss: 0.1233 - acc: 0.8838 - val_loss: 0.1273 - val_acc: 0.8768\n",
      "Epoch 96/100\n",
      "284/284 [==============================] - 0s 99us/step - loss: 0.1232 - acc: 0.8838 - val_loss: 0.1271 - val_acc: 0.8768\n",
      "Epoch 97/100\n",
      "284/284 [==============================] - 0s 70us/step - loss: 0.1230 - acc: 0.8838 - val_loss: 0.1269 - val_acc: 0.8768\n",
      "Epoch 98/100\n",
      "284/284 [==============================] - 0s 59us/step - loss: 0.1229 - acc: 0.8838 - val_loss: 0.1268 - val_acc: 0.8768\n",
      "Epoch 99/100\n",
      "284/284 [==============================] - 0s 69us/step - loss: 0.1228 - acc: 0.8838 - val_loss: 0.1267 - val_acc: 0.8768\n",
      "Epoch 100/100\n",
      "284/284 [==============================] - 0s 75us/step - loss: 0.1227 - acc: 0.8838 - val_loss: 0.1266 - val_acc: 0.8768\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 100\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 398 samples\n",
      "Epoch 1/50\n",
      "170/170 [==============================] - 0s 132us/step - loss: 0.1240 - acc: 0.8941 - val_loss: 0.1248 - val_acc: 0.8744\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 0s 67us/step - loss: 0.1240 - acc: 0.8941 - val_loss: 0.1247 - val_acc: 0.8744\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 0s 73us/step - loss: 0.1238 - acc: 0.8941 - val_loss: 0.1247 - val_acc: 0.8744\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 0s 78us/step - loss: 0.1238 - acc: 0.8941 - val_loss: 0.1246 - val_acc: 0.8744\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 0s 128us/step - loss: 0.1237 - acc: 0.8941 - val_loss: 0.1246 - val_acc: 0.8744\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.1236 - acc: 0.8941 - val_loss: 0.1245 - val_acc: 0.8744\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 0s 85us/step - loss: 0.1235 - acc: 0.8941 - val_loss: 0.1244 - val_acc: 0.8744\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.1235 - acc: 0.8941 - val_loss: 0.1244 - val_acc: 0.8744\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 0s 116us/step - loss: 0.1234 - acc: 0.8941 - val_loss: 0.1243 - val_acc: 0.8719\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.1233 - acc: 0.8941 - val_loss: 0.1243 - val_acc: 0.8719\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 0s 94us/step - loss: 0.1232 - acc: 0.8941 - val_loss: 0.1242 - val_acc: 0.8719\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 0s 180us/step - loss: 0.1232 - acc: 0.8941 - val_loss: 0.1242 - val_acc: 0.8719\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 0s 85us/step - loss: 0.1231 - acc: 0.8941 - val_loss: 0.1241 - val_acc: 0.8719\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 0s 81us/step - loss: 0.1231 - acc: 0.8941 - val_loss: 0.1240 - val_acc: 0.8744\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1230 - acc: 0.8941 - val_loss: 0.1239 - val_acc: 0.8744\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.1229 - acc: 0.8941 - val_loss: 0.1239 - val_acc: 0.8744\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.1229 - acc: 0.8941 - val_loss: 0.1238 - val_acc: 0.8744\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 0s 116us/step - loss: 0.1227 - acc: 0.8941 - val_loss: 0.1237 - val_acc: 0.8744\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.1227 - acc: 0.8941 - val_loss: 0.1237 - val_acc: 0.8719\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.1226 - acc: 0.8941 - val_loss: 0.1236 - val_acc: 0.8719\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 0s 167us/step - loss: 0.1226 - acc: 0.8941 - val_loss: 0.1236 - val_acc: 0.8719\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 0s 156us/step - loss: 0.1225 - acc: 0.8941 - val_loss: 0.1236 - val_acc: 0.8719\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 0s 120us/step - loss: 0.1224 - acc: 0.8941 - val_loss: 0.1235 - val_acc: 0.8719\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1223 - acc: 0.8941 - val_loss: 0.1234 - val_acc: 0.8719\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 0s 75us/step - loss: 0.1222 - acc: 0.8941 - val_loss: 0.1234 - val_acc: 0.8719\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.1222 - acc: 0.8941 - val_loss: 0.1233 - val_acc: 0.8719\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 0s 102us/step - loss: 0.1221 - acc: 0.9000 - val_loss: 0.1232 - val_acc: 0.8719\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 0s 77us/step - loss: 0.1220 - acc: 0.8941 - val_loss: 0.1231 - val_acc: 0.8719\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 0s 122us/step - loss: 0.1220 - acc: 0.8941 - val_loss: 0.1231 - val_acc: 0.8719\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1219 - acc: 0.8941 - val_loss: 0.1230 - val_acc: 0.8719\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1218 - acc: 0.8941 - val_loss: 0.1229 - val_acc: 0.8719\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.1218 - acc: 0.8941 - val_loss: 0.1229 - val_acc: 0.8719\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 0s 102us/step - loss: 0.1217 - acc: 0.8941 - val_loss: 0.1229 - val_acc: 0.8719\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.1216 - acc: 0.9000 - val_loss: 0.1228 - val_acc: 0.8719\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.1216 - acc: 0.9000 - val_loss: 0.1227 - val_acc: 0.8719\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 0s 84us/step - loss: 0.1215 - acc: 0.9000 - val_loss: 0.1226 - val_acc: 0.8719\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 0s 114us/step - loss: 0.1214 - acc: 0.9000 - val_loss: 0.1225 - val_acc: 0.8719\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.1214 - acc: 0.8941 - val_loss: 0.1225 - val_acc: 0.8719\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 0s 98us/step - loss: 0.1213 - acc: 0.9000 - val_loss: 0.1224 - val_acc: 0.8719\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 0s 93us/step - loss: 0.1212 - acc: 0.8941 - val_loss: 0.1224 - val_acc: 0.8719\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1212 - acc: 0.8941 - val_loss: 0.1223 - val_acc: 0.8719\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 0s 95us/step - loss: 0.1211 - acc: 0.9000 - val_loss: 0.1223 - val_acc: 0.8719\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 0s 101us/step - loss: 0.1210 - acc: 0.9000 - val_loss: 0.1222 - val_acc: 0.8719\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.1210 - acc: 0.9000 - val_loss: 0.1221 - val_acc: 0.8719\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.1209 - acc: 0.9000 - val_loss: 0.1220 - val_acc: 0.8719\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.1208 - acc: 0.9000 - val_loss: 0.1219 - val_acc: 0.8719\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 0s 107us/step - loss: 0.1208 - acc: 0.9000 - val_loss: 0.1219 - val_acc: 0.8744\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 0s 127us/step - loss: 0.1207 - acc: 0.8941 - val_loss: 0.1218 - val_acc: 0.8719\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 0s 96us/step - loss: 0.1206 - acc: 0.9000 - val_loss: 0.1218 - val_acc: 0.8719\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 0s 150us/step - loss: 0.1206 - acc: 0.9000 - val_loss: 0.1217 - val_acc: 0.8719\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.7\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 398 samples\n",
      "Epoch 1/50\n",
      "170/170 [==============================] - 0s 150us/step - loss: 0.1205 - acc: 0.8941 - val_loss: 0.1216 - val_acc: 0.8719\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 0s 110us/step - loss: 0.1204 - acc: 0.9000 - val_loss: 0.1216 - val_acc: 0.8719\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 0s 92us/step - loss: 0.1204 - acc: 0.9000 - val_loss: 0.1215 - val_acc: 0.8744\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.1203 - acc: 0.9000 - val_loss: 0.1214 - val_acc: 0.8744\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 0s 173us/step - loss: 0.1202 - acc: 0.9000 - val_loss: 0.1213 - val_acc: 0.8744\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 0s 204us/step - loss: 0.1202 - acc: 0.9000 - val_loss: 0.1213 - val_acc: 0.8744\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 0s 196us/step - loss: 0.1201 - acc: 0.9000 - val_loss: 0.1212 - val_acc: 0.8744\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 0s 157us/step - loss: 0.1201 - acc: 0.9000 - val_loss: 0.1212 - val_acc: 0.8744\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 0s 266us/step - loss: 0.1200 - acc: 0.9000 - val_loss: 0.1211 - val_acc: 0.8744\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 0s 354us/step - loss: 0.1199 - acc: 0.9000 - val_loss: 0.1210 - val_acc: 0.8744\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 0s 236us/step - loss: 0.1199 - acc: 0.8941 - val_loss: 0.1209 - val_acc: 0.8744\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 0s 246us/step - loss: 0.1198 - acc: 0.9000 - val_loss: 0.1209 - val_acc: 0.8744\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 0s 95us/step - loss: 0.1197 - acc: 0.9000 - val_loss: 0.1208 - val_acc: 0.8744\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 0s 138us/step - loss: 0.1197 - acc: 0.8941 - val_loss: 0.1207 - val_acc: 0.8744\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.1196 - acc: 0.8941 - val_loss: 0.1207 - val_acc: 0.8744\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 0s 121us/step - loss: 0.1195 - acc: 0.8941 - val_loss: 0.1206 - val_acc: 0.8744\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 0s 185us/step - loss: 0.1195 - acc: 0.9000 - val_loss: 0.1205 - val_acc: 0.8744\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 0s 131us/step - loss: 0.1194 - acc: 0.8941 - val_loss: 0.1205 - val_acc: 0.8744\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 0s 137us/step - loss: 0.1194 - acc: 0.8941 - val_loss: 0.1204 - val_acc: 0.8744\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 0s 180us/step - loss: 0.1193 - acc: 0.8941 - val_loss: 0.1203 - val_acc: 0.8744\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 0s 119us/step - loss: 0.1192 - acc: 0.8941 - val_loss: 0.1203 - val_acc: 0.8744\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 0s 138us/step - loss: 0.1192 - acc: 0.9000 - val_loss: 0.1202 - val_acc: 0.8744\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 0s 139us/step - loss: 0.1191 - acc: 0.9000 - val_loss: 0.1202 - val_acc: 0.8744\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 0s 137us/step - loss: 0.1190 - acc: 0.9000 - val_loss: 0.1201 - val_acc: 0.8744\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 0s 226us/step - loss: 0.1190 - acc: 0.9000 - val_loss: 0.1200 - val_acc: 0.8744\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 0s 188us/step - loss: 0.1189 - acc: 0.9000 - val_loss: 0.1199 - val_acc: 0.8744\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 0s 125us/step - loss: 0.1188 - acc: 0.8941 - val_loss: 0.1198 - val_acc: 0.8744\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 0s 208us/step - loss: 0.1188 - acc: 0.8941 - val_loss: 0.1198 - val_acc: 0.8744\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 0s 149us/step - loss: 0.1187 - acc: 0.8941 - val_loss: 0.1197 - val_acc: 0.8744\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 0s 158us/step - loss: 0.1187 - acc: 0.9000 - val_loss: 0.1196 - val_acc: 0.8744\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 0s 104us/step - loss: 0.1186 - acc: 0.8941 - val_loss: 0.1196 - val_acc: 0.8744\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.1185 - acc: 0.8941 - val_loss: 0.1195 - val_acc: 0.8744\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.1185 - acc: 0.8941 - val_loss: 0.1194 - val_acc: 0.8744\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 0s 110us/step - loss: 0.1184 - acc: 0.8941 - val_loss: 0.1194 - val_acc: 0.8744\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 0s 178us/step - loss: 0.1184 - acc: 0.8941 - val_loss: 0.1193 - val_acc: 0.8744\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 0s 209us/step - loss: 0.1183 - acc: 0.8941 - val_loss: 0.1193 - val_acc: 0.8744\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 0s 175us/step - loss: 0.1182 - acc: 0.8941 - val_loss: 0.1192 - val_acc: 0.8744\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 0s 245us/step - loss: 0.1182 - acc: 0.8941 - val_loss: 0.1191 - val_acc: 0.8744\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 0s 149us/step - loss: 0.1181 - acc: 0.8941 - val_loss: 0.1190 - val_acc: 0.8744\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 0s 126us/step - loss: 0.1180 - acc: 0.8941 - val_loss: 0.1189 - val_acc: 0.8744\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.1180 - acc: 0.8941 - val_loss: 0.1188 - val_acc: 0.8744\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 0s 140us/step - loss: 0.1180 - acc: 0.8941 - val_loss: 0.1188 - val_acc: 0.8744\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 0s 146us/step - loss: 0.1179 - acc: 0.8941 - val_loss: 0.1187 - val_acc: 0.8744\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 0s 132us/step - loss: 0.1178 - acc: 0.8941 - val_loss: 0.1186 - val_acc: 0.8744\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 0s 139us/step - loss: 0.1177 - acc: 0.8941 - val_loss: 0.1186 - val_acc: 0.8744\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 0s 112us/step - loss: 0.1177 - acc: 0.8941 - val_loss: 0.1185 - val_acc: 0.8744\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.1176 - acc: 0.8941 - val_loss: 0.1184 - val_acc: 0.8744\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.1176 - acc: 0.8941 - val_loss: 0.1184 - val_acc: 0.8744\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 0s 114us/step - loss: 0.1175 - acc: 0.8941 - val_loss: 0.1183 - val_acc: 0.8744\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 0s 215us/step - loss: 0.1175 - acc: 0.8941 - val_loss: 0.1183 - val_acc: 0.8744\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.7\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 340 samples, validate on 228 samples\n",
      "Epoch 1/50\n",
      "340/340 [==============================] - 0s 120us/step - loss: 0.1192 - acc: 0.8706 - val_loss: 0.1157 - val_acc: 0.8991\n",
      "Epoch 2/50\n",
      "340/340 [==============================] - 0s 79us/step - loss: 0.1190 - acc: 0.8735 - val_loss: 0.1154 - val_acc: 0.8991\n",
      "Epoch 3/50\n",
      "340/340 [==============================] - 0s 99us/step - loss: 0.1188 - acc: 0.8735 - val_loss: 0.1152 - val_acc: 0.8991\n",
      "Epoch 4/50\n",
      "340/340 [==============================] - 0s 69us/step - loss: 0.1187 - acc: 0.8735 - val_loss: 0.1150 - val_acc: 0.8991\n",
      "Epoch 5/50\n",
      "340/340 [==============================] - 0s 128us/step - loss: 0.1186 - acc: 0.8735 - val_loss: 0.1147 - val_acc: 0.9035\n",
      "Epoch 6/50\n",
      "340/340 [==============================] - 0s 158us/step - loss: 0.1184 - acc: 0.8735 - val_loss: 0.1144 - val_acc: 0.9035\n",
      "Epoch 7/50\n",
      "340/340 [==============================] - 0s 100us/step - loss: 0.1183 - acc: 0.8735 - val_loss: 0.1141 - val_acc: 0.9035\n",
      "Epoch 8/50\n",
      "340/340 [==============================] - 0s 118us/step - loss: 0.1181 - acc: 0.8735 - val_loss: 0.1139 - val_acc: 0.9035\n",
      "Epoch 9/50\n",
      "340/340 [==============================] - 0s 123us/step - loss: 0.1180 - acc: 0.8735 - val_loss: 0.1136 - val_acc: 0.9035\n",
      "Epoch 10/50\n",
      "340/340 [==============================] - 0s 87us/step - loss: 0.1179 - acc: 0.8735 - val_loss: 0.1134 - val_acc: 0.9035\n",
      "Epoch 11/50\n",
      "340/340 [==============================] - 0s 96us/step - loss: 0.1178 - acc: 0.8735 - val_loss: 0.1132 - val_acc: 0.9123\n",
      "Epoch 12/50\n",
      "340/340 [==============================] - 0s 77us/step - loss: 0.1176 - acc: 0.8765 - val_loss: 0.1128 - val_acc: 0.9123\n",
      "Epoch 13/50\n",
      "340/340 [==============================] - 0s 89us/step - loss: 0.1175 - acc: 0.8794 - val_loss: 0.1127 - val_acc: 0.9123\n",
      "Epoch 14/50\n",
      "340/340 [==============================] - 0s 91us/step - loss: 0.1173 - acc: 0.8794 - val_loss: 0.1125 - val_acc: 0.9123\n",
      "Epoch 15/50\n",
      "340/340 [==============================] - 0s 80us/step - loss: 0.1172 - acc: 0.8794 - val_loss: 0.1123 - val_acc: 0.9123\n",
      "Epoch 16/50\n",
      "340/340 [==============================] - 0s 129us/step - loss: 0.1171 - acc: 0.8794 - val_loss: 0.1121 - val_acc: 0.9123\n",
      "Epoch 17/50\n",
      "340/340 [==============================] - 0s 71us/step - loss: 0.1170 - acc: 0.8794 - val_loss: 0.1121 - val_acc: 0.9123\n",
      "Epoch 18/50\n",
      "340/340 [==============================] - 0s 89us/step - loss: 0.1169 - acc: 0.8794 - val_loss: 0.1118 - val_acc: 0.9167\n",
      "Epoch 19/50\n",
      "340/340 [==============================] - 0s 82us/step - loss: 0.1168 - acc: 0.8794 - val_loss: 0.1116 - val_acc: 0.9167\n",
      "Epoch 20/50\n",
      "340/340 [==============================] - 0s 71us/step - loss: 0.1167 - acc: 0.8794 - val_loss: 0.1114 - val_acc: 0.9167\n",
      "Epoch 21/50\n",
      "340/340 [==============================] - 0s 61us/step - loss: 0.1166 - acc: 0.8794 - val_loss: 0.1112 - val_acc: 0.9167\n",
      "Epoch 22/50\n",
      "340/340 [==============================] - 0s 68us/step - loss: 0.1164 - acc: 0.8853 - val_loss: 0.1111 - val_acc: 0.9167\n",
      "Epoch 23/50\n",
      "340/340 [==============================] - 0s 64us/step - loss: 0.1163 - acc: 0.8853 - val_loss: 0.1110 - val_acc: 0.9167\n",
      "Epoch 24/50\n",
      "340/340 [==============================] - 0s 64us/step - loss: 0.1162 - acc: 0.8794 - val_loss: 0.1108 - val_acc: 0.9167\n",
      "Epoch 25/50\n",
      "340/340 [==============================] - 0s 63us/step - loss: 0.1161 - acc: 0.8853 - val_loss: 0.1107 - val_acc: 0.9167\n",
      "Epoch 26/50\n",
      "340/340 [==============================] - 0s 61us/step - loss: 0.1160 - acc: 0.8824 - val_loss: 0.1106 - val_acc: 0.9167\n",
      "Epoch 27/50\n",
      "340/340 [==============================] - 0s 75us/step - loss: 0.1159 - acc: 0.8853 - val_loss: 0.1105 - val_acc: 0.9167\n",
      "Epoch 28/50\n",
      "340/340 [==============================] - 0s 76us/step - loss: 0.1158 - acc: 0.8824 - val_loss: 0.1102 - val_acc: 0.9211\n",
      "Epoch 29/50\n",
      "340/340 [==============================] - 0s 65us/step - loss: 0.1157 - acc: 0.8853 - val_loss: 0.1100 - val_acc: 0.9211\n",
      "Epoch 30/50\n",
      "340/340 [==============================] - 0s 72us/step - loss: 0.1156 - acc: 0.8853 - val_loss: 0.1099 - val_acc: 0.9211\n",
      "Epoch 31/50\n",
      "340/340 [==============================] - 0s 96us/step - loss: 0.1154 - acc: 0.8853 - val_loss: 0.1097 - val_acc: 0.9211\n",
      "Epoch 32/50\n",
      "340/340 [==============================] - 0s 64us/step - loss: 0.1154 - acc: 0.8853 - val_loss: 0.1095 - val_acc: 0.9211\n",
      "Epoch 33/50\n",
      "340/340 [==============================] - 0s 94us/step - loss: 0.1152 - acc: 0.8853 - val_loss: 0.1093 - val_acc: 0.9211\n",
      "Epoch 34/50\n",
      "340/340 [==============================] - 0s 101us/step - loss: 0.1151 - acc: 0.8853 - val_loss: 0.1091 - val_acc: 0.9211\n",
      "Epoch 35/50\n",
      "340/340 [==============================] - 0s 192us/step - loss: 0.1150 - acc: 0.8853 - val_loss: 0.1091 - val_acc: 0.9211\n",
      "Epoch 36/50\n",
      "340/340 [==============================] - 0s 65us/step - loss: 0.1149 - acc: 0.8912 - val_loss: 0.1090 - val_acc: 0.9211\n",
      "Epoch 37/50\n",
      "340/340 [==============================] - 0s 96us/step - loss: 0.1148 - acc: 0.8853 - val_loss: 0.1089 - val_acc: 0.9211\n",
      "Epoch 38/50\n",
      "340/340 [==============================] - 0s 69us/step - loss: 0.1147 - acc: 0.8853 - val_loss: 0.1087 - val_acc: 0.9211\n",
      "Epoch 39/50\n",
      "340/340 [==============================] - 0s 85us/step - loss: 0.1146 - acc: 0.8853 - val_loss: 0.1086 - val_acc: 0.9211\n",
      "Epoch 40/50\n",
      "340/340 [==============================] - 0s 79us/step - loss: 0.1145 - acc: 0.8853 - val_loss: 0.1085 - val_acc: 0.9211\n",
      "Epoch 41/50\n",
      "340/340 [==============================] - 0s 70us/step - loss: 0.1144 - acc: 0.8853 - val_loss: 0.1084 - val_acc: 0.9211\n",
      "Epoch 42/50\n",
      "340/340 [==============================] - 0s 65us/step - loss: 0.1143 - acc: 0.8882 - val_loss: 0.1083 - val_acc: 0.9211\n",
      "Epoch 43/50\n",
      "340/340 [==============================] - 0s 71us/step - loss: 0.1142 - acc: 0.8853 - val_loss: 0.1081 - val_acc: 0.9211\n",
      "Epoch 44/50\n",
      "340/340 [==============================] - 0s 67us/step - loss: 0.1141 - acc: 0.8853 - val_loss: 0.1079 - val_acc: 0.9211\n",
      "Epoch 45/50\n",
      "340/340 [==============================] - 0s 82us/step - loss: 0.1140 - acc: 0.8853 - val_loss: 0.1077 - val_acc: 0.9254\n",
      "Epoch 46/50\n",
      "340/340 [==============================] - 0s 75us/step - loss: 0.1138 - acc: 0.8941 - val_loss: 0.1077 - val_acc: 0.9254\n",
      "Epoch 47/50\n",
      "340/340 [==============================] - 0s 78us/step - loss: 0.1138 - acc: 0.8912 - val_loss: 0.1075 - val_acc: 0.9254\n",
      "Epoch 48/50\n",
      "340/340 [==============================] - 0s 66us/step - loss: 0.1137 - acc: 0.8882 - val_loss: 0.1075 - val_acc: 0.9211\n",
      "Epoch 49/50\n",
      "340/340 [==============================] - 0s 92us/step - loss: 0.1135 - acc: 0.8882 - val_loss: 0.1073 - val_acc: 0.9254\n",
      "Epoch 50/50\n",
      "340/340 [==============================] - 0s 94us/step - loss: 0.1134 - acc: 0.8882 - val_loss: 0.1072 - val_acc: 0.9254\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.4\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 284 samples\n",
      "Epoch 1/50\n",
      "284/284 [==============================] - 0s 164us/step - loss: 0.1107 - acc: 0.8979 - val_loss: 0.1109 - val_acc: 0.9120\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 0s 137us/step - loss: 0.1106 - acc: 0.9014 - val_loss: 0.1109 - val_acc: 0.9085\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 0s 212us/step - loss: 0.1105 - acc: 0.8944 - val_loss: 0.1109 - val_acc: 0.9049\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 0s 136us/step - loss: 0.1104 - acc: 0.8944 - val_loss: 0.1108 - val_acc: 0.9049\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 0s 113us/step - loss: 0.1104 - acc: 0.8944 - val_loss: 0.1108 - val_acc: 0.9049\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 0s 111us/step - loss: 0.1103 - acc: 0.8944 - val_loss: 0.1107 - val_acc: 0.9049\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 0s 110us/step - loss: 0.1102 - acc: 0.8944 - val_loss: 0.1106 - val_acc: 0.9049\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 0s 111us/step - loss: 0.1101 - acc: 0.8944 - val_loss: 0.1105 - val_acc: 0.9049\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 0s 229us/step - loss: 0.1100 - acc: 0.8944 - val_loss: 0.1105 - val_acc: 0.9049\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 0s 332us/step - loss: 0.1099 - acc: 0.8944 - val_loss: 0.1103 - val_acc: 0.9049\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 0s 111us/step - loss: 0.1099 - acc: 0.8944 - val_loss: 0.1102 - val_acc: 0.9049\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 0s 96us/step - loss: 0.1098 - acc: 0.8944 - val_loss: 0.1101 - val_acc: 0.9049\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 0s 166us/step - loss: 0.1097 - acc: 0.8944 - val_loss: 0.1101 - val_acc: 0.9049\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 0s 159us/step - loss: 0.1096 - acc: 0.8944 - val_loss: 0.1100 - val_acc: 0.9049\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 0s 117us/step - loss: 0.1095 - acc: 0.8944 - val_loss: 0.1100 - val_acc: 0.9049\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 0s 157us/step - loss: 0.1095 - acc: 0.8944 - val_loss: 0.1099 - val_acc: 0.9049\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 0s 109us/step - loss: 0.1094 - acc: 0.8944 - val_loss: 0.1098 - val_acc: 0.9049\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 0s 111us/step - loss: 0.1093 - acc: 0.8944 - val_loss: 0.1098 - val_acc: 0.9049\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 0s 104us/step - loss: 0.1092 - acc: 0.8944 - val_loss: 0.1097 - val_acc: 0.9049\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 0s 141us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.1096 - val_acc: 0.9049\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1091 - acc: 0.8944 - val_loss: 0.1095 - val_acc: 0.9049\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 0s 99us/step - loss: 0.1090 - acc: 0.8944 - val_loss: 0.1094 - val_acc: 0.9049\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 0s 100us/step - loss: 0.1089 - acc: 0.8944 - val_loss: 0.1093 - val_acc: 0.9049\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 0s 103us/step - loss: 0.1088 - acc: 0.8944 - val_loss: 0.1092 - val_acc: 0.9049\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 0s 115us/step - loss: 0.1088 - acc: 0.8944 - val_loss: 0.1091 - val_acc: 0.9049\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 0s 102us/step - loss: 0.1087 - acc: 0.8944 - val_loss: 0.1091 - val_acc: 0.9049\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 0s 119us/step - loss: 0.1086 - acc: 0.8944 - val_loss: 0.1090 - val_acc: 0.9049\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 0s 79us/step - loss: 0.1085 - acc: 0.8944 - val_loss: 0.1088 - val_acc: 0.9049\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 0s 132us/step - loss: 0.1085 - acc: 0.8944 - val_loss: 0.1088 - val_acc: 0.9049\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 0s 99us/step - loss: 0.1084 - acc: 0.8944 - val_loss: 0.1087 - val_acc: 0.9049\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 0s 137us/step - loss: 0.1083 - acc: 0.8944 - val_loss: 0.1086 - val_acc: 0.9049\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 0s 93us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.1085 - val_acc: 0.9049\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 0s 114us/step - loss: 0.1082 - acc: 0.8944 - val_loss: 0.1085 - val_acc: 0.9049\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 0s 114us/step - loss: 0.1081 - acc: 0.8944 - val_loss: 0.1084 - val_acc: 0.9049\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 0s 214us/step - loss: 0.1080 - acc: 0.8944 - val_loss: 0.1083 - val_acc: 0.9049\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 0s 180us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.1082 - val_acc: 0.9049\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 0s 178us/step - loss: 0.1079 - acc: 0.8944 - val_loss: 0.1082 - val_acc: 0.9049\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 0s 119us/step - loss: 0.1078 - acc: 0.8944 - val_loss: 0.1080 - val_acc: 0.9049\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 0s 120us/step - loss: 0.1077 - acc: 0.8944 - val_loss: 0.1080 - val_acc: 0.9049\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 0s 97us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.1079 - val_acc: 0.9049\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 0s 140us/step - loss: 0.1076 - acc: 0.8944 - val_loss: 0.1078 - val_acc: 0.9049\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 0s 121us/step - loss: 0.1075 - acc: 0.8944 - val_loss: 0.1076 - val_acc: 0.9085\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 0s 106us/step - loss: 0.1074 - acc: 0.8944 - val_loss: 0.1075 - val_acc: 0.9085\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 0s 162us/step - loss: 0.1073 - acc: 0.8944 - val_loss: 0.1074 - val_acc: 0.9085\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 0s 556us/step - loss: 0.1073 - acc: 0.8944 - val_loss: 0.1074 - val_acc: 0.9085\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 0s 80us/step - loss: 0.1072 - acc: 0.8944 - val_loss: 0.1073 - val_acc: 0.9085\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 0s 149us/step - loss: 0.1071 - acc: 0.8979 - val_loss: 0.1072 - val_acc: 0.9085\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 0s 131us/step - loss: 0.1071 - acc: 0.8944 - val_loss: 0.1072 - val_acc: 0.9085\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 0s 90us/step - loss: 0.1070 - acc: 0.8944 - val_loss: 0.1071 - val_acc: 0.9085\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 0s 122us/step - loss: 0.1069 - acc: 0.8944 - val_loss: 0.1070 - val_acc: 0.9085\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.5\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 398 samples\n",
      "Epoch 1/50\n",
      "170/170 [==============================] - 0s 152us/step - loss: 0.1084 - acc: 0.9059 - val_loss: 0.1063 - val_acc: 0.8995\n",
      "Epoch 2/50\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.1083 - acc: 0.9059 - val_loss: 0.1063 - val_acc: 0.8970\n",
      "Epoch 3/50\n",
      "170/170 [==============================] - 0s 142us/step - loss: 0.1083 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 4/50\n",
      "170/170 [==============================] - 0s 181us/step - loss: 0.1082 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 5/50\n",
      "170/170 [==============================] - 0s 200us/step - loss: 0.1081 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 6/50\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.1081 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 7/50\n",
      "170/170 [==============================] - 0s 361us/step - loss: 0.1080 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 8/50\n",
      "170/170 [==============================] - 0s 177us/step - loss: 0.1080 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 9/50\n",
      "170/170 [==============================] - 0s 141us/step - loss: 0.1079 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 10/50\n",
      "170/170 [==============================] - 0s 238us/step - loss: 0.1079 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 11/50\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.1078 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 12/50\n",
      "170/170 [==============================] - 0s 391us/step - loss: 0.1078 - acc: 0.9059 - val_loss: 0.1062 - val_acc: 0.8970\n",
      "Epoch 13/50\n",
      "170/170 [==============================] - 0s 418us/step - loss: 0.1077 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 14/50\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.1077 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 15/50\n",
      "170/170 [==============================] - 0s 120us/step - loss: 0.1076 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 16/50\n",
      "170/170 [==============================] - 0s 208us/step - loss: 0.1076 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 17/50\n",
      "170/170 [==============================] - 0s 134us/step - loss: 0.1075 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 18/50\n",
      "170/170 [==============================] - 0s 174us/step - loss: 0.1075 - acc: 0.9059 - val_loss: 0.1061 - val_acc: 0.8945\n",
      "Epoch 19/50\n",
      "170/170 [==============================] - 0s 336us/step - loss: 0.1075 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 20/50\n",
      "170/170 [==============================] - 0s 228us/step - loss: 0.1074 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 21/50\n",
      "170/170 [==============================] - 0s 160us/step - loss: 0.1074 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 22/50\n",
      "170/170 [==============================] - 0s 114us/step - loss: 0.1073 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 23/50\n",
      "170/170 [==============================] - 0s 126us/step - loss: 0.1073 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 24/50\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.1072 - acc: 0.9059 - val_loss: 0.1060 - val_acc: 0.8945\n",
      "Epoch 25/50\n",
      "170/170 [==============================] - 0s 104us/step - loss: 0.1072 - acc: 0.9059 - val_loss: 0.1059 - val_acc: 0.8945\n",
      "Epoch 26/50\n",
      "170/170 [==============================] - 0s 195us/step - loss: 0.1071 - acc: 0.9059 - val_loss: 0.1059 - val_acc: 0.8894\n",
      "Epoch 27/50\n",
      "170/170 [==============================] - 0s 144us/step - loss: 0.1071 - acc: 0.9059 - val_loss: 0.1059 - val_acc: 0.8945\n",
      "Epoch 28/50\n",
      "170/170 [==============================] - 0s 133us/step - loss: 0.1071 - acc: 0.9059 - val_loss: 0.1058 - val_acc: 0.8945\n",
      "Epoch 29/50\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.1070 - acc: 0.9059 - val_loss: 0.1058 - val_acc: 0.8894\n",
      "Epoch 30/50\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.1070 - acc: 0.9059 - val_loss: 0.1058 - val_acc: 0.8894\n",
      "Epoch 31/50\n",
      "170/170 [==============================] - 0s 234us/step - loss: 0.1069 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8920\n",
      "Epoch 32/50\n",
      "170/170 [==============================] - 0s 157us/step - loss: 0.1069 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8894\n",
      "Epoch 33/50\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.1068 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8894\n",
      "Epoch 34/50\n",
      "170/170 [==============================] - 0s 253us/step - loss: 0.1068 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8894\n",
      "Epoch 35/50\n",
      "170/170 [==============================] - 0s 185us/step - loss: 0.1068 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8894\n",
      "Epoch 36/50\n",
      "170/170 [==============================] - 0s 377us/step - loss: 0.1067 - acc: 0.9059 - val_loss: 0.1057 - val_acc: 0.8894\n",
      "Epoch 37/50\n",
      "170/170 [==============================] - 0s 173us/step - loss: 0.1067 - acc: 0.9059 - val_loss: 0.1056 - val_acc: 0.8894\n",
      "Epoch 38/50\n",
      "170/170 [==============================] - 0s 150us/step - loss: 0.1066 - acc: 0.9059 - val_loss: 0.1056 - val_acc: 0.8894\n",
      "Epoch 39/50\n",
      "170/170 [==============================] - 0s 172us/step - loss: 0.1066 - acc: 0.9059 - val_loss: 0.1056 - val_acc: 0.8894\n",
      "Epoch 40/50\n",
      "170/170 [==============================] - 0s 119us/step - loss: 0.1066 - acc: 0.9059 - val_loss: 0.1055 - val_acc: 0.8894\n",
      "Epoch 41/50\n",
      "170/170 [==============================] - 0s 152us/step - loss: 0.1065 - acc: 0.9059 - val_loss: 0.1055 - val_acc: 0.8894\n",
      "Epoch 42/50\n",
      "170/170 [==============================] - 0s 168us/step - loss: 0.1065 - acc: 0.9059 - val_loss: 0.1054 - val_acc: 0.8894\n",
      "Epoch 43/50\n",
      "170/170 [==============================] - 0s 120us/step - loss: 0.1064 - acc: 0.9059 - val_loss: 0.1053 - val_acc: 0.8894\n",
      "Epoch 44/50\n",
      "170/170 [==============================] - 0s 145us/step - loss: 0.1064 - acc: 0.9059 - val_loss: 0.1053 - val_acc: 0.8894\n",
      "Epoch 45/50\n",
      "170/170 [==============================] - 0s 173us/step - loss: 0.1063 - acc: 0.9059 - val_loss: 0.1053 - val_acc: 0.8894\n",
      "Epoch 46/50\n",
      "170/170 [==============================] - 0s 117us/step - loss: 0.1063 - acc: 0.9059 - val_loss: 0.1052 - val_acc: 0.8894\n",
      "Epoch 47/50\n",
      "170/170 [==============================] - 0s 111us/step - loss: 0.1063 - acc: 0.9059 - val_loss: 0.1052 - val_acc: 0.8894\n",
      "Epoch 48/50\n",
      "170/170 [==============================] - 0s 222us/step - loss: 0.1062 - acc: 0.9059 - val_loss: 0.1052 - val_acc: 0.8894\n",
      "Epoch 49/50\n",
      "170/170 [==============================] - 0s 132us/step - loss: 0.1062 - acc: 0.9059 - val_loss: 0.1051 - val_acc: 0.8894\n",
      "Epoch 50/50\n",
      "170/170 [==============================] - 0s 182us/step - loss: 0.1062 - acc: 0.9059 - val_loss: 0.1051 - val_acc: 0.8894\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.7\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113 samples, validate on 455 samples\n",
      "Epoch 1/50\n",
      "113/113 [==============================] - 0s 429us/step - loss: 0.1077 - acc: 0.8850 - val_loss: 0.1048 - val_acc: 0.8967\n",
      "Epoch 2/50\n",
      "113/113 [==============================] - 0s 188us/step - loss: 0.1077 - acc: 0.8850 - val_loss: 0.1048 - val_acc: 0.8967\n",
      "Epoch 3/50\n",
      "113/113 [==============================] - 0s 199us/step - loss: 0.1077 - acc: 0.8850 - val_loss: 0.1047 - val_acc: 0.8967\n",
      "Epoch 4/50\n",
      "113/113 [==============================] - 0s 346us/step - loss: 0.1077 - acc: 0.8850 - val_loss: 0.1047 - val_acc: 0.8967\n",
      "Epoch 5/50\n",
      "113/113 [==============================] - 0s 560us/step - loss: 0.1076 - acc: 0.8850 - val_loss: 0.1047 - val_acc: 0.8967\n",
      "Epoch 6/50\n",
      "113/113 [==============================] - 0s 534us/step - loss: 0.1076 - acc: 0.8850 - val_loss: 0.1047 - val_acc: 0.8967\n",
      "Epoch 7/50\n",
      "113/113 [==============================] - 0s 276us/step - loss: 0.1076 - acc: 0.8850 - val_loss: 0.1046 - val_acc: 0.8967\n",
      "Epoch 8/50\n",
      "113/113 [==============================] - 0s 234us/step - loss: 0.1076 - acc: 0.8850 - val_loss: 0.1046 - val_acc: 0.8967\n",
      "Epoch 9/50\n",
      "113/113 [==============================] - 0s 310us/step - loss: 0.1076 - acc: 0.8850 - val_loss: 0.1046 - val_acc: 0.8967\n",
      "Epoch 10/50\n",
      "113/113 [==============================] - 0s 449us/step - loss: 0.1075 - acc: 0.8850 - val_loss: 0.1046 - val_acc: 0.8967\n",
      "Epoch 11/50\n",
      "113/113 [==============================] - 0s 372us/step - loss: 0.1075 - acc: 0.8850 - val_loss: 0.1045 - val_acc: 0.8967\n",
      "Epoch 12/50\n",
      "113/113 [==============================] - 0s 196us/step - loss: 0.1075 - acc: 0.8850 - val_loss: 0.1045 - val_acc: 0.8967\n",
      "Epoch 13/50\n",
      "113/113 [==============================] - 0s 251us/step - loss: 0.1075 - acc: 0.8850 - val_loss: 0.1045 - val_acc: 0.8967\n",
      "Epoch 14/50\n",
      "113/113 [==============================] - 0s 201us/step - loss: 0.1074 - acc: 0.8850 - val_loss: 0.1045 - val_acc: 0.8967\n",
      "Epoch 15/50\n",
      "113/113 [==============================] - 0s 141us/step - loss: 0.1074 - acc: 0.8850 - val_loss: 0.1044 - val_acc: 0.8967\n",
      "Epoch 16/50\n",
      "113/113 [==============================] - 0s 126us/step - loss: 0.1074 - acc: 0.8850 - val_loss: 0.1044 - val_acc: 0.8967\n",
      "Epoch 17/50\n",
      "113/113 [==============================] - 0s 145us/step - loss: 0.1074 - acc: 0.8850 - val_loss: 0.1044 - val_acc: 0.8967\n",
      "Epoch 18/50\n",
      "113/113 [==============================] - 0s 145us/step - loss: 0.1073 - acc: 0.8850 - val_loss: 0.1043 - val_acc: 0.8967\n",
      "Epoch 19/50\n",
      "113/113 [==============================] - 0s 173us/step - loss: 0.1073 - acc: 0.8850 - val_loss: 0.1043 - val_acc: 0.8967\n",
      "Epoch 20/50\n",
      "113/113 [==============================] - 0s 130us/step - loss: 0.1073 - acc: 0.8850 - val_loss: 0.1043 - val_acc: 0.8967\n",
      "Epoch 21/50\n",
      "113/113 [==============================] - 0s 210us/step - loss: 0.1073 - acc: 0.8850 - val_loss: 0.1043 - val_acc: 0.8967\n",
      "Epoch 22/50\n",
      "113/113 [==============================] - 0s 167us/step - loss: 0.1072 - acc: 0.8850 - val_loss: 0.1043 - val_acc: 0.8967\n",
      "Epoch 23/50\n",
      "113/113 [==============================] - 0s 200us/step - loss: 0.1072 - acc: 0.8850 - val_loss: 0.1042 - val_acc: 0.8967\n",
      "Epoch 24/50\n",
      "113/113 [==============================] - 0s 162us/step - loss: 0.1072 - acc: 0.8850 - val_loss: 0.1042 - val_acc: 0.8967\n",
      "Epoch 25/50\n",
      "113/113 [==============================] - 0s 120us/step - loss: 0.1071 - acc: 0.8850 - val_loss: 0.1042 - val_acc: 0.8967\n",
      "Epoch 26/50\n",
      "113/113 [==============================] - 0s 131us/step - loss: 0.1071 - acc: 0.8850 - val_loss: 0.1042 - val_acc: 0.8967\n",
      "Epoch 27/50\n",
      "113/113 [==============================] - 0s 129us/step - loss: 0.1071 - acc: 0.8850 - val_loss: 0.1041 - val_acc: 0.8967\n",
      "Epoch 28/50\n",
      "113/113 [==============================] - 0s 119us/step - loss: 0.1071 - acc: 0.8850 - val_loss: 0.1041 - val_acc: 0.8967\n",
      "Epoch 29/50\n",
      "113/113 [==============================] - 0s 130us/step - loss: 0.1071 - acc: 0.8850 - val_loss: 0.1041 - val_acc: 0.8967\n",
      "Epoch 30/50\n",
      "113/113 [==============================] - 0s 347us/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.1041 - val_acc: 0.8967\n",
      "Epoch 31/50\n",
      "113/113 [==============================] - 0s 107us/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.1040 - val_acc: 0.8967\n",
      "Epoch 32/50\n",
      "113/113 [==============================] - 0s 372us/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.1040 - val_acc: 0.8967\n",
      "Epoch 33/50\n",
      "113/113 [==============================] - 0s 162us/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.1040 - val_acc: 0.8967\n",
      "Epoch 34/50\n",
      "113/113 [==============================] - 0s 215us/step - loss: 0.1069 - acc: 0.8850 - val_loss: 0.1040 - val_acc: 0.8967\n",
      "Epoch 35/50\n",
      "113/113 [==============================] - 0s 130us/step - loss: 0.1069 - acc: 0.8850 - val_loss: 0.1039 - val_acc: 0.8967\n",
      "Epoch 36/50\n",
      "113/113 [==============================] - 0s 180us/step - loss: 0.1069 - acc: 0.8850 - val_loss: 0.1039 - val_acc: 0.8967\n",
      "Epoch 37/50\n",
      "113/113 [==============================] - 0s 135us/step - loss: 0.1069 - acc: 0.8850 - val_loss: 0.1039 - val_acc: 0.8989\n",
      "Epoch 38/50\n",
      "113/113 [==============================] - 0s 216us/step - loss: 0.1068 - acc: 0.8850 - val_loss: 0.1038 - val_acc: 0.8989\n",
      "Epoch 39/50\n",
      "113/113 [==============================] - 0s 148us/step - loss: 0.1068 - acc: 0.8850 - val_loss: 0.1038 - val_acc: 0.8967\n",
      "Epoch 40/50\n",
      "113/113 [==============================] - 0s 112us/step - loss: 0.1068 - acc: 0.8850 - val_loss: 0.1038 - val_acc: 0.8989\n",
      "Epoch 41/50\n",
      "113/113 [==============================] - 0s 145us/step - loss: 0.1068 - acc: 0.8850 - val_loss: 0.1038 - val_acc: 0.8989\n",
      "Epoch 42/50\n",
      "113/113 [==============================] - 0s 149us/step - loss: 0.1067 - acc: 0.8850 - val_loss: 0.1037 - val_acc: 0.8989\n",
      "Epoch 43/50\n",
      "113/113 [==============================] - 0s 133us/step - loss: 0.1067 - acc: 0.8850 - val_loss: 0.1037 - val_acc: 0.8989\n",
      "Epoch 44/50\n",
      "113/113 [==============================] - 0s 127us/step - loss: 0.1067 - acc: 0.8850 - val_loss: 0.1037 - val_acc: 0.8989\n",
      "Epoch 45/50\n",
      "113/113 [==============================] - 0s 167us/step - loss: 0.1067 - acc: 0.8850 - val_loss: 0.1036 - val_acc: 0.8989\n",
      "Epoch 46/50\n",
      "113/113 [==============================] - 0s 115us/step - loss: 0.1066 - acc: 0.8850 - val_loss: 0.1036 - val_acc: 0.8989\n",
      "Epoch 47/50\n",
      "113/113 [==============================] - 0s 129us/step - loss: 0.1066 - acc: 0.8850 - val_loss: 0.1036 - val_acc: 0.8989\n",
      "Epoch 48/50\n",
      "113/113 [==============================] - 0s 127us/step - loss: 0.1066 - acc: 0.8850 - val_loss: 0.1036 - val_acc: 0.8989\n",
      "Epoch 49/50\n",
      "113/113 [==============================] - 0s 236us/step - loss: 0.1066 - acc: 0.8850 - val_loss: 0.1035 - val_acc: 0.8989\n",
      "Epoch 50/50\n",
      "113/113 [==============================] - 0s 125us/step - loss: 0.1065 - acc: 0.8850 - val_loss: 0.1035 - val_acc: 0.8989\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.8\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples, validate on 341 samples\n",
      "Epoch 1/50\n",
      "227/227 [==============================] - 0s 120us/step - loss: 0.1056 - acc: 0.8899 - val_loss: 0.1030 - val_acc: 0.9032\n",
      "Epoch 2/50\n",
      "227/227 [==============================] - 0s 79us/step - loss: 0.1056 - acc: 0.8899 - val_loss: 0.1029 - val_acc: 0.9032\n",
      "Epoch 3/50\n",
      "227/227 [==============================] - 0s 68us/step - loss: 0.1055 - acc: 0.8899 - val_loss: 0.1028 - val_acc: 0.9032\n",
      "Epoch 4/50\n",
      "227/227 [==============================] - 0s 75us/step - loss: 0.1054 - acc: 0.8899 - val_loss: 0.1026 - val_acc: 0.9032\n",
      "Epoch 5/50\n",
      "227/227 [==============================] - 0s 132us/step - loss: 0.1054 - acc: 0.8899 - val_loss: 0.1026 - val_acc: 0.9032\n",
      "Epoch 6/50\n",
      "227/227 [==============================] - 0s 76us/step - loss: 0.1053 - acc: 0.8899 - val_loss: 0.1025 - val_acc: 0.9032\n",
      "Epoch 7/50\n",
      "227/227 [==============================] - 0s 76us/step - loss: 0.1053 - acc: 0.8899 - val_loss: 0.1025 - val_acc: 0.9032\n",
      "Epoch 8/50\n",
      "227/227 [==============================] - 0s 111us/step - loss: 0.1052 - acc: 0.8899 - val_loss: 0.1024 - val_acc: 0.9032\n",
      "Epoch 9/50\n",
      "227/227 [==============================] - 0s 150us/step - loss: 0.1051 - acc: 0.8899 - val_loss: 0.1023 - val_acc: 0.9032\n",
      "Epoch 10/50\n",
      "227/227 [==============================] - 0s 95us/step - loss: 0.1051 - acc: 0.8899 - val_loss: 0.1022 - val_acc: 0.9032\n",
      "Epoch 11/50\n",
      "227/227 [==============================] - 0s 81us/step - loss: 0.1051 - acc: 0.8899 - val_loss: 0.1021 - val_acc: 0.9032\n",
      "Epoch 12/50\n",
      "227/227 [==============================] - 0s 73us/step - loss: 0.1050 - acc: 0.8899 - val_loss: 0.1020 - val_acc: 0.9032\n",
      "Epoch 13/50\n",
      "227/227 [==============================] - 0s 68us/step - loss: 0.1049 - acc: 0.8943 - val_loss: 0.1019 - val_acc: 0.9032\n",
      "Epoch 14/50\n",
      "227/227 [==============================] - 0s 73us/step - loss: 0.1049 - acc: 0.8943 - val_loss: 0.1018 - val_acc: 0.9032\n",
      "Epoch 15/50\n",
      "227/227 [==============================] - 0s 76us/step - loss: 0.1048 - acc: 0.8943 - val_loss: 0.1017 - val_acc: 0.9032\n",
      "Epoch 16/50\n",
      "227/227 [==============================] - 0s 104us/step - loss: 0.1048 - acc: 0.8943 - val_loss: 0.1016 - val_acc: 0.9032\n",
      "Epoch 17/50\n",
      "227/227 [==============================] - 0s 127us/step - loss: 0.1047 - acc: 0.8943 - val_loss: 0.1015 - val_acc: 0.9032\n",
      "Epoch 18/50\n",
      "227/227 [==============================] - 0s 92us/step - loss: 0.1047 - acc: 0.8943 - val_loss: 0.1015 - val_acc: 0.9032\n",
      "Epoch 19/50\n",
      "227/227 [==============================] - 0s 84us/step - loss: 0.1047 - acc: 0.8943 - val_loss: 0.1014 - val_acc: 0.9062\n",
      "Epoch 20/50\n",
      "227/227 [==============================] - 0s 88us/step - loss: 0.1046 - acc: 0.8943 - val_loss: 0.1013 - val_acc: 0.9062\n",
      "Epoch 21/50\n",
      "227/227 [==============================] - 0s 77us/step - loss: 0.1045 - acc: 0.8943 - val_loss: 0.1012 - val_acc: 0.9062\n",
      "Epoch 22/50\n",
      "227/227 [==============================] - 0s 67us/step - loss: 0.1045 - acc: 0.8987 - val_loss: 0.1012 - val_acc: 0.9062\n",
      "Epoch 23/50\n",
      "227/227 [==============================] - 0s 72us/step - loss: 0.1044 - acc: 0.8943 - val_loss: 0.1011 - val_acc: 0.9062\n",
      "Epoch 24/50\n",
      "227/227 [==============================] - 0s 62us/step - loss: 0.1044 - acc: 0.8943 - val_loss: 0.1011 - val_acc: 0.9062\n",
      "Epoch 25/50\n",
      "227/227 [==============================] - 0s 74us/step - loss: 0.1043 - acc: 0.8943 - val_loss: 0.1010 - val_acc: 0.9062\n",
      "Epoch 26/50\n",
      "227/227 [==============================] - 0s 84us/step - loss: 0.1043 - acc: 0.8987 - val_loss: 0.1010 - val_acc: 0.9062\n",
      "Epoch 27/50\n",
      "227/227 [==============================] - 0s 73us/step - loss: 0.1043 - acc: 0.8987 - val_loss: 0.1009 - val_acc: 0.9062\n",
      "Epoch 28/50\n",
      "227/227 [==============================] - 0s 58us/step - loss: 0.1042 - acc: 0.8987 - val_loss: 0.1008 - val_acc: 0.9062\n",
      "Epoch 29/50\n",
      "227/227 [==============================] - 0s 76us/step - loss: 0.1042 - acc: 0.8987 - val_loss: 0.1008 - val_acc: 0.9062\n",
      "Epoch 30/50\n",
      "227/227 [==============================] - 0s 64us/step - loss: 0.1042 - acc: 0.8987 - val_loss: 0.1007 - val_acc: 0.9062\n",
      "Epoch 31/50\n",
      "227/227 [==============================] - 0s 62us/step - loss: 0.1041 - acc: 0.8987 - val_loss: 0.1006 - val_acc: 0.9062\n",
      "Epoch 32/50\n",
      "227/227 [==============================] - 0s 56us/step - loss: 0.1040 - acc: 0.8987 - val_loss: 0.1005 - val_acc: 0.9062\n",
      "Epoch 33/50\n",
      "227/227 [==============================] - 0s 95us/step - loss: 0.1040 - acc: 0.8987 - val_loss: 0.1005 - val_acc: 0.9062\n",
      "Epoch 34/50\n",
      "227/227 [==============================] - 0s 72us/step - loss: 0.1039 - acc: 0.8987 - val_loss: 0.1004 - val_acc: 0.9091\n",
      "Epoch 35/50\n",
      "227/227 [==============================] - 0s 72us/step - loss: 0.1039 - acc: 0.8987 - val_loss: 0.1004 - val_acc: 0.9062\n",
      "Epoch 36/50\n",
      "227/227 [==============================] - 0s 75us/step - loss: 0.1038 - acc: 0.8987 - val_loss: 0.1003 - val_acc: 0.9091\n",
      "Epoch 37/50\n",
      "227/227 [==============================] - 0s 115us/step - loss: 0.1038 - acc: 0.8987 - val_loss: 0.1003 - val_acc: 0.9091\n",
      "Epoch 38/50\n",
      "227/227 [==============================] - 0s 72us/step - loss: 0.1037 - acc: 0.8987 - val_loss: 0.1002 - val_acc: 0.9091\n",
      "Epoch 39/50\n",
      "227/227 [==============================] - 0s 83us/step - loss: 0.1037 - acc: 0.9031 - val_loss: 0.1001 - val_acc: 0.9091\n",
      "Epoch 40/50\n",
      "227/227 [==============================] - 0s 85us/step - loss: 0.1036 - acc: 0.9031 - val_loss: 0.1000 - val_acc: 0.9091\n",
      "Epoch 41/50\n",
      "227/227 [==============================] - 0s 78us/step - loss: 0.1036 - acc: 0.9031 - val_loss: 0.0999 - val_acc: 0.9091\n",
      "Epoch 42/50\n",
      "227/227 [==============================] - 0s 87us/step - loss: 0.1035 - acc: 0.9031 - val_loss: 0.0999 - val_acc: 0.9091\n",
      "Epoch 43/50\n",
      "227/227 [==============================] - 0s 83us/step - loss: 0.1035 - acc: 0.9031 - val_loss: 0.0998 - val_acc: 0.9091\n",
      "Epoch 44/50\n",
      "227/227 [==============================] - 0s 78us/step - loss: 0.1035 - acc: 0.9031 - val_loss: 0.0998 - val_acc: 0.9091\n",
      "Epoch 45/50\n",
      "227/227 [==============================] - 0s 79us/step - loss: 0.1034 - acc: 0.9031 - val_loss: 0.0997 - val_acc: 0.9091\n",
      "Epoch 46/50\n",
      "227/227 [==============================] - 0s 124us/step - loss: 0.1034 - acc: 0.9031 - val_loss: 0.0997 - val_acc: 0.9091\n",
      "Epoch 47/50\n",
      "227/227 [==============================] - 0s 150us/step - loss: 0.1033 - acc: 0.9031 - val_loss: 0.0996 - val_acc: 0.9091\n",
      "Epoch 48/50\n",
      "227/227 [==============================] - 0s 114us/step - loss: 0.1033 - acc: 0.9031 - val_loss: 0.0996 - val_acc: 0.9091\n",
      "Epoch 49/50\n",
      "227/227 [==============================] - 0s 137us/step - loss: 0.1032 - acc: 0.9031 - val_loss: 0.0995 - val_acc: 0.9091\n",
      "Epoch 50/50\n",
      "227/227 [==============================] - 0s 109us/step - loss: 0.1032 - acc: 0.9031 - val_loss: 0.0995 - val_acc: 0.9091\n"
     ]
    }
   ],
   "source": [
    "batch_size = 63\n",
    "epochs = 50\n",
    "validation_split = 0.6\n",
    "history = model.fit(X, Y,\n",
    "batch_size = batch_size,\n",
    "epochs = epochs,\n",
    "verbose = 1,\n",
    "validation_split = validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 0s 95us/step\n",
      "Test loss: 0.10093047553804559\n",
      "Test accuracy: 0.9066901408450704\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X, Y, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
