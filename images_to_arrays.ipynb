{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program reads in the images, categorized by type, from the TrashNet dataset, resizes them, converts them to arrays, expands their dimensions, and writes each array to .npy files.\n",
    "The arrays are meant to be loaded up in the main project program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs an image from a given path and resizes it.\n",
    "size = 200\n",
    "\n",
    "def grab_image(img_path):\n",
    "    img = image.load_img(img_path, target_size = (size, size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    return x\n",
    "\n",
    "### LOAD IMAGES AND SAVE IMAGE DATA TO FILE\n",
    "# 0 - GLASS: 501 images\n",
    "imgdat_glass = np.concatenate([grab_image('TrashNet-Dataset/glass/0_%d_glass.jpg'\n",
    "                                         % (i)) for i in range(1, 502)])\n",
    "np.save('imgdat_glass_' + str(size) + 'x' + str(size) + '.npy', imgdat_glass)\n",
    "\n",
    "# 1 - PAPER: 594 images\n",
    "imgdat_paper = np.concatenate([grab_image('/nfshome/sandbox/TrashNet-Dataset/paper/1_%d_paper.jpg'\n",
    "                              % (i)) for i in range(1, 595)])\n",
    "np.save('imgdat_paper_' + str(size) + 'x' + str(size) + '.npy', imgdat_paper)\n",
    "\n",
    "# 2 - CARDBOARD: 403 images\n",
    "imgdat_cardboard = np.concatenate([grab_image('/nfshome/sandbox/TrashNet-Dataset/cardboard/2_%d_cardboard.jpg'\n",
    "                                            % (i)) for i in range(1, 404)])\n",
    "np.save('imgdat_cardboard_' + str(size) + 'x' + str(size) + '.npy', imgdat_cardboard)\n",
    "\n",
    "# 3 - PLASTIC: 482 images\n",
    "imgdat_plastic = np.concatenate([grab_image('/nfshome/sandbox/TrashNet-Dataset/plastic/3_%d_plastic.jpg'\n",
    "                                           % (i)) for i in range(1, 483)])\n",
    "np.save('imgdat_plastic_' + str(size) + 'x' + str(size) + '.npy', imgdat_plastic)\n",
    "\n",
    "# 4 - METAL: 410 images\n",
    "imgdat_metal = np.concatenate([grab_image('/nfshome/sandbox/TrashNet-Dataset/metal/4_%d_metal.jpg'\n",
    "                                          % (i)) for i in range(1, 411)])\n",
    "np.save('imgdat_metal_' + str(size) + 'x' + str(size) + '.npy', imgdat_metal)\n",
    "\n",
    "# 5 - TRASH: 137 images\n",
    "imgdat_trash = np.concatenate([grab_image('/nfshome/sandbox/TrashNet-Dataset/trash/5_%d_trash.jpg'\n",
    "                                          % (i)) for i in range(1, 138)])\n",
    "np.save('imgdat_trash_' + str(size) + 'x' + str(size) + '.npy', imgdat_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
